#!/usr/bin/env python3
"""
í…ŒìŠ¤íŠ¸ ë¡œê·¸ ë°ì´í„°ë¥¼ OpenSearchì— ì‚½ì…í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
KNN ë²¡í„° í•„ë“œ í¬í•¨
"""

import os
import sys
from datetime import datetime
from opensearchpy import OpenSearch
from openai import OpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
OPENSEARCH_HOST = os.getenv("OPENSEARCH_HOST", "localhost")
OPENSEARCH_PORT = int(os.getenv("OPENSEARCH_PORT", "9200"))
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL")

# OpenSearch í´ë¼ì´ì–¸íŠ¸
os_client = OpenSearch(
    hosts=[{"host": OPENSEARCH_HOST, "port": OPENSEARCH_PORT}],
    http_auth=("admin", "admin"),
    use_ssl=False,
    verify_certs=False,
)

# OpenAI í´ë¼ì´ì–¸íŠ¸
openai_client = OpenAI(
    api_key=OPENAI_API_KEY,
    base_url=OPENAI_BASE_URL,
)

# í˜„ì¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë¡œê·¸ ìƒì„±
def generate_recent_timestamp(hours_ago: int) -> str:
    """í˜„ì¬ UTC ì‹œê°„ì—ì„œ Nì‹œê°„ ì „ì˜ timestamp ìƒì„±"""
    from datetime import datetime, timedelta
    timestamp = datetime.utcnow() - timedelta(hours=hours_ago)
    return timestamp.isoformat() + "Z"

# í…ŒìŠ¤íŠ¸ ë¡œê·¸ ë°ì´í„° (ë‹¤ì–‘í•œ ì„œë¹„ìŠ¤ ë° ì‹œê°„ëŒ€)
SAMPLE_LOGS = [
    # ERROR ë¡œê·¸ë“¤ (ìµœê·¼ 24ì‹œê°„)
    {
        "method_name": "UserController.createUser",
        "level": "ERROR",
        "message": "NullPointerException: User object is null at line 45",
        "timestamp": generate_recent_timestamp(0.5),  # 30ë¶„ ì „
        "service_name": "user-service",
        "source_type": "BE",
        "log_id": 101,
    },
    {
        "method_name": "PaymentService.processPayment",
        "level": "ERROR",
        "message": "DatabaseTimeout: Connection pool exhausted after 30s",
        "timestamp": generate_recent_timestamp(3),  # 3ì‹œê°„ ì „
        "service_name": "payment-service",
        "source_type": "BE",
        "log_id": 102,
    },
    {
        "method_name": "AuthController.validateToken",
        "level": "ERROR",
        "message": "InvalidTokenException: JWT signature verification failed",
        "timestamp": generate_recent_timestamp(12),  # 12ì‹œê°„ ì „
        "service_name": "auth-service",
        "source_type": "BE",
        "log_id": 103,
    },
    # WARN ë¡œê·¸ë“¤
    {
        "method_name": "DatabaseConnection.executeQuery",
        "level": "WARN",
        "message": "Slow query detected: execution time 3.5s",
        "timestamp": generate_recent_timestamp(6),  # 6ì‹œê°„ ì „
        "service_name": "user-service",
        "source_type": "BE",
        "log_id": 104,
    },
    {
        "method_name": "CacheManager.get",
        "level": "WARN",
        "message": "Cache miss for key: user:12345",
        "timestamp": generate_recent_timestamp(2),  # 2ì‹œê°„ ì „
        "service_name": "cache-service",
        "source_type": "BE",
        "log_id": 105,
    },
    # INFO ë¡œê·¸ë“¤
    {
        "method_name": "Workflow.processUserWorkflow",
        "level": "INFO",
        "message": "Workflow.processUserWorkflow completed successfully",
        "timestamp": generate_recent_timestamp(1),  # 1ì‹œê°„ ì „
        "service_name": "Loglens",
        "source_type": "FE",
        "log_id": 106,
    },
    {
        "method_name": "ApiController.healthCheck",
        "level": "INFO",
        "message": "Health check passed: all services operational",
        "timestamp": generate_recent_timestamp(0.25),  # 15ë¶„ ì „
        "service_name": "gateway",
        "source_type": "BE",
        "log_id": 107,
    },
    # 7ì¼ ì „ ë¡œê·¸ (ì‹œê°„ ë²”ìœ„ í…ŒìŠ¤íŠ¸ìš©)
    {
        "method_name": "BatchJob.processDailyReports",
        "level": "ERROR",
        "message": "OutOfMemoryError: Java heap space exceeded",
        "timestamp": generate_recent_timestamp(168),  # 7ì¼ ì „
        "service_name": "batch-service",
        "source_type": "BE",
        "log_id": 108,
    },
]

PROJECT_UUID = "9f8c4c75-a936-3ab6-92a5-d1309cd9f87e"
INDEX_NAME = "9f8c4c75_a936_3ab6_92a5_d1309cd9f87e_2025_11"


def generate_embedding(text: str) -> list:
    """OpenAI APIë¡œ í…ìŠ¤íŠ¸ embedding ìƒì„± (1536 ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ)"""
    try:
        print(f"   ğŸ”„ Embedding ìƒì„± ì¤‘... (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)})")
        response = openai_client.embeddings.create(
            model="text-embedding-3-large",
            input=text,
            dimensions=1536,  # 1536 ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ
        )
        embedding = response.data[0].embedding
        print(f"   âœ… Embedding ìƒì„± ì™„ë£Œ (dim: {len(embedding)})")
        return embedding
    except Exception as e:
        print(f"âŒ Embedding ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def insert_logs():
    """ë¡œê·¸ ë°ì´í„°ë¥¼ OpenSearchì— ì‚½ì…"""
    print(f"ğŸ“ {len(SAMPLE_LOGS)}ê°œì˜ ë¡œê·¸ ì‚½ì… ì‹œì‘...")
    print(f"   ì¸ë±ìŠ¤: {INDEX_NAME}")
    print(f"   í”„ë¡œì íŠ¸: {PROJECT_UUID}")
    print(f"   í˜„ì¬ UTC ì‹œê°„: {datetime.utcnow().isoformat()}Z")
    print()

    for i, log in enumerate(SAMPLE_LOGS, 1):
        print(f"[{i}/{len(SAMPLE_LOGS)}] {log['method_name'][:40]}... ({log['level']})")

        # Embedding ìƒì„±
        embedding_text = f"{log['method_name']} {log['message']}"
        log_vector = generate_embedding(embedding_text)

        # ë¬¸ì„œ ìƒì„±
        doc = {
            "log_id": log["log_id"],
            "project_uuid": PROJECT_UUID,
            "service_name": log["service_name"],
            "log_level": log["level"],
            "level": log["level"],
            "source_type": log["source_type"],
            "method_name": log["method_name"],
            "class_name": log["method_name"].split(".")[0] if "." in log["method_name"] else "",
            "message": log["message"],
            "timestamp": log["timestamp"],
            "log_vector": log_vector,
            "indexed_at": datetime.utcnow().isoformat() + "Z",
        }

        # OpenSearchì— ì‚½ì…
        try:
            os_client.index(
                index=INDEX_NAME,
                body=doc,
                id=log["log_id"],
            )
            print(f"   âœ… ì‚½ì… ì™„ë£Œ (log_id: {log['log_id']})")
        except Exception as e:
            print(f"   âŒ ì‚½ì… ì‹¤íŒ¨: {e}")
            continue

    # Refresh
    print()
    print("ğŸ”„ ì¸ë±ìŠ¤ ìƒˆë¡œê³ ì¹¨...")
    os_client.indices.refresh(index=INDEX_NAME)

    # í™•ì¸
    print("âœ… ì‚½ì… ì™„ë£Œ!")
    print()
    print(f"ğŸ“Š ì¸ë±ìŠ¤ ì •ë³´:")
    stats = os_client.count(index=INDEX_NAME)
    print(f"   ì´ ë¬¸ì„œ ìˆ˜: {stats['count']}")

    # ìƒ˜í”Œ ì¡°íšŒ
    print()
    print("ğŸ“‹ ìƒ˜í”Œ ë¡œê·¸ ì¡°íšŒ:")
    result = os_client.search(
        index=INDEX_NAME,
        body={"query": {"match_all": {}}, "size": 1}
    )
    if result["hits"]["hits"]:
        hit = result["hits"]["hits"][0]["_source"]
        print(f"   log_id: {hit['log_id']}")
        print(f"   message: {hit['message'][:50]}...")
        print(f"   log_vector: [{hit['log_vector'][0]:.4f}, ..., {hit['log_vector'][-1]:.4f}] (dim: {len(hit['log_vector'])})")


if __name__ == "__main__":
    print("ğŸš€ OpenSearch í…ŒìŠ¤íŠ¸ ë¡œê·¸ ì‚½ì… ìŠ¤í¬ë¦½íŠ¸")
    print()

    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    if not OPENAI_API_KEY:
        print("âŒ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        sys.exit(1)

    # OpenSearch ì—°ê²° í™•ì¸
    try:
        info = os_client.info()
        print(f"âœ… OpenSearch ì—°ê²° ì„±ê³µ: {info['version']['number']}")
        print()
    except Exception as e:
        print(f"âŒ OpenSearch ì—°ê²° ì‹¤íŒ¨: {e}")
        sys.exit(1)

    # ì‚½ì… ì‹¤í–‰
    insert_logs()
    print()
    print("ğŸ‰ ì™„ë£Œ!")
