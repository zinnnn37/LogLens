"""
ë¹„êµ ë¶„ì„ ë„êµ¬ (Comparison Tools) - P1 Priority
- ì‹œê°„ëŒ€ ë¹„êµ, ì—°ì‡„ ì¥ì•  ê°ì§€
"""

from typing import Optional
from datetime import datetime, timedelta
from langchain_core.tools import tool

from app.core.opensearch import opensearch_client


@tool
async def compare_time_periods(
    project_uuid: str,
    current_hours: int = 24,
    comparison_hours: int = 24,
    metric: str = "error_count",  # error_count, error_rate, total_logs
    service_name: Optional[str] = None
) -> str:
    """
    ë‘ ì‹œê°„ëŒ€ë¥¼ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - "ì˜¤ëŠ˜ì´ ì–´ì œë³´ë‹¤ ì—ëŸ¬ê°€ ë§ë‚˜ìš”?"
    - "ì´ë²ˆ ì£¼ì™€ ì§€ë‚œ ì£¼ ë¹„êµí•´ì¤˜"
    - "ì§€ë‚œ 1ì‹œê°„ì´ í‰ì†Œë³´ë‹¤ ë¹„ì •ìƒì ì¸ê°€ìš”?"
    - "ì£¼ë§ê³¼ í‰ì¼ì˜ íŠ¸ë˜í”½ ì°¨ì´ëŠ”?"

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        current_hours: í˜„ì¬ ê¸°ê°„ (ì‹œê°„ ë‹¨ìœ„, ê¸°ë³¸ 24ì‹œê°„ = ì˜¤ëŠ˜)
        comparison_hours: ë¹„êµ ê¸°ê°„ (ì‹œê°„ ë‹¨ìœ„, ê¸°ë³¸ 24ì‹œê°„ = ì–´ì œ)
        metric: ë¹„êµ ë©”íŠ¸ë¦­ (error_count, error_rate, total_logs ì¤‘ í•˜ë‚˜)
        service_name: ì„œë¹„ìŠ¤ ì´ë¦„ í•„í„° (ì„ íƒ)

    ì°¸ê³ : project_uuidëŠ” ìë™ìœ¼ë¡œ ì£¼ì…ë˜ë¯€ë¡œ ì „ë‹¬í•˜ì§€ ë§ˆì„¸ìš”.

    Returns:
        ë‘ ê¸°ê°„ì˜ í†µê³„ ë¹„êµ, ë³€í™”ìœ¨, ì¦ê° ë°©í–¥
    """
    # ì¸ë±ìŠ¤ íŒ¨í„´
    index_pattern = f"{project_uuid.replace('-', '_')}_*"

    # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
    end_time = datetime.utcnow()
    current_start = end_time - timedelta(hours=current_hours)
    comparison_start = current_start - timedelta(hours=comparison_hours)
    comparison_end = current_start

    # Query êµ¬ì„±
    must_clauses = []
    if service_name:
        must_clauses.append({"term": {"service_name": service_name}})

    try:
        # OpenSearch Multi-period Aggregation Query
        results = opensearch_client.search(
            index=index_pattern,
            body={
                "size": 0,
                "query": {"bool": {"must": must_clauses}} if must_clauses else {"match_all": {}},
                "aggs": {
                    "current_period": {
                        "filter": {
                            "range": {
                                "timestamp": {
                                    "gte": current_start.isoformat() + "Z",
                                    "lte": end_time.isoformat() + "Z"
                                }
                            }
                        },
                        "aggs": {
                            "total_logs": {
                                "value_count": {"field": "log_id"}
                            },
                            "error_logs": {
                                "filter": {"term": {"level": "ERROR"}}
                            },
                            "warn_logs": {
                                "filter": {"term": {"level": "WARN"}}
                            },
                            "by_service": {
                                "terms": {
                                    "field": "service_name",
                                    "size": 10
                                }
                            }
                        }
                    },
                    "comparison_period": {
                        "filter": {
                            "range": {
                                "timestamp": {
                                    "gte": comparison_start.isoformat() + "Z",
                                    "lt": comparison_end.isoformat() + "Z"
                                }
                            }
                        },
                        "aggs": {
                            "total_logs": {
                                "value_count": {"field": "log_id"}
                            },
                            "error_logs": {
                                "filter": {"term": {"level": "ERROR"}}
                            },
                            "warn_logs": {
                                "filter": {"term": {"level": "WARN"}}
                            },
                            "by_service": {
                                "terms": {
                                    "field": "service_name",
                                    "size": 10
                                }
                            }
                        }
                    }
                }
            }
        )

        # ì§‘ê³„ ê²°ê³¼ ì¶”ì¶œ
        aggs = results.get("aggregations", {})
        current = aggs.get("current_period", {})
        comparison = aggs.get("comparison_period", {})

        # í˜„ì¬ ê¸°ê°„ ë°ì´í„°
        current_total = current.get("total_logs", {}).get("value", 0)
        current_errors = current.get("error_logs", {}).get("doc_count", 0)
        current_warns = current.get("warn_logs", {}).get("doc_count", 0)
        current_error_rate = (current_errors / current_total * 100) if current_total > 0 else 0

        # ë¹„êµ ê¸°ê°„ ë°ì´í„°
        comparison_total = comparison.get("total_logs", {}).get("value", 0)
        comparison_errors = comparison.get("error_logs", {}).get("doc_count", 0)
        comparison_warns = comparison.get("warn_logs", {}).get("doc_count", 0)
        comparison_error_rate = (comparison_errors / comparison_total * 100) if comparison_total > 0 else 0

        if current_total == 0 and comparison_total == 0:
            return f"ë‘ ê¸°ê°„ ëª¨ë‘ ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ë³€í™”ìœ¨ ê³„ì‚°
        if metric == "error_count":
            current_value = current_errors
            comparison_value = comparison_errors
            metric_name = "ì—ëŸ¬ ìˆ˜"
            unit = "ê±´"
        elif metric == "error_rate":
            current_value = current_error_rate
            comparison_value = comparison_error_rate
            metric_name = "ì—ëŸ¬ìœ¨"
            unit = "%"
        else:  # total_logs
            current_value = current_total
            comparison_value = comparison_total
            metric_name = "ì´ ë¡œê·¸ ìˆ˜"
            unit = "ê±´"

        if comparison_value > 0:
            change_rate = ((current_value - comparison_value) / comparison_value * 100)
            absolute_change = current_value - comparison_value
        else:
            change_rate = 100 if current_value > 0 else 0
            absolute_change = current_value

        # ì¶”ì„¸ íŒì •
        if abs(change_rate) < 5:
            trend = "ë¹„ìŠ·í•¨"
            trend_emoji = "ğŸŸ¢"
        elif change_rate > 0:
            if change_rate > 50:
                trend = "ê¸‰ì¦"
                trend_emoji = "ğŸ”´"
            elif change_rate > 20:
                trend = "í¬ê²Œ ì¦ê°€"
                trend_emoji = "ğŸŸ "
            else:
                trend = "ì¦ê°€"
                trend_emoji = "ğŸŸ¡"
        else:
            if change_rate < -50:
                trend = "ê¸‰ê°"
                trend_emoji = "ğŸŸ¢"
            elif change_rate < -20:
                trend = "í¬ê²Œ ê°ì†Œ"
                trend_emoji = "ğŸŸ¢"
            else:
                trend = "ê°ì†Œ"
                trend_emoji = "ğŸŸ¢"

        # ê²°ê³¼ í¬ë§·íŒ…
        summary_lines = [
            f"=== ì‹œê°„ëŒ€ ë¹„êµ ë¶„ì„ ===",
            ""
        ]

        if service_name:
            summary_lines.append(f"ğŸ”§ ì„œë¹„ìŠ¤: {service_name}")
            summary_lines.append("")

        # ê¸°ê°„ ì •ë³´
        current_label = f"ìµœê·¼ {current_hours}ì‹œê°„"
        comparison_label = f"ì´ì „ {comparison_hours}ì‹œê°„"

        summary_lines.append(f"ğŸ“… ë¹„êµ ê¸°ê°„:")
        summary_lines.append(f"  - {current_label}: {current_start.strftime('%Y-%m-%d %H:%M')} ~ {end_time.strftime('%Y-%m-%d %H:%M')}")
        summary_lines.append(f"  - {comparison_label}: {comparison_start.strftime('%Y-%m-%d %H:%M')} ~ {comparison_end.strftime('%Y-%m-%d %H:%M')}")
        summary_lines.append("")

        # ì£¼ìš” ë©”íŠ¸ë¦­ ë¹„êµ
        summary_lines.append(f"## ğŸ“Š {metric_name} ë¹„êµ")
        summary_lines.append("")
        summary_lines.append(f"**{current_label}**: {current_value:.2f}{unit}")
        summary_lines.append(f"**{comparison_label}**: {comparison_value:.2f}{unit}")
        summary_lines.append(f"**ë³€í™”**: {absolute_change:+.2f}{unit} ({change_rate:+.1f}%)")
        summary_lines.append(f"**ì¶”ì„¸**: {trend_emoji} {trend}")
        summary_lines.append("")

        # ìƒì„¸ í†µê³„ ë¹„êµí‘œ
        summary_lines.append("## ğŸ“ˆ ìƒì„¸ í†µê³„ ë¹„êµ")
        summary_lines.append("")
        summary_lines.append(f"| ë©”íŠ¸ë¦­ | {current_label} | {comparison_label} | ë³€í™” |")
        summary_lines.append("|--------|---------|---------|------|")
        summary_lines.append(f"| ì´ ë¡œê·¸ | {int(current_total):,}ê±´ | {int(comparison_total):,}ê±´ | {int(current_total - comparison_total):+,}ê±´ |")
        summary_lines.append(f"| ì—ëŸ¬ | {current_errors}ê±´ | {comparison_errors}ê±´ | {current_errors - comparison_errors:+}ê±´ |")
        summary_lines.append(f"| ê²½ê³  | {current_warns}ê±´ | {comparison_warns}ê±´ | {current_warns - comparison_warns:+}ê±´ |")
        summary_lines.append(f"| ì—ëŸ¬ìœ¨ | {current_error_rate:.2f}% | {comparison_error_rate:.2f}% | {current_error_rate - comparison_error_rate:+.2f}%p |")
        summary_lines.append("")

        # ì„œë¹„ìŠ¤ë³„ ë¹„êµ (ìƒìœ„ 5ê°œ)
        current_services = {sb["key"]: sb["doc_count"] for sb in current.get("by_service", {}).get("buckets", [])}
        comparison_services = {sb["key"]: sb["doc_count"] for sb in comparison.get("by_service", {}).get("buckets", [])}
        all_services = set(current_services.keys()) | set(comparison_services.keys())

        if all_services and not service_name:
            summary_lines.append("## ğŸ”§ ì„œë¹„ìŠ¤ë³„ ë¹„êµ (ìƒìœ„ 5ê°œ)")
            summary_lines.append("")

            # ì„œë¹„ìŠ¤ë³„ ë³€í™”ìœ¨ ê³„ì‚° í›„ ì •ë ¬
            service_changes = []
            for svc in all_services:
                cur_count = current_services.get(svc, 0)
                cmp_count = comparison_services.get(svc, 0)
                change = cur_count - cmp_count
                change_pct = ((cur_count - cmp_count) / cmp_count * 100) if cmp_count > 0 else (100 if cur_count > 0 else 0)
                service_changes.append({
                    "name": svc,
                    "current": cur_count,
                    "comparison": cmp_count,
                    "change": change,
                    "change_pct": change_pct
                })

            # ì ˆëŒ€ ë³€í™”ëŸ‰ ìˆœìœ¼ë¡œ ì •ë ¬
            service_changes.sort(key=lambda s: abs(s["change"]), reverse=True)

            for sc in service_changes[:5]:
                change_emoji = "ğŸ”´" if sc["change"] > 0 else "ğŸŸ¢" if sc["change"] < 0 else "âšª"
                summary_lines.append(f"**{sc['name']}**")
                summary_lines.append(f"  {change_emoji} {int(sc['current']):,}ê±´ â†’ {int(sc['comparison']):,}ê±´ ({sc['change']:+,}ê±´, {sc['change_pct']:+.1f}%)")

            summary_lines.append("")

        # ì¢…í•© í‰ê°€
        summary_lines.append("## ğŸ’¡ ì¢…í•© í‰ê°€")
        summary_lines.append("")

        if trend in ["ê¸‰ì¦", "í¬ê²Œ ì¦ê°€"] and metric in ["error_count", "error_rate"]:
            summary_lines.append(f"ğŸš¨ **ê²½ê³ **: {metric_name}ì´(ê°€) {trend}í–ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ì›ì¸ íŒŒì•…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            summary_lines.append(f"   - ë³€í™”ìœ¨: {change_rate:+.1f}%")
            summary_lines.append(f"   - ì ˆëŒ€ ë³€í™”: {absolute_change:+.2f}{unit}")
        elif trend == "ì¦ê°€" and metric in ["error_count", "error_rate"]:
            summary_lines.append(f"âš ï¸ **ì£¼ì˜**: {metric_name}ì´(ê°€) ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ëª¨ë‹ˆí„°ë§ì„ ê°•í™”í•˜ì„¸ìš”.")
        elif trend in ["ê¸‰ê°", "í¬ê²Œ ê°ì†Œ", "ê°ì†Œ"] and metric in ["error_count", "error_rate"]:
            summary_lines.append(f"âœ… **ì–‘í˜¸**: {metric_name}ì´(ê°€) {trend}í–ˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì´ ê°œì„ ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
        else:
            summary_lines.append(f"â„¹ï¸ **ì•ˆì •**: {metric_name}ì´(ê°€) ë¹„ìŠ·í•œ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")

        return "\n".join(summary_lines)

    except Exception as e:
        return f"ì‹œê°„ëŒ€ ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
async def detect_cascading_failures(
    project_uuid: str,
    time_hours: int = 1,  # ê¸°ë³¸ 1ì‹œê°„ (ì—°ì‡„ ì¥ì• ëŠ” ì§§ì€ ì‹œê°„ ë‚´ ë°œìƒ)
    window_minutes: int = 5,  # ë™ì‹œ ë°œìƒ íŒë‹¨ ìœˆë„ìš° (5ë¶„)
    min_services: int = 2  # ìµœì†Œ ì˜í–¥ ì„œë¹„ìŠ¤ ìˆ˜
) -> str:
    """
    ì—°ì‡„ ì¥ì• (Cascading Failure)ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - "database-service ì¥ì• ê°€ ë‹¤ë¥¸ ì„œë¹„ìŠ¤ì— ì˜í–¥ì„ ì£¼ë‚˜ìš”?"
    - "ì„œë¹„ìŠ¤ ê°„ ì˜ì¡´ì„± ë¬¸ì œê°€ ìˆë‚˜ìš”?"
    - "ë™ì‹œì— ì—¬ëŸ¬ ì„œë¹„ìŠ¤ì—ì„œ ë°œìƒí•œ ì—ëŸ¬ëŠ”?"
    - "ì—°ì‡„ ì¥ì•  íŒ¨í„´ì´ ìˆë‚˜ìš”?"

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        time_hours: ë¶„ì„ ì‹œê°„ ë²”ìœ„ (ì‹œê°„ ë‹¨ìœ„, ê¸°ë³¸ 1ì‹œê°„)
        window_minutes: ë™ì‹œ ë°œìƒ íŒë‹¨ ì‹œê°„ ìœˆë„ìš° (ë¶„ ë‹¨ìœ„, ê¸°ë³¸ 5ë¶„)
        min_services: ì—°ì‡„ ì¥ì• ë¡œ íŒë‹¨í•  ìµœì†Œ ì„œë¹„ìŠ¤ ìˆ˜ (ê¸°ë³¸ 2ê°œ)

    ì°¸ê³ : project_uuidëŠ” ìë™ìœ¼ë¡œ ì£¼ì…ë˜ë¯€ë¡œ ì „ë‹¬í•˜ì§€ ë§ˆì„¸ìš”.

    Returns:
        ì—°ì‡„ ì¥ì•  íŒ¨í„´, ì˜í–¥ë°›ì€ ì„œë¹„ìŠ¤ ëª©ë¡, ë°œìƒ ì‹œê°„ëŒ€
    """
    # ì¸ë±ìŠ¤ íŒ¨í„´
    index_pattern = f"{project_uuid.replace('-', '_')}_*"

    # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=time_hours)

    # Query êµ¬ì„±
    must_clauses = [
        {"term": {"level": "ERROR"}},
        {"range": {
            "timestamp": {
                "gte": start_time.isoformat() + "Z",
                "lte": end_time.isoformat() + "Z"
            }
        }}
    ]

    try:
        # OpenSearch Aggregation Query (ì‹œê°„ ìœˆë„ìš°ë³„ ë‹¤ì¤‘ ì„œë¹„ìŠ¤ ì—ëŸ¬ ê°ì§€)
        results = opensearch_client.search(
            index=index_pattern,
            body={
                "size": 0,
                "query": {"bool": {"must": must_clauses}},
                "aggs": {
                    "time_windows": {
                        "date_histogram": {
                            "field": "timestamp",
                            "fixed_interval": f"{window_minutes}m",
                            "time_zone": "Asia/Seoul"
                        },
                        "aggs": {
                            "services_with_errors": {
                                "terms": {
                                    "field": "service_name",
                                    "size": 20
                                },
                                "aggs": {
                                    "error_count": {
                                        "value_count": {"field": "log_id"}
                                    },
                                    "error_types": {
                                        "terms": {
                                            "field": "log_details.exception_type",
                                            "size": 5
                                        }
                                    }
                                }
                            },
                            "service_count": {
                                "cardinality": {"field": "service_name"}
                            }
                        }
                    }
                }
            }
        )

        # ì§‘ê³„ ê²°ê³¼ ì¶”ì¶œ
        buckets = results.get("aggregations", {}).get("time_windows", {}).get("buckets", [])
        total_errors = results.get("hits", {}).get("total", {}).get("value", 0)

        if total_errors == 0:
            return f"ìµœê·¼ {time_hours}ì‹œê°„ ë™ì•ˆ ERROR ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ì—°ì‡„ ì¥ì•  íŒ¨í„´ ê°ì§€ (min_servicesê°œ ì´ìƒì˜ ì„œë¹„ìŠ¤ì—ì„œ ë™ì‹œ ì—ëŸ¬)
        cascading_patterns = []
        for bucket in buckets:
            time_str = bucket.get("key_as_string", "")
            service_count = bucket.get("service_count", {}).get("value", 0)
            total_errors_in_window = bucket.get("doc_count", 0)

            if service_count >= min_services and total_errors_in_window > 0:
                service_buckets = bucket.get("services_with_errors", {}).get("buckets", [])
                services = []
                for sb in service_buckets:
                    service_name = sb.get("key", "")
                    error_cnt = sb.get("error_count", {}).get("value", 0)
                    error_type_buckets = sb.get("error_types", {}).get("buckets", [])
                    error_types = [etb["key"] for etb in error_type_buckets]

                    services.append({
                        "name": service_name,
                        "error_count": int(error_cnt),
                        "error_types": error_types
                    })

                cascading_patterns.append({
                    "time": time_str,
                    "service_count": service_count,
                    "total_errors": total_errors_in_window,
                    "services": services
                })

        if not cascading_patterns:
            return f"ìµœê·¼ {time_hours}ì‹œê°„ ë™ì•ˆ ì—°ì‡„ ì¥ì•  íŒ¨í„´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ë™ì‹œ {min_services}ê°œ ì´ìƒ ì„œë¹„ìŠ¤ ì—ëŸ¬ ì—†ìŒ)"

        # ê²°ê³¼ í¬ë§·íŒ…
        summary_lines = [
            f"=== ì—°ì‡„ ì¥ì•  ê°ì§€ (ìµœê·¼ {time_hours}ì‹œê°„) ===",
            f"ê°ì§€ ì¡°ê±´: {window_minutes}ë¶„ ë‚´ {min_services}ê°œ ì´ìƒ ì„œë¹„ìŠ¤ ë™ì‹œ ì—ëŸ¬",
            ""
        ]

        summary_lines.append(f"ğŸš¨ **{len(cascading_patterns)}ê°œì˜ ì—°ì‡„ ì¥ì•  íŒ¨í„´ ê°ì§€**")
        summary_lines.append("")

        # ì—°ì‡„ ì¥ì•  íŒ¨í„´ë³„ ìƒì„¸
        for i, pattern in enumerate(cascading_patterns, 1):
            time_display = pattern["time"][:16].replace("T", " ")
            service_count = pattern["service_count"]
            total_errors = pattern["total_errors"]
            services = pattern["services"]

            # ì‹¬ê°ë„ íŒì •
            if service_count >= 5:
                severity = "ğŸ”´ ë§¤ìš° ì‹¬ê°"
            elif service_count >= 3:
                severity = "ğŸŸ  ì‹¬ê°"
            else:
                severity = "ğŸŸ¡ ì£¼ì˜"

            summary_lines.append(f"## {i}. {time_display} | {severity}")
            summary_lines.append(f"   ì˜í–¥ ì„œë¹„ìŠ¤: {service_count}ê°œ | ì´ ì—ëŸ¬: {total_errors}ê±´")
            summary_lines.append("")

            # ì„œë¹„ìŠ¤ë³„ ìƒì„¸
            summary_lines.append("   **ì˜í–¥ë°›ì€ ì„œë¹„ìŠ¤:**")
            for svc in services:
                error_types_str = ", ".join(svc["error_types"][:2])
                if len(svc["error_types"]) > 2:
                    error_types_str += f" ì™¸ {len(svc['error_types']) - 2}ê°œ"

                summary_lines.append(f"   - {svc['name']}: {svc['error_count']}ê±´")
                if error_types_str:
                    summary_lines.append(f"     ì—ëŸ¬ íƒ€ì…: {error_types_str}")

            summary_lines.append("")

        # ì—°ì‡„ ì¥ì•  ë¶„ì„
        summary_lines.append("## ğŸ“Š ì—°ì‡„ ì¥ì•  ë¶„ì„")
        summary_lines.append("")

        # ê°€ì¥ ìì£¼ ì˜í–¥ë°›ì€ ì„œë¹„ìŠ¤ ì°¾ê¸°
        service_impact_count = {}
        for pattern in cascading_patterns:
            for svc in pattern["services"]:
                service_impact_count[svc["name"]] = service_impact_count.get(svc["name"], 0) + 1

        if service_impact_count:
            summary_lines.append("ê°€ì¥ ìì£¼ ì˜í–¥ë°›ì€ ì„œë¹„ìŠ¤:")
            sorted_services = sorted(service_impact_count.items(), key=lambda x: x[1], reverse=True)
            for svc_name, count in sorted_services[:5]:
                summary_lines.append(f"  - {svc_name}: {count}íšŒ ì˜í–¥")
            summary_lines.append("")

        # ê³µí†µ ì—ëŸ¬ íƒ€ì… ë¶„ì„
        all_error_types = {}
        for pattern in cascading_patterns:
            for svc in pattern["services"]:
                for error_type in svc["error_types"]:
                    all_error_types[error_type] = all_error_types.get(error_type, 0) + 1

        if all_error_types:
            summary_lines.append("ê³µí†µ ì—ëŸ¬ íƒ€ì…:")
            sorted_errors = sorted(all_error_types.items(), key=lambda x: x[1], reverse=True)
            for error_type, count in sorted_errors[:5]:
                summary_lines.append(f"  - {error_type}: {count}íšŒ ë°œìƒ")
            summary_lines.append("")

        # ê¶Œì¥ ì¡°ì¹˜
        summary_lines.append("## ğŸ’¡ ê¶Œì¥ ì¡°ì¹˜")
        summary_lines.append("")

        if len(cascading_patterns) >= 3:
            summary_lines.append("ğŸš¨ **ê¸´ê¸‰**: ë°˜ë³µì ì¸ ì—°ì‡„ ì¥ì• ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            summary_lines.append("   1. ê°€ì¥ ìì£¼ ì˜í–¥ë°›ì€ ì„œë¹„ìŠ¤ë¶€í„° ì ê²€")
            summary_lines.append("   2. ì„œë¹„ìŠ¤ ê°„ ì˜ì¡´ì„± ê²€í† ")
            summary_lines.append("   3. Circuit Breaker íŒ¨í„´ ì ìš© ê²€í† ")
        elif sorted_services[0][1] >= len(cascading_patterns) * 0.8:
            # íŠ¹ì • ì„œë¹„ìŠ¤ê°€ 80% ì´ìƒ ì—°ì‡„ ì¥ì• ì— í¬í•¨
            root_service = sorted_services[0][0]
            summary_lines.append(f"ğŸ” **ë¶„ì„**: '{root_service}' ì„œë¹„ìŠ¤ê°€ ëŒ€ë¶€ë¶„ì˜ ì—°ì‡„ ì¥ì• ì— ê´€ì—¬í•©ë‹ˆë‹¤.")
            summary_lines.append(f"   â†’ '{root_service}'ê°€ ê·¼ë³¸ ì›ì¸(Root Cause)ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")
            summary_lines.append(f"   â†’ '{root_service}' ì„œë¹„ìŠ¤ë¥¼ ìš°ì„  ì ê²€í•˜ì„¸ìš”.")
        else:
            summary_lines.append("âš ï¸ **ì£¼ì˜**: ì—¬ëŸ¬ ì„œë¹„ìŠ¤ê°€ ë™ì‹œì— ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ê³  ìˆìŠµë‹ˆë‹¤.")
            summary_lines.append("   1. ê³µí†µ ì¸í”„ë¼(DB, Cache ë“±) ì ê²€")
            summary_lines.append("   2. ë„¤íŠ¸ì›Œí¬ ìƒíƒœ í™•ì¸")
            summary_lines.append("   3. ì™¸ë¶€ API ì¥ì•  ì—¬ë¶€ í™•ì¸")

        return "\n".join(summary_lines)

    except Exception as e:
        return f"ì—°ì‡„ ì¥ì•  ê°ì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
