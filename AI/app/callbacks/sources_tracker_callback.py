"""
ì¶œì²˜ ì¶”ì  ì½œë°± - Agent ë„êµ¬ í˜¸ì¶œ ì‹œ ë¡œê·¸ ì¶œì²˜ ìë™ ìˆ˜ì§‘

LangChain Callbackì„ ì´ìš©í•˜ì—¬ Agentê°€ í˜¸ì¶œí•˜ëŠ” ë„êµ¬ì˜ ì¶œë ¥ì„ ëª¨ë‹ˆí„°ë§í•˜ê³ 
LogSourceë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘
"""

from typing import Any, Dict, List, Optional
from langchain.callbacks.base import BaseCallbackHandler
from app.utils.sources_tracker import SourcesTracker
import json
import re


class SourcesTrackerCallback(BaseCallbackHandler):
    """
    Agent ë„êµ¬ í˜¸ì¶œì„ ì¶”ì í•˜ì—¬ ë¡œê·¸ ì¶œì²˜ ìë™ ìˆ˜ì§‘

    ì‚¬ìš© ë°©ë²•:
    ```python
    tracker = SourcesTracker()
    callback = SourcesTrackerCallback(tracker)
    agent_executor.invoke(input, config={"callbacks": [callback]})
    sources = tracker.get_top_sources()
    validation = tracker.get_validation_info()
    ```
    """

    def __init__(self, sources_tracker: SourcesTracker):
        """
        Args:
            sources_tracker: SourcesTracker ì¸ìŠ¤í„´ìŠ¤ (ê³µìœ )
        """
        self.sources_tracker = sources_tracker

    def on_tool_start(
        self,
        serialized: Dict[str, Any],
        input_str: str,
        **kwargs: Any
    ) -> None:
        """
        ë„êµ¬ ì‹œì‘ ì‹œ í˜¸ì¶œ

        Args:
            serialized: ë„êµ¬ ì •ë³´
            input_str: ë„êµ¬ ì…ë ¥ (JSON ë¬¸ìì—´)
        """
        tool_name = serialized.get("name", "unknown")

        # ì…ë ¥ íŒŒì‹± (JSON í˜•ì‹)
        try:
            params = json.loads(input_str) if input_str.startswith("{") else {"raw": input_str}
        except json.JSONDecodeError:
            params = {"raw": input_str}

        # ë„êµ¬ í˜¸ì¶œ ê¸°ë¡
        self.sources_tracker.add_tool_call(tool_name, params)

    def on_tool_end(
        self,
        output: str,
        **kwargs: Any
    ) -> None:
        """
        ë„êµ¬ ì¢…ë£Œ ì‹œ í˜¸ì¶œ - ì¶œë ¥ì—ì„œ ë¡œê·¸ ì¶”ì¶œ

        Args:
            output: ë„êµ¬ ì¶œë ¥ (ë¬¸ìì—´)
        """
        # ì¶œë ¥ì´ JSONì¸ì§€ í™•ì¸
        logs = self._extract_logs_from_output(output)

        if logs:
            # ë¡œê·¸ ì¶œì²˜ ì¶”ê°€
            # ê²€ìƒ‰ íƒ€ì… ì¶”ë¡  (ì¶œë ¥ ë¶„ì„)
            search_type = self._infer_search_type(output)
            self.sources_tracker.add_sources(logs, search_type)

    def _extract_logs_from_output(self, output: str) -> List[Dict[str, Any]]:
        """
        ë„êµ¬ ì¶œë ¥ì—ì„œ ë¡œê·¸ ì •ë³´ ì¶”ì¶œ

        ë„êµ¬ ì¶œë ¥ í˜•ì‹ ì˜ˆ:
        - "ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼: 5ê±´\n\n1. [ERROR] ..."
        - JSON í˜•ì‹: {"logs": [...], "count": 5}
        - ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹

        Returns:
            List[Dict]: ì¶”ì¶œëœ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
        """
        logs = []

        # 1. JSON í˜•ì‹ ì‹œë„
        try:
            data = json.loads(output)
            if isinstance(data, dict) and "logs" in data:
                return data["logs"]
        except json.JSONDecodeError:
            pass

        # 2. ë§ˆí¬ë‹¤ìš´ ë¡œê·¸ ì—”íŠ¸ë¦¬ íŒ¨í„´ ë§¤ì¹­
        # íŒ¨í„´: "1. [ERROR] NullPointerException ... (log_id: 12345, 2024-01-15 10:30:00)"
        log_pattern = re.compile(
            r'\d+\.\s*\[([A-Z]+)\]\s*(.+?)\s*\(log_id:\s*(\d+),\s*(.+?)\)',
            re.MULTILINE | re.DOTALL
        )

        matches = log_pattern.findall(output)
        for match in matches:
            level, message, log_id, timestamp = match
            log = {
                "log_id": log_id.strip(),
                "level": level.strip(),
                "message": message.strip()[:500],  # ìµœëŒ€ 500ì
                "timestamp": timestamp.strip(),
                "service_name": self._extract_service_name(message)
            }
            logs.append(log)

        # 3. ê°„ë‹¨í•œ ERROR/WARN/INFO íŒ¨í„´ ë§¤ì¹­ (fallback)
        if not logs:
            simple_pattern = re.compile(r'\[?(ERROR|WARN|INFO)\]?\s*(.+)', re.MULTILINE)
            simple_matches = simple_pattern.findall(output)

            for i, (level, message) in enumerate(simple_matches[:10], 1):  # ìµœëŒ€ 10ê°œ
                log = {
                    "log_id": f"extracted_{i}",
                    "level": level.strip(),
                    "message": message.strip()[:500],
                    "timestamp": "",
                    "service_name": self._extract_service_name(message)
                }
                logs.append(log)

        return logs

    def _extract_service_name(self, message: str) -> str:
        """
        ë©”ì‹œì§€ì—ì„œ ì„œë¹„ìŠ¤ ì´ë¦„ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)

        Args:
            message: ë¡œê·¸ ë©”ì‹œì§€

        Returns:
            str: ì„œë¹„ìŠ¤ ì´ë¦„ (ì°¾ì§€ ëª»í•˜ë©´ "unknown")
        """
        # "user-service", "payment-api" ê°™ì€ íŒ¨í„´
        service_pattern = re.compile(r'([\w-]+)-(service|api|gateway|worker)')
        match = service_pattern.search(message)
        if match:
            return match.group(0)

        # "UserService", "PaymentAPI" ê°™ì€ íŒ¨í„´
        class_pattern = re.compile(r'([A-Z][a-z]+)+(?:Service|API|Controller|Manager)')
        match = class_pattern.search(message)
        if match:
            return match.group(0)

        return "unknown"

    def _infer_search_type(self, output: str) -> str:
        """
        ë„êµ¬ ì¶œë ¥ì—ì„œ ê²€ìƒ‰ íƒ€ì… ì¶”ë¡ 

        Args:
            output: ë„êµ¬ ì¶œë ¥ ë¬¸ìì—´

        Returns:
            "vector_knn" | "keyword" | "filter" | "aggregation" | "unknown"
        """
        output_lower = output.lower()

        if "vector" in output_lower or "ìœ ì‚¬ë„" in output_lower or "similarity" in output_lower:
            return "vector_knn"
        elif "keyword" in output_lower or "í‚¤ì›Œë“œ" in output_lower:
            return "keyword"
        elif "filter" in output_lower or "í•„í„°" in output_lower:
            return "filter"
        elif "í†µê³„" in output_lower or "ì§‘ê³„" in output_lower or "statistics" in output_lower:
            return "aggregation"
        else:
            return "unknown"
