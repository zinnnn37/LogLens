"""
V2 LangGraph API - Statistics Comparison Endpoints

AI vs DB í†µê³„ ë¹„êµë¥¼ í†µí•œ LLM ì—­ëŸ‰ ê²€ì¦ API
"""

import logging
from fastapi import APIRouter, HTTPException, Query
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import datetime

from app.tools.statistics_comparison_tools import (
    _get_db_statistics,
    _get_log_samples,
    _get_stratified_log_samples,
    _llm_estimate_statistics,
    _calculate_accuracy
)

logger = logging.getLogger(__name__)


router = APIRouter(prefix="/v2-langgraph", tags=["Statistics Comparison"])


# Response Models
class DBStatistics(BaseModel):
    """DB ì§ì ‘ ì¡°íšŒ í†µê³„"""
    total_logs: int = Field(..., description="ì´ ë¡œê·¸ ìˆ˜")
    error_count: int = Field(..., description="ERROR ë¡œê·¸ ìˆ˜")
    warn_count: int = Field(..., description="WARN ë¡œê·¸ ìˆ˜")
    info_count: int = Field(..., description="INFO ë¡œê·¸ ìˆ˜")
    error_rate: float = Field(..., description="ì—ëŸ¬ìœ¨ (%)")
    peak_hour: str = Field(..., description="í”¼í¬ ì‹œê°„")
    peak_count: int = Field(..., description="í”¼í¬ ì‹œê°„ ë¡œê·¸ ìˆ˜")


class AIStatistics(BaseModel):
    """AI(LLM) ì¶”ë¡  í†µê³„"""
    estimated_total_logs: int = Field(..., description="ì¶”ë¡ í•œ ì´ ë¡œê·¸ ìˆ˜")
    estimated_error_count: int = Field(..., description="ì¶”ë¡ í•œ ERROR ë¡œê·¸ ìˆ˜")
    estimated_warn_count: int = Field(..., description="ì¶”ë¡ í•œ WARN ë¡œê·¸ ìˆ˜")
    estimated_info_count: int = Field(..., description="ì¶”ë¡ í•œ INFO ë¡œê·¸ ìˆ˜")
    estimated_error_rate: float = Field(..., description="ì¶”ë¡ í•œ ì—ëŸ¬ìœ¨ (%)")
    confidence_score: int = Field(..., description="AI ì‹ ë¢°ë„ (0-100)")
    reasoning: str = Field(..., description="ì¶”ë¡  ê·¼ê±°")


class AccuracyMetrics(BaseModel):
    """ì •í™•ë„ ì§€í‘œ"""
    total_logs_accuracy: float = Field(..., description="ì´ ë¡œê·¸ ìˆ˜ ì¼ì¹˜ìœ¨ (%)")
    error_count_accuracy: float = Field(..., description="ERROR ìˆ˜ ì¼ì¹˜ìœ¨ (%)")
    warn_count_accuracy: float = Field(..., description="WARN ìˆ˜ ì¼ì¹˜ìœ¨ (%)")
    info_count_accuracy: float = Field(..., description="INFO ìˆ˜ ì¼ì¹˜ìœ¨ (%)")
    error_rate_accuracy: float = Field(..., description="ì—ëŸ¬ìœ¨ ì •í™•ë„ (%)")
    overall_accuracy: float = Field(..., description="ì¢…í•© ì •í™•ë„ (%)")
    ai_confidence: int = Field(..., description="AI ìì²´ ì‹ ë¢°ë„")


class ComparisonVerdict(BaseModel):
    """ê²€ì¦ ê²°ë¡ """
    grade: str = Field(..., description="ë“±ê¸‰ (ë§¤ìš° ìš°ìˆ˜/ìš°ìˆ˜/ì–‘í˜¸/ë³´í†µ/ë¯¸í¡)")
    can_replace_db: bool = Field(..., description="DB ëŒ€ì²´ ê°€ëŠ¥ ì—¬ë¶€")
    explanation: str = Field(..., description="ì„¤ëª…")
    recommendations: List[str] = Field(..., description="ê¶Œì¥ ì‚¬í•­")


class AIvsDBComparisonResponse(BaseModel):
    """AI vs DB í†µê³„ ë¹„êµ ì‘ë‹µ"""
    project_uuid: str = Field(..., description="í”„ë¡œì íŠ¸ UUID")
    analysis_period_hours: int = Field(..., description="ë¶„ì„ ê¸°ê°„ (ì‹œê°„)")
    sample_size: int = Field(..., description="ì‚¬ìš©ëœ ìƒ˜í”Œ í¬ê¸°")
    analyzed_at: datetime = Field(..., description="ë¶„ì„ ì‹œì ")

    db_statistics: DBStatistics = Field(..., description="DB ì§ì ‘ ì¡°íšŒ ê²°ê³¼")
    ai_statistics: AIStatistics = Field(..., description="AI ì¶”ë¡  ê²°ê³¼")
    accuracy_metrics: AccuracyMetrics = Field(..., description="ì •í™•ë„ ì§€í‘œ")
    verdict: ComparisonVerdict = Field(..., description="ê²€ì¦ ê²°ë¡ ")

    technical_highlights: List[str] = Field(..., description="ê¸°ìˆ ì  ì–´í•„ í¬ì¸íŠ¸")


class HourlyDataPoint(BaseModel):
    """ì‹œê°„ëŒ€ë³„ ë°ì´í„° í¬ì¸íŠ¸"""
    hour: str = Field(..., description="ì‹œê°„ (ISO format)")
    total: int = Field(..., description="ì´ ë¡œê·¸ ìˆ˜")
    error: int = Field(..., description="ERROR ìˆ˜")
    warn: int = Field(..., description="WARN ìˆ˜")
    info: int = Field(..., description="INFO ìˆ˜")


class HourlyStatisticsResponse(BaseModel):
    """ì‹œê°„ëŒ€ë³„ í†µê³„ ì‘ë‹µ"""
    project_uuid: str = Field(..., description="í”„ë¡œì íŠ¸ UUID")
    analysis_period_hours: int = Field(..., description="ë¶„ì„ ê¸°ê°„")
    total_logs: int = Field(..., description="ì´ ë¡œê·¸ ìˆ˜")
    error_rate: float = Field(..., description="ì—ëŸ¬ìœ¨ (%)")
    peak_hour: str = Field(..., description="í”¼í¬ ì‹œê°„")
    peak_count: int = Field(..., description="í”¼í¬ ì‹œê°„ ë¡œê·¸ ìˆ˜")
    hourly_data: List[HourlyDataPoint] = Field(..., description="ì‹œê°„ëŒ€ë³„ ë°ì´í„°")


@router.get("/statistics/compare", response_model=AIvsDBComparisonResponse)
async def compare_ai_vs_db(
    project_uuid: str = Query(..., description="í”„ë¡œì íŠ¸ UUID"),
    time_hours: int = Query(24, ge=1, le=168, description="ë¶„ì„ ê¸°ê°„ (ì‹œê°„, ê¸°ë³¸ 24ì‹œê°„)"),
    sample_size: int = Query(100, ge=10, le=500, description="AI ë¶„ì„ìš© ìƒ˜í”Œ í¬ê¸°")
) -> AIvsDBComparisonResponse:
    """
    AI vs DB í†µê³„ ë¹„êµë¥¼ ìˆ˜í–‰í•˜ì—¬ LLMì˜ DB ëŒ€ì²´ ì—­ëŸ‰ì„ ê²€ì¦í•©ë‹ˆë‹¤.

    **ê²€ì¦ ëª©í‘œ:**
    - LLMì´ ë¡œê·¸ ìƒ˜í”Œë§Œìœ¼ë¡œ ì „ì²´ í†µê³„ë¥¼ ì •í™•íˆ ì¶”ë¡ í•  ìˆ˜ ìˆëŠ”ê°€?
    - AIê°€ ì‚¬ëŒ(ë˜ëŠ” DB ì¿¼ë¦¬)ì„ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ì—­ëŸ‰ì„ ë³´ìœ í–ˆëŠ”ê°€?

    **ê¸°ìˆ ì  ì–´í•„ í¬ì¸íŠ¸:**
    - Temperature 0.1ë¡œ ì¼ê´€ëœ ì¶”ë¡  ë³´ì¥
    - Structured Outputìœ¼ë¡œ í˜•ì‹ ì˜¤ë¥˜ ë°©ì§€
    - ìë™í™”ëœ ì •í™•ë„ ì¸¡ì •ìœ¼ë¡œ ì‹ ë¢°ì„± ê²€ì¦

    **ë°˜í™˜ ë°ì´í„°:**
    - DB ì§ì ‘ ì¡°íšŒ ê²°ê³¼ (Ground Truth)
    - AI ì¶”ë¡  ê²°ê³¼
    - ì •í™•ë„ ì§€í‘œ (ì˜¤ì°¨ìœ¨)
    - ê²€ì¦ ê²°ë¡  (DB ëŒ€ì²´ ê°€ëŠ¥ ì—¬ë¶€)

    **ì •í™•ë„ ê¸°ì¤€:**
    - 95% ì´ìƒ: ë§¤ìš° ìš°ìˆ˜ (í”„ë¡œë•ì…˜ ì‚¬ìš© ê°€ëŠ¥)
    - 90% ì´ìƒ: ìš°ìˆ˜ (ëŒ€ë¶€ë¶„ ì—…ë¬´ì— í™œìš© ê°€ëŠ¥)
    - 80% ì´ìƒ: ì–‘í˜¸ (ë³´ì¡° ë„êµ¬ë¡œ ìœ ìš©)
    - 70% ì´ìƒ: ë³´í†µ (ê°œì„  í•„ìš”)
    - 70% ë¯¸ë§Œ: ë¯¸í¡ (ì¬ê²€í†  í•„ìš”)
    """
    logger.info(f"ğŸ¤– AI vs DB í†µê³„ ë¹„êµ ì‹œì‘: project_uuid={project_uuid}, time_hours={time_hours}, sample_size={sample_size}")

    try:
        # 1. DBì—ì„œ ì§ì ‘ í†µê³„ ì¡°íšŒ
        logger.debug(f"1ë‹¨ê³„: DB í†µê³„ ì¡°íšŒ ì‹œì‘")
        db_stats = _get_db_statistics(project_uuid, time_hours)
        logger.info(f"âœ… DB í†µê³„ ì¡°íšŒ ì™„ë£Œ: total_logs={db_stats.get('total_logs', 0)}")

        if db_stats["total_logs"] == 0:
            logger.warning(f"âš ï¸ ë¡œê·¸ ë°ì´í„° ì—†ìŒ: project_uuid={project_uuid}, time_hours={time_hours}")
            raise HTTPException(
                status_code=404,
                detail=f"ìµœê·¼ {time_hours}ì‹œê°„ ë™ì•ˆ ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            )

        # 2. ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ (ì¸µí™” ìƒ˜í”Œë§ ì‚¬ìš©)
        logger.debug(f"2ë‹¨ê³„: ì¸µí™” ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ ì‹œì‘")
        level_counts = {
            "ERROR": db_stats["error_count"],
            "WARN": db_stats["warn_count"],
            "INFO": db_stats["info_count"]
        }
        log_samples = _get_stratified_log_samples(project_uuid, time_hours, sample_size, level_counts)
        logger.info(f"âœ… ì¸µí™” ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ ì™„ë£Œ: sample_count={len(log_samples)}")

        if not log_samples:
            logger.error(f"ğŸ”´ ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ ì‹¤íŒ¨: project_uuid={project_uuid}")
            raise HTTPException(
                status_code=500,
                detail="ë¡œê·¸ ìƒ˜í”Œì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )

        # 3. LLM ê¸°ë°˜ í†µê³„ ê²€ì¦ (ì‹¤ì œ ê°œìˆ˜ íŒíŠ¸ ì œê³µ)
        logger.debug(f"3ë‹¨ê³„: LLM í†µê³„ ê²€ì¦ ì‹œì‘")
        ai_stats = _llm_estimate_statistics(log_samples, db_stats["total_logs"], time_hours, level_counts)
        logger.info(f"âœ… LLM ê²€ì¦ ì™„ë£Œ: estimated_total={ai_stats.get('estimated_total_logs', 0)}, confidence={ai_stats.get('confidence_score', 0)}")

        # 4. ì •í™•ë„ ê³„ì‚°
        logger.debug(f"4ë‹¨ê³„: ì •í™•ë„ ê³„ì‚° ì‹œì‘")
        accuracy_metrics = _calculate_accuracy(db_stats, ai_stats)
        logger.info(f"âœ… ì •í™•ë„ ê³„ì‚° ì™„ë£Œ: overall_accuracy={accuracy_metrics.get('overall_accuracy', 0)}%")

        # 5. ê²€ì¦ ê²°ë¡  ìƒì„±
        overall = accuracy_metrics["overall_accuracy"]
        if overall >= 95:
            grade = "ë§¤ìš° ìš°ìˆ˜"
            can_replace = True
            explanation = "ì˜¤ì°¨ìœ¨ 5% ë¯¸ë§Œìœ¼ë¡œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‹ ë¢°ì„± ìˆê²Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
            recommendations = [
                "í”„ë¡œë•ì…˜ í™˜ê²½ ì ìš© ê¶Œì¥",
                "ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ AI ê¸°ë°˜ ë¶„ì„ ë„ì… ê°€ëŠ¥",
                "DB ë¶€í•˜ ê°ì†Œë¥¼ ìœ„í•œ AI ìºì‹± ë ˆì´ì–´ êµ¬ì¶•"
            ]
        elif overall >= 90:
            grade = "ìš°ìˆ˜"
            can_replace = True
            explanation = "ì˜¤ì°¨ìœ¨ 10% ë¯¸ë§Œìœ¼ë¡œ ëŒ€ë¶€ë¶„ì˜ ë¶„ì„ ì—…ë¬´ì— í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
            recommendations = [
                "ë³´ì¡° ë¶„ì„ ë„êµ¬ë¡œ ì¦‰ì‹œ í™œìš© ê°€ëŠ¥",
                "ë¹„ì‹¤ì‹œê°„ ë¦¬í¬íŠ¸ ìƒì„±ì— AI í™œìš©",
                "ì¶”ê°€ í”„ë¡¬í”„íŠ¸ íŠœë‹ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ ê°€ëŠ¥"
            ]
        elif overall >= 80:
            grade = "ì–‘í˜¸"
            can_replace = False
            explanation = "ì˜¤ì°¨ìœ¨ 20% ë¯¸ë§Œìœ¼ë¡œ íŠ¸ë Œë“œ ë¶„ì„ê³¼ ì´ìƒ íƒì§€ì— í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
            recommendations = [
                "íŠ¸ë Œë“œ ë¶„ì„ ë³´ì¡° ë„êµ¬ë¡œ í™œìš©",
                "ì´ìƒ íƒì§€ ì•Œë¦¼ì— AI ì¶”ë¡  ê²°í•©",
                "ìƒ˜í”Œ í¬ê¸° ì¦ê°€ë¡œ ì •í™•ë„ í–¥ìƒ"
            ]
        elif overall >= 70:
            grade = "ë³´í†µ"
            can_replace = False
            explanation = "ì˜¤ì°¨ìœ¨ì´ ë†’ì•„ ì¶”ê°€ íŠœë‹ì´ í•„ìš”í•©ë‹ˆë‹¤."
            recommendations = [
                "í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°œì„  í•„ìš”",
                "ìƒ˜í”Œë§ ì „ëµ ì¬ê²€í† ",
                "Few-shot ì˜ˆì œ ì¶”ê°€ ê³ ë ¤"
            ]
        else:
            grade = "ë¯¸í¡"
            can_replace = False
            explanation = "ì •í™•ë„ê°€ ë‚®ì•„ ê·¼ë³¸ì ì¸ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."
            recommendations = [
                "LLM ëª¨ë¸ ì—…ê·¸ë ˆì´ë“œ ê³ ë ¤",
                "ë°ì´í„° ì „ì²˜ë¦¬ ë¡œì§ ê°œì„ ",
                "RAG íŒ¨í„´ ë„ì… ê²€í† "
            ]

        verdict = ComparisonVerdict(
            grade=grade,
            can_replace_db=can_replace,
            explanation=explanation,
            recommendations=recommendations
        )

        # 6. ê¸°ìˆ ì  ì–´í•„ í¬ì¸íŠ¸
        technical_highlights = [
            f"Temperature 0.1ë¡œ ì¼ê´€ëœ ì¶”ë¡  (ê¸°ë³¸ê°’ ëŒ€ë¹„ 7ë°° ë‚®ìŒ)",
            f"ì¸µí™” ìƒ˜í”Œë§ìœ¼ë¡œ í¬ì†Œ ì´ë²¤íŠ¸(ERROR/WARN) í¬ì°© ë³´ì¥",
            f"ìƒ˜í”Œ {len(log_samples)}ê°œë¡œ {db_stats['total_logs']:,}ê°œ í†µê³„ ì¶”ë¡ ",
            f"ì¢…í•© ì •í™•ë„ {overall:.1f}% ë‹¬ì„±",
            "Structured Outputìœ¼ë¡œ JSON ìŠ¤í‚¤ë§ˆ ê°•ì œ",
            "ìë™í™”ëœ ë‹¤ì°¨ì› ì •í™•ë„ ê²€ì¦",
            "MCP/ë©€í‹°ëª¨ë‹¬ ì—†ì´ ë‹¨ì¼ LLMìœ¼ë¡œ êµ¬í˜„"
        ]

        # 7. ì‘ë‹µ êµ¬ì„±
        return AIvsDBComparisonResponse(
            project_uuid=project_uuid,
            analysis_period_hours=time_hours,
            sample_size=len(log_samples),
            analyzed_at=datetime.utcnow(),
            db_statistics=DBStatistics(
                total_logs=db_stats["total_logs"],
                error_count=db_stats["error_count"],
                warn_count=db_stats["warn_count"],
                info_count=db_stats["info_count"],
                error_rate=db_stats["error_rate"],
                peak_hour=db_stats["peak_hour"],
                peak_count=db_stats["peak_count"]
            ),
            ai_statistics=AIStatistics(
                estimated_total_logs=ai_stats.get("estimated_total_logs", 0),
                estimated_error_count=ai_stats.get("estimated_error_count", 0),
                estimated_warn_count=ai_stats.get("estimated_warn_count", 0),
                estimated_info_count=ai_stats.get("estimated_info_count", 0),
                estimated_error_rate=ai_stats.get("estimated_error_rate", 0.0),
                confidence_score=ai_stats.get("confidence_score", 0),
                reasoning=ai_stats.get("reasoning", "N/A")
            ),
            accuracy_metrics=AccuracyMetrics(
                total_logs_accuracy=accuracy_metrics["total_logs_accuracy"],
                error_count_accuracy=accuracy_metrics["error_count_accuracy"],
                warn_count_accuracy=accuracy_metrics["warn_count_accuracy"],
                info_count_accuracy=accuracy_metrics["info_count_accuracy"],
                error_rate_accuracy=accuracy_metrics["error_rate_accuracy"],
                overall_accuracy=accuracy_metrics["overall_accuracy"],
                ai_confidence=accuracy_metrics["ai_confidence"]
            ),
            verdict=verdict,
            technical_highlights=technical_highlights
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ğŸ”´ AI vs DB í†µê³„ ë¹„êµ ì¤‘ ì˜ˆì™¸ ë°œìƒ: project_uuid={project_uuid}, error={str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"AI vs DB í†µê³„ ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )


@router.get("/statistics/hourly", response_model=HourlyStatisticsResponse)
async def get_hourly_statistics(
    project_uuid: str = Query(..., description="í”„ë¡œì íŠ¸ UUID"),
    time_hours: int = Query(24, ge=1, le=168, description="ë¶„ì„ ê¸°ê°„ (ì‹œê°„)")
) -> HourlyStatisticsResponse:
    """
    ì‹œê°„ëŒ€ë³„ ë¡œê·¸ í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

    1ì‹œê°„ ë‹¨ìœ„ë¡œ ë¡œê·¸ ë¶„í¬ë¥¼ í™•ì¸í•˜ì—¬ íŠ¸ë Œë“œì™€ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    """
    try:
        db_stats = _get_db_statistics(project_uuid, time_hours)

        if db_stats["total_logs"] == 0:
            raise HTTPException(
                status_code=404,
                detail=f"ìµœê·¼ {time_hours}ì‹œê°„ ë™ì•ˆ ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            )

        hourly_data = [
            HourlyDataPoint(
                hour=h["hour"],
                total=h["total"],
                error=h["error"],
                warn=h["warn"],
                info=h["info"]
            )
            for h in db_stats["hourly_data"]
        ]

        return HourlyStatisticsResponse(
            project_uuid=project_uuid,
            analysis_period_hours=time_hours,
            total_logs=db_stats["total_logs"],
            error_rate=db_stats["error_rate"],
            peak_hour=db_stats["peak_hour"],
            peak_count=db_stats["peak_count"],
            hourly_data=hourly_data
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ì‹œê°„ëŒ€ë³„ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )
