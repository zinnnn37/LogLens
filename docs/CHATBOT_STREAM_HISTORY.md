# Chatbot Stream & History êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“š ëª©ì°¨
1. [ê°œìš”](#1-ê°œìš”)
2. [Stream êµ¬í˜„ (Fetch API + ReadableStream)](#2-stream-êµ¬í˜„)
3. [Chat History êµ¬í˜„](#3-chat-history-êµ¬í˜„)
4. [Stream + History í†µí•©](#4-stream--history-í†µí•©)
5. [ì‹¤ìŠµ ê°€ì´ë“œ](#5-ì‹¤ìŠµ-ê°€ì´ë“œ)
6. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#6-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## 1. ê°œìš”

### í˜„ì¬ ìƒíƒœ vs ê°œì„  í›„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              í˜„ì¬ (Non-Stream, No History)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì‚¬ìš©ì: "ìµœê·¼ ì—ëŸ¬ ì•Œë ¤ì¤˜"
   â†“
[Loading... 25ì´ˆ ëŒ€ê¸°] â³
   â†“
ì±—ë´‡: "NPE 3ê±´, DB íƒ€ì„ì•„ì›ƒ 2ê±´ ë°œìƒí–ˆìŠµë‹ˆë‹¤"

ì‚¬ìš©ì: "ê·¸ ì¤‘ ê°€ì¥ ì‹¬ê°í•œ ê±´?"
   â†“
ì±—ë´‡: "ë¬´ì—‡ì„ ë§ì”€í•˜ì‹œëŠ”ì§€ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤" âŒ

ë¬¸ì œì :
- ê¸´ ëŒ€ê¸° ì‹œê°„ (20-30ì´ˆ)
- ì´ì „ ëŒ€í™” ë§¥ë½ ì´í•´ ë¶ˆê°€
- ì—°ì† ëŒ€í™” ë¶ˆê°€ëŠ¥


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        ê°œì„  í›„ (Stream + History)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ì‚¬ìš©ì: "ìµœê·¼ ì—ëŸ¬ ì•Œë ¤ì¤˜"
   â†“
ì±—ë´‡: "N" (0.5ì´ˆ)
ì±—ë´‡: "PE 3ê±´" (1ì´ˆ)
ì±—ë´‡: ", DB íƒ€ì„ì•„ì›ƒ 2ê±´ ë°œìƒ" (1.5ì´ˆ)
ì±—ë´‡: "í–ˆìŠµë‹ˆë‹¤" (2ì´ˆ) âœ… ì‹¤ì‹œê°„ íƒ€ì´í•‘

ì‚¬ìš©ì: "ê·¸ ì¤‘ ê°€ì¥ ì‹¬ê°í•œ ê±´?"
   â†“
ì±—ë´‡: "ì•ì„œ ë§ì”€ë“œë¦° DB íƒ€ì„ì•„ì›ƒì´ ê°€ì¥ ì‹¬ê°í•©ë‹ˆë‹¤..." âœ… ë§¥ë½ ì´í•´

ì¥ì :
- ì¦‰ê°ì ì¸ í”¼ë“œë°± (0.5ì´ˆ ì´ë‚´)
- ì´ì „ ëŒ€í™” ê¸°ì–µ
- ìì—°ìŠ¤ëŸ¬ìš´ ì—°ì† ëŒ€í™”
```

---

## 2. Stream êµ¬í˜„

### 2.1. ë°±ì—”ë“œ êµ¬í˜„ (FastAPI)

#### Step 1: í•„ìš”í•œ import ì¶”ê°€

**íŒŒì¼**: `app/api/v1/chatbot.py`

```python
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
import json
from app.services.chatbot_service import chatbot_service
from app.models.chat import ChatRequest, ChatResponse
```

#### Step 2: Stream ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€

```python
@router.post("/chatbot/ask/stream")
async def ask_chatbot_stream(request: ChatRequest):
    """
    Stream ë°©ì‹ìœ¼ë¡œ ë‹µë³€ ìƒì„±

    SSE (Server-Sent Events) í˜•ì‹ìœ¼ë¡œ ì‹¤ì‹œê°„ ë‹µë³€ ì „ì†¡:
    - ê° ì²­í¬ë¥¼ "data: {content}\n\n" í˜•ì‹ìœ¼ë¡œ ì „ì†¡
    - ì™„ë£Œ ì‹œ "data: [DONE]\n\n" ì „ì†¡
    - ì—ëŸ¬ ì‹œ "data: {\"error\": \"...\"}\n\n" ì „ì†¡

    Args:
        request: ChatRequest (question, project_id, filters, time_range)

    Returns:
        StreamingResponse (text/event-stream)
    """
    async def generate():
        try:
            # 1. ì§ˆë¬¸ ì„ë² ë”© ìƒì„±
            question_vector = await embedding_service.embed_query(request.question)

            # 2. ìºì‹œ ì²´í¬ (2-stage validation)
            cache_candidates = await similarity_service.find_similar_questions(
                question_vector=question_vector,
                k=settings.CACHE_CANDIDATE_SIZE,
                project_id=request.project_id
            )

            # ìºì‹œëœ ë‹µë³€ì´ ìˆìœ¼ë©´ í•œë²ˆì— ì „ì†¡
            for candidate in cache_candidates:
                if candidate["score"] >= chatbot_service.threshold:
                    if chatbot_service._is_cache_valid(candidate):
                        if chatbot_service._metadata_matches(
                            candidate.get("metadata", {}),
                            request.filters,
                            request.time_range,
                            request.project_id
                        ):
                            # ìºì‹œ íˆíŠ¸ - ì „ì²´ ë‹µë³€ ì „ì†¡
                            cached_answer = candidate["answer"]
                            yield f"data: {cached_answer}\n\n"
                            yield "data: [DONE]\n\n"
                            return

            # 3. ìºì‹œ ë¯¸ìŠ¤ - ê´€ë ¨ ë¡œê·¸ ê²€ìƒ‰
            relevant_logs_data = await similarity_service.find_similar_logs(
                log_vector=question_vector,
                k=chatbot_service.max_context,
                filters=request.filters,
                project_id=request.project_id,
            )

            # 4. ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            context_logs = chatbot_service._format_context_logs(relevant_logs_data)

            # 5. LLM ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
            full_answer = ""
            async for chunk in chatbot_chain.astream({
                "context_logs": context_logs,
                "question": request.question,
            }):
                content = chunk.content
                full_answer += content

                # SSE í˜•ì‹ìœ¼ë¡œ ì²­í¬ ì „ì†¡
                yield f"data: {content}\n\n"

            # 6. ì™„ë£Œ ì‹ í˜¸
            yield "data: [DONE]\n\n"

            # 7. QA ìºì‹± (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¹„ë™ê¸° ì‹¤í–‰)
            related_log_ids = [log["log_id"] for log in relevant_logs_data]
            ttl = chatbot_service._calculate_ttl(request.question, request.time_range)

            # asyncio.create_taskë¡œ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ í›„)
            import asyncio
            asyncio.create_task(chatbot_service._cache_qa_pair(
                question=request.question,
                question_vector=question_vector,
                answer=full_answer,
                related_log_ids=related_log_ids,
                metadata={
                    "project_id": request.project_id,
                    "filters": request.filters,
                    "time_range": request.time_range,
                },
                ttl=ttl
            ))

        except Exception as e:
            # ì—ëŸ¬ ì „ì†¡
            error_data = json.dumps({"error": str(e)})
            yield f"data: {error_data}\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # Nginx ë²„í¼ë§ ë¹„í™œì„±í™”
        }
    )
```

#### í•µì‹¬ í¬ì¸íŠ¸

**SSE í˜•ì‹**:
```
data: Hello
data:  world
data: !

data: [DONE]

```

ê° ë©”ì‹œì§€ëŠ” `data: {content}\n\n`ìœ¼ë¡œ êµ¬ì„±:
- `data: `: í”„ë¦¬í”½ìŠ¤
- `{content}`: ì‹¤ì œ ë‚´ìš©
- `\n\n`: ë©”ì‹œì§€ êµ¬ë¶„ì (2ê°œì˜ ì¤„ë°”ê¿ˆ)

---

### 2.2. í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„ (React)

#### ChatBot ì»´í¬ë„ŒíŠ¸

**íŒŒì¼**: `src/components/ChatBot.jsx`

```jsx
import { useState } from 'react';
import './ChatBot.css';

function ChatBot() {
    const [messages, setMessages] = useState([]);
    const [currentAnswer, setCurrentAnswer] = useState('');
    const [isStreaming, setIsStreaming] = useState(false);
    const [input, setInput] = useState('');
    const [error, setError] = useState(null);

    /**
     * Stream ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸ ì „ì†¡ ë° ì‘ë‹µ ìˆ˜ì‹ 
     */
    const askQuestionStream = async (question) => {
        // ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        const userMessage = {
            type: 'user',
            content: question,
            timestamp: new Date()
        };
        setMessages(prev => [...prev, userMessage]);

        // ì´ˆê¸°í™”
        setCurrentAnswer('');
        setIsStreaming(true);
        setError(null);

        try {
            // Fetch APIë¡œ POST ìš”ì²­
            const response = await fetch('/api/v1/chatbot/ask/stream', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    question: question,
                    project_id: 'proj-123', // ì‹¤ì œ í”„ë¡œì íŠ¸ ID ì‚¬ìš©
                    filters: null,
                    time_range: null
                })
            });

            // HTTP ì—ëŸ¬ ì²´í¬
            if (!response.ok) {
                throw new Error(`HTTP ${response.status}: ${response.statusText}`);
            }

            // ReadableStream ì½ê¸°
            const reader = response.body.getReader();
            const decoder = new TextDecoder('utf-8');

            let buffer = ''; // ë¶ˆì™„ì „í•œ ì²­í¬ë¥¼ ìœ„í•œ ë²„í¼
            let fullAnswer = ''; // ì „ì²´ ë‹µë³€ ëˆ„ì 

            while (true) {
                const { done, value } = await reader.read();

                if (done) {
                    console.log('Stream ì™„ë£Œ');
                    break;
                }

                // Uint8Arrayë¥¼ ë¬¸ìì—´ë¡œ ë””ì½”ë”©
                const chunk = decoder.decode(value, { stream: true });
                buffer += chunk;

                // ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
                const lines = buffer.split('\n');

                // ë§ˆì§€ë§‰ ë¼ì¸ì€ ë¶ˆì™„ì „í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë²„í¼ì— ë³´ê´€
                buffer = lines.pop() || '';

                // ê° ë¼ì¸ ì²˜ë¦¬
                for (const line of lines) {
                    // SSE í˜•ì‹: "data: {content}"
                    if (line.startsWith('data: ')) {
                        const data = line.slice(6); // 'data: ' ì œê±°

                        // ì¢…ë£Œ ì‹ í˜¸ ì²´í¬
                        if (data === '[DONE]') {
                            console.log('LLM ìƒì„± ì™„ë£Œ');
                            continue;
                        }

                        // ì—ëŸ¬ ì²´í¬
                        try {
                            const parsed = JSON.parse(data);
                            if (parsed.error) {
                                throw new Error(parsed.error);
                            }
                        } catch (e) {
                            // JSONì´ ì•„ë‹ˆë©´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
                        }

                        // ë‹µë³€ ëˆ„ì  ë° í™”ë©´ ì—…ë°ì´íŠ¸
                        fullAnswer += data;
                        setCurrentAnswer(fullAnswer);
                    }
                }
            }

            // ë´‡ ë©”ì‹œì§€ ì¶”ê°€ (ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„)
            const botMessage = {
                type: 'bot',
                content: fullAnswer,
                timestamp: new Date(),
                fromCache: false // Streamì€ ìºì‹œ ì•„ë‹˜
            };
            setMessages(prev => [...prev, botMessage]);

        } catch (err) {
            console.error('Stream ì—ëŸ¬:', err);
            setError(err.message);

            // ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
            const errorMessage = {
                type: 'bot',
                content: `ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${err.message}`,
                timestamp: new Date(),
                isError: true
            };
            setMessages(prev => [...prev, errorMessage]);

        } finally {
            setIsStreaming(false);
            setCurrentAnswer('');
            setInput('');
        }
    };

    const handleSubmit = (e) => {
        e.preventDefault();
        if (input.trim() && !isStreaming) {
            askQuestionStream(input.trim());
        }
    };

    return (
        <div className="chatbot-container">
            <div className="chatbot-header">
                <h2>ë¡œê·¸ ë¶„ì„ ì±—ë´‡</h2>
            </div>

            <div className="messages-container">
                {/* ì´ì „ ë©”ì‹œì§€ë“¤ */}
                {messages.map((msg, idx) => (
                    <div key={idx} className={`message ${msg.type} ${msg.isError ? 'error' : ''}`}>
                        <div className="message-content">
                            {msg.content}
                        </div>
                        <div className="message-timestamp">
                            {msg.timestamp.toLocaleTimeString('ko-KR')}
                        </div>
                    </div>
                ))}

                {/* í˜„ì¬ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¸ ë‹µë³€ */}
                {isStreaming && currentAnswer && (
                    <div className="message bot streaming">
                        <div className="message-content">
                            {currentAnswer}
                            <span className="typing-cursor">â–Š</span>
                        </div>
                    </div>
                )}

                {/* ì—ëŸ¬ í‘œì‹œ */}
                {error && (
                    <div className="error-banner">
                        âš ï¸ {error}
                    </div>
                )}
            </div>

            <form onSubmit={handleSubmit} className="input-form">
                <input
                    type="text"
                    value={input}
                    onChange={(e) => setInput(e.target.value)}
                    placeholder="ë¡œê·¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."
                    disabled={isStreaming}
                    className="chat-input"
                />
                <button
                    type="submit"
                    disabled={isStreaming || !input.trim()}
                    className="send-button"
                >
                    {isStreaming ? 'ë‹µë³€ ì¤‘...' : 'ì „ì†¡'}
                </button>
            </form>
        </div>
    );
}

export default ChatBot;
```

#### CSS ìŠ¤íƒ€ì¼

**íŒŒì¼**: `src/components/ChatBot.css`

```css
.chatbot-container {
    display: flex;
    flex-direction: column;
    height: 600px;
    max-width: 800px;
    margin: 0 auto;
    border: 1px solid #ddd;
    border-radius: 8px;
    overflow: hidden;
    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
}

.chatbot-header {
    background: #4CAF50;
    color: white;
    padding: 1rem;
    text-align: center;
}

.messages-container {
    flex: 1;
    overflow-y: auto;
    padding: 1rem;
    background: #f9f9f9;
}

.message {
    margin-bottom: 1rem;
    padding: 0.75rem;
    border-radius: 8px;
    max-width: 70%;
    word-wrap: break-word;
}

.message.user {
    background: #2196F3;
    color: white;
    margin-left: auto;
    text-align: right;
}

.message.bot {
    background: white;
    border: 1px solid #ddd;
}

.message.error {
    background: #ffebee;
    border: 1px solid #f44336;
    color: #d32f2f;
}

.message.streaming {
    border: 2px solid #4CAF50;
}

.message-content {
    white-space: pre-wrap;
    font-size: 0.95rem;
    line-height: 1.5;
}

.message-timestamp {
    font-size: 0.75rem;
    color: #888;
    margin-top: 0.5rem;
}

/* íƒ€ì´í•‘ ì»¤ì„œ ì• ë‹ˆë©”ì´ì…˜ */
@keyframes blink {
    0%, 50% { opacity: 1; }
    51%, 100% { opacity: 0; }
}

.typing-cursor {
    animation: blink 1s infinite;
    font-weight: bold;
    color: #4CAF50;
    margin-left: 2px;
}

.input-form {
    display: flex;
    gap: 0.5rem;
    padding: 1rem;
    background: white;
    border-top: 1px solid #ddd;
}

.chat-input {
    flex: 1;
    padding: 0.75rem;
    border: 1px solid #ddd;
    border-radius: 4px;
    font-size: 1rem;
}

.chat-input:disabled {
    background: #f0f0f0;
    cursor: not-allowed;
}

.send-button {
    padding: 0.75rem 1.5rem;
    background: #4CAF50;
    color: white;
    border: none;
    border-radius: 4px;
    cursor: pointer;
    font-size: 1rem;
    font-weight: bold;
}

.send-button:hover:not(:disabled) {
    background: #45a049;
}

.send-button:disabled {
    background: #ccc;
    cursor: not-allowed;
}

.error-banner {
    background: #ffebee;
    border: 1px solid #f44336;
    color: #d32f2f;
    padding: 0.75rem;
    border-radius: 4px;
    margin-bottom: 1rem;
}
```

---

## 3. Chat History êµ¬í˜„

### 3.1. ê°œë…

**Chat History**ëŠ” ì´ì „ ëŒ€í™” ë‚´ìš©ì„ LLMì— ì „ë‹¬í•˜ì—¬ ë¬¸ë§¥ì„ ì´í•´í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

```
ëŒ€í™” íë¦„:

[Turn 1]
User: "ìµœê·¼ ì—ëŸ¬ ì•Œë ¤ì¤˜"
Bot: "NPE 3ê±´, DB íƒ€ì„ì•„ì›ƒ 2ê±´ ë°œìƒí–ˆìŠµë‹ˆë‹¤"

[Turn 2]
User: "ê·¸ ì¤‘ ê°€ì¥ ì‹¬ê°í•œ ê±´?"
                 â†‘
            ëŒ€ëª…ì‚¬ "ê·¸"ê°€ ë¬´ì—‡ì„ ê°€ë¦¬í‚¤ëŠ”ì§€?
            â†’ Turn 1ì˜ ë§¥ë½ì´ í•„ìš”!

History ì—†ì´:
Bot: "ë¬´ì—‡ì„ ë§ì”€í•˜ì‹œëŠ”ì§€ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤" âŒ

History ìˆìœ¼ë©´:
LLM Input:
  [History]
  - User: "ìµœê·¼ ì—ëŸ¬ ì•Œë ¤ì¤˜"
  - Bot: "NPE 3ê±´, DB íƒ€ì„ì•„ì›ƒ 2ê±´ ë°œìƒí–ˆìŠµë‹ˆë‹¤"

  [Current]
  - User: "ê·¸ ì¤‘ ê°€ì¥ ì‹¬ê°í•œ ê±´?"

Bot: "ì•ì„œ ë§ì”€ë“œë¦° DB íƒ€ì„ì•„ì›ƒì´ ê°€ì¥ ì‹¬ê°í•©ë‹ˆë‹¤" âœ…
```

### 3.2. ë°±ì—”ë“œ êµ¬í˜„

#### Step 1: ëª¨ë¸ ìˆ˜ì •

**íŒŒì¼**: `app/models/chat.py`

```python
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import datetime

class ChatMessage(BaseModel):
    """ë‹¨ì¼ ì±„íŒ… ë©”ì‹œì§€"""
    role: str = Field(..., description="'user' ë˜ëŠ” 'assistant'")
    content: str = Field(..., description="ë©”ì‹œì§€ ë‚´ìš©")

class ChatRequest(BaseModel):
    """Chatbot question request with history support"""

    question: str = Field(..., description="User's question about logs")
    project_id: str = Field(..., description="Project ID for multi-tenancy isolation")

    # History ì¶”ê°€
    chat_history: Optional[List[ChatMessage]] = Field(
        default=None,
        description="Previous conversation history"
    )

    filters: Optional[Dict[str, Any]] = Field(None, description="Optional filters for log search")
    time_range: Optional[Dict[str, str]] = Field(
        None, description="Time range filter (start, end)"
    )

    class Config:
        json_schema_extra = {
            "example": {
                "question": "ê·¸ ì¤‘ ê°€ì¥ ì‹¬ê°í•œ ê±´?",
                "project_id": "proj-123",
                "chat_history": [
                    {"role": "user", "content": "ìµœê·¼ ì—ëŸ¬ ì•Œë ¤ì¤˜"},
                    {"role": "assistant", "content": "NPE 3ê±´, DB íƒ€ì„ì•„ì›ƒ 2ê±´ ë°œìƒí–ˆìŠµë‹ˆë‹¤"}
                ],
                "filters": None,
                "time_range": None,
            }
        }
```

#### Step 2: ì²´ì¸ ìˆ˜ì • (LangChain)

**íŒŒì¼**: `app/chains/chatbot_chain.py`

```python
"""
LangChain chain for chatbot QA with history support
"""

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from app.core.config import settings


# Initialize LLM
llm = ChatOpenAI(
    model=settings.LLM_MODEL,
    temperature=0.7,
    api_key=settings.OPENAI_API_KEY,
    base_url=settings.OPENAI_BASE_URL,
)

# Prompt template with history support
chatbot_prompt = ChatPromptTemplate.from_messages([
    (
        "system",
        """You are a helpful log analysis assistant. Answer questions about application logs based on the provided context.

Guidelines:
- Use the context logs to provide accurate, specific answers
- Consider the conversation history when answering
- If the context doesn't contain relevant information, say so clearly
- Provide actionable insights when possible
- Use clear, concise language
- Include relevant log details (timestamps, error counts, patterns)
- Answer in Korean if the question is in Korean, English if in English"""
    ),

    # ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (ë™ì )
    MessagesPlaceholder(variable_name="chat_history", optional=True),

    (
        "human",
        """Context - Recent Logs:
{context_logs}

Question: {question}

Answer:"""
    ),
])

# Create the chain
chatbot_chain = chatbot_prompt | llm
```

**í•µì‹¬**: `MessagesPlaceholder`
- `variable_name="chat_history"`: ì´ ì´ë¦„ìœ¼ë¡œ íˆìŠ¤í† ë¦¬ë¥¼ ë°›ìŒ
- `optional=True`: íˆìŠ¤í† ë¦¬ê°€ ì—†ì–´ë„ ë™ì‘ (ì²« ëŒ€í™”)

#### Step 3: ì„œë¹„ìŠ¤ ìˆ˜ì •

**íŒŒì¼**: `app/services/chatbot_service.py`

ê¸°ì¡´ `ask()` ë©”ì„œë“œ ìˆ˜ì •:

```python
from langchain_core.messages import HumanMessage, AIMessage

async def ask(
    self,
    question: str,
    project_id: str,
    chat_history: Optional[List[Dict[str, str]]] = None,
    filters: Optional[Dict[str, Any]] = None,
    time_range: Optional[Dict[str, str]] = None,
) -> ChatResponse:
    """
    Answer a question with chat history support

    Args:
        question: User's question
        project_id: Project ID
        chat_history: Previous conversation (list of {role, content})
        filters: Optional filters
        time_range: Optional time range
    """
    # ... (ê¸°ì¡´ ìºì‹œ/ë²¡í„° ê²€ìƒ‰ ë¡œì§) ...

    # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
    context_logs = self._format_context_logs(relevant_logs_data)

    # Chat historyë¥¼ LangChain ë©”ì‹œì§€ë¡œ ë³€í™˜
    history_messages = []
    if chat_history:
        for msg in chat_history[-10:]:  # ìµœê·¼ 10ê°œë§Œ (í† í° ì ˆì•½)
            if msg["role"] == "user":
                history_messages.append(HumanMessage(content=msg["content"]))
            elif msg["role"] == "assistant":
                history_messages.append(AIMessage(content=msg["content"]))

    # LLM í˜¸ì¶œ (íˆìŠ¤í† ë¦¬ í¬í•¨)
    response = await chatbot_chain.ainvoke({
        "context_logs": context_logs,
        "question": question,
        "chat_history": history_messages,  # íˆìŠ¤í† ë¦¬ ì „ë‹¬
    })

    answer = response.content

    # ... (ìºì‹± ë¡œì§) ...

    return ChatResponse(...)
```

**ì¤‘ìš”**: íˆìŠ¤í† ë¦¬ ê°œìˆ˜ ì œí•œ
- `chat_history[-10:]`: ìµœê·¼ 10ê°œë§Œ ì‚¬ìš©
- ì´ìœ : í† í° ì ˆì•½ + ë„ˆë¬´ ì˜¤ë˜ëœ ëŒ€í™”ëŠ” ê´€ë ¨ì„± ë‚®ìŒ

---

### 3.3. í”„ë¡ íŠ¸ì—”ë“œ ìˆ˜ì •

**íŒŒì¼**: `src/components/ChatBot.jsx`

```jsx
function ChatBot() {
    const [messages, setMessages] = useState([]);
    const [currentAnswer, setCurrentAnswer] = useState('');
    const [isStreaming, setIsStreaming] = useState(false);
    const [input, setInput] = useState('');

    /**
     * ë©”ì‹œì§€ ë°°ì—´ì„ chat_history í˜•ì‹ìœ¼ë¡œ ë³€í™˜
     */
    const buildChatHistory = () => {
        return messages.map(msg => ({
            role: msg.type === 'user' ? 'user' : 'assistant',
            content: msg.content
        }));
    };

    const askQuestionStream = async (question) => {
        // ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        const userMessage = {
            type: 'user',
            content: question,
            timestamp: new Date()
        };
        setMessages(prev => [...prev, userMessage]);

        setCurrentAnswer('');
        setIsStreaming(true);

        try {
            // History í¬í•¨í•˜ì—¬ ìš”ì²­
            const chatHistory = buildChatHistory();

            const response = await fetch('/api/v1/chatbot/ask/stream', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    question: question,
                    project_id: 'proj-123',
                    chat_history: chatHistory,  // íˆìŠ¤í† ë¦¬ ì „ë‹¬
                    filters: null,
                    time_range: null
                })
            });

            // ... (ê¸°ì¡´ ìŠ¤íŠ¸ë¦¬ë° ë¡œì§ ë™ì¼) ...

        } catch (err) {
            // ...
        }
    };

    // ... (ë‚˜ë¨¸ì§€ ì½”ë“œ ë™ì¼) ...
}
```

**í•µì‹¬**:
- `buildChatHistory()`: ê¸°ì¡´ ë©”ì‹œì§€ë¥¼ API í˜•ì‹ìœ¼ë¡œ ë³€í™˜
- ë§¤ ìš”ì²­ë§ˆë‹¤ ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ì„œë²„ì— ì „ë‹¬

---

### 3.4. ë©”ëª¨ë¦¬ ê´€ë¦¬

#### ë¬¸ì œ: ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´?

```
ëŒ€í™” 100í„´ Ã— í‰ê·  500í† í° = 50,000 í† í°!
â†’ ë¹„ìš© í­ë°œ ğŸ’¸
```

#### í•´ê²°: ìŠ¬ë¼ì´ë”© ìœˆë„ìš°

**ë°±ì—”ë“œ** (ì´ë¯¸ êµ¬í˜„ë¨):
```python
# ìµœê·¼ 10ê°œë§Œ ì‚¬ìš©
history_messages = []
if chat_history:
    for msg in chat_history[-10:]:  # ìµœê·¼ 10ê°œ
        # ...
```

**í”„ë¡ íŠ¸ì—”ë“œ** (ì¶”ê°€ ìµœì í™”):
```jsx
const buildChatHistory = () => {
    // ìµœê·¼ 20ê°œ ë©”ì‹œì§€ë§Œ (10í„´)
    const recentMessages = messages.slice(-20);

    return recentMessages.map(msg => ({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
    }));
};
```

#### ì¶”ê°€ ìµœì í™”: ìš”ì•½ ê¸°ë°˜ íˆìŠ¤í† ë¦¬

ë§¤ìš° ê¸´ ëŒ€í™”ì˜ ê²½ìš°:

```python
# ì˜¤ë˜ëœ ëŒ€í™”ëŠ” ìš”ì•½í•˜ì—¬ ì €ì¥
if len(chat_history) > 20:
    # ì²˜ìŒ 10ê°œëŠ” ìš”ì•½
    old_messages = chat_history[:10]
    summary = await summarize_conversation(old_messages)

    # ìš”ì•½ + ìµœê·¼ 10ê°œ
    condensed_history = [
        {"role": "system", "content": f"Previous context: {summary}"}
    ] + chat_history[-10:]
else:
    condensed_history = chat_history
```

---

## 4. Stream + History í†µí•©

### 4.1. ì „ì²´ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Frontend (React)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ POST /chatbot/ask/stream
                         â”‚ Body: {
                         â”‚   question,
                         â”‚   project_id,
                         â”‚   chat_history: [...]  â† ì´ì „ ëŒ€í™”
                         â”‚ }
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FastAPI: ask_chatbot_stream()                  â”‚
â”‚  1. ìºì‹œ ì²´í¬ (question + history ê¸°ë°˜)                   â”‚
â”‚  2. ë²¡í„° ê²€ìƒ‰ (ê´€ë ¨ ë¡œê·¸ ì°¾ê¸°)                            â”‚
â”‚  3. LLM í˜¸ì¶œ (íˆìŠ¤í† ë¦¬ í¬í•¨)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         LangChain: chatbot_chain.astream()               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ System: "You are a helpful assistant"  â”‚              â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”‚
â”‚  â”‚ History:                               â”‚              â”‚
â”‚  â”‚  - User: "ìµœê·¼ ì—ëŸ¬ ì•Œë ¤ì¤˜"              â”‚              â”‚
â”‚  â”‚  - AI: "NPE 3ê±´, DB 2ê±´"                â”‚              â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”‚
â”‚  â”‚ Context: [ë¡œê·¸ 5ê°œ]                     â”‚              â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”‚
â”‚  â”‚ Human: "ê°€ì¥ ì‹¬ê°í•œ ê±´?"                â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Stream chunks
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SSE Stream Response                              â”‚
â”‚  data: ì•ì„œ                                              â”‚
â”‚  data:  ë§ì”€ë“œë¦°                                          â”‚
â”‚  data:  DB íƒ€ì„ì•„ì›ƒì´                                     â”‚
â”‚  data:  ê°€ì¥ ì‹¬ê°í•©ë‹ˆë‹¤                                   â”‚
â”‚  data: [DONE]                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Frontend: Real-time UI Update                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ User: ìµœê·¼ ì—ëŸ¬ ì•Œë ¤ì¤˜                â”‚                â”‚
â”‚  â”‚ Bot: NPE 3ê±´, DB 2ê±´                 â”‚                â”‚
â”‚  â”‚                                      â”‚                â”‚
â”‚  â”‚ User: ê°€ì¥ ì‹¬ê°í•œ ê±´?                â”‚                â”‚
â”‚  â”‚ Bot: ì•ì„œ ë§ì”€ë“œë¦° DB íƒ€ì„ì•„ì›ƒ...â–Š   â”‚  â† íƒ€ì´í•‘ ì¤‘    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2. í†µí•© ì½”ë“œ

#### ë°±ì—”ë“œ (ìµœì¢…)

**íŒŒì¼**: `app/api/v1/chatbot.py`

```python
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from langchain_core.messages import HumanMessage, AIMessage
import json

from app.services.chatbot_service import chatbot_service
from app.services.embedding_service import embedding_service
from app.services.similarity_service import similarity_service
from app.chains.chatbot_chain import chatbot_chain
from app.models.chat import ChatRequest
from app.core.config import settings

router = APIRouter()

@router.post("/chatbot/ask/stream")
async def ask_chatbot_stream(request: ChatRequest):
    """
    Stream + History í†µí•© ì—”ë“œí¬ì¸íŠ¸
    """
    async def generate():
        try:
            # 1. ì„ë² ë”© ìƒì„±
            question_vector = await embedding_service.embed_query(request.question)

            # 2. ìºì‹œ ì²´í¬ (ìƒëµ ê°€ëŠ¥, íˆìŠ¤í† ë¦¬ ë•Œë¬¸ì— ìºì‹œ íˆíŠ¸ìœ¨ ë‚®ìŒ)
            # ...

            # 3. ê´€ë ¨ ë¡œê·¸ ê²€ìƒ‰
            relevant_logs_data = await similarity_service.find_similar_logs(
                log_vector=question_vector,
                k=chatbot_service.max_context,
                filters=request.filters,
                project_id=request.project_id,
            )

            # 4. ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            context_logs = chatbot_service._format_context_logs(relevant_logs_data)

            # 5. Chat history ë³€í™˜
            history_messages = []
            if request.chat_history:
                for msg in request.chat_history[-10:]:  # ìµœê·¼ 10ê°œ
                    if msg.role == "user":
                        history_messages.append(HumanMessage(content=msg.content))
                    elif msg.role == "assistant":
                        history_messages.append(AIMessage(content=msg.content))

            # 6. LLM ìŠ¤íŠ¸ë¦¬ë° (íˆìŠ¤í† ë¦¬ í¬í•¨)
            async for chunk in chatbot_chain.astream({
                "context_logs": context_logs,
                "question": request.question,
                "chat_history": history_messages,  # íˆìŠ¤í† ë¦¬
            }):
                content = chunk.content
                yield f"data: {content}\n\n"

            # 7. ì™„ë£Œ
            yield "data: [DONE]\n\n"

        except Exception as e:
            error_data = json.dumps({"error": str(e)})
            yield f"data: {error_data}\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        }
    )
```

#### í”„ë¡ íŠ¸ì—”ë“œ (ìµœì¢…)

**íŒŒì¼**: `src/components/ChatBot.jsx`

```jsx
import { useState, useRef, useEffect } from 'react';
import './ChatBot.css';

function ChatBot() {
    const [messages, setMessages] = useState([]);
    const [currentAnswer, setCurrentAnswer] = useState('');
    const [isStreaming, setIsStreaming] = useState(false);
    const [input, setInput] = useState('');
    const messagesEndRef = useRef(null);

    // ìë™ ìŠ¤í¬ë¡¤
    useEffect(() => {
        messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
    }, [messages, currentAnswer]);

    const buildChatHistory = () => {
        // ìµœê·¼ 20ê°œ ë©”ì‹œì§€ë§Œ (10í„´)
        const recentMessages = messages.slice(-20);
        return recentMessages.map(msg => ({
            role: msg.type === 'user' ? 'user' : 'assistant',
            content: msg.content
        }));
    };

    const askQuestionStream = async (question) => {
        const userMessage = {
            type: 'user',
            content: question,
            timestamp: new Date()
        };
        setMessages(prev => [...prev, userMessage]);

        setCurrentAnswer('');
        setIsStreaming(true);

        try {
            const chatHistory = buildChatHistory();

            const response = await fetch('/api/v1/chatbot/ask/stream', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    question,
                    project_id: 'proj-123',
                    chat_history: chatHistory,
                    filters: null,
                    time_range: null
                })
            });

            if (!response.ok) {
                throw new Error(`HTTP ${response.status}`);
            }

            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let buffer = '';
            let fullAnswer = '';

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                const chunk = decoder.decode(value, { stream: true });
                buffer += chunk;
                const lines = buffer.split('\n');
                buffer = lines.pop() || '';

                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const data = line.slice(6);

                        if (data === '[DONE]') continue;

                        try {
                            const parsed = JSON.parse(data);
                            if (parsed.error) throw new Error(parsed.error);
                        } catch {}

                        fullAnswer += data;
                        setCurrentAnswer(fullAnswer);
                    }
                }
            }

            const botMessage = {
                type: 'bot',
                content: fullAnswer,
                timestamp: new Date()
            };
            setMessages(prev => [...prev, botMessage]);

        } catch (err) {
            console.error('Error:', err);
            const errorMessage = {
                type: 'bot',
                content: `ì˜¤ë¥˜: ${err.message}`,
                timestamp: new Date(),
                isError: true
            };
            setMessages(prev => [...prev, errorMessage]);
        } finally {
            setIsStreaming(false);
            setCurrentAnswer('');
            setInput('');
        }
    };

    const handleSubmit = (e) => {
        e.preventDefault();
        if (input.trim() && !isStreaming) {
            askQuestionStream(input.trim());
        }
    };

    return (
        <div className="chatbot-container">
            <div className="chatbot-header">
                <h2>ğŸ¤– ë¡œê·¸ ë¶„ì„ ì±—ë´‡</h2>
                <p>ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ë©° ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤</p>
            </div>

            <div className="messages-container">
                {messages.map((msg, idx) => (
                    <div key={idx} className={`message ${msg.type} ${msg.isError ? 'error' : ''}`}>
                        <div className="message-avatar">
                            {msg.type === 'user' ? 'ğŸ‘¤' : 'ğŸ¤–'}
                        </div>
                        <div className="message-bubble">
                            <div className="message-content">{msg.content}</div>
                            <div className="message-timestamp">
                                {msg.timestamp.toLocaleTimeString('ko-KR')}
                            </div>
                        </div>
                    </div>
                ))}

                {isStreaming && currentAnswer && (
                    <div className="message bot streaming">
                        <div className="message-avatar">ğŸ¤–</div>
                        <div className="message-bubble">
                            <div className="message-content">
                                {currentAnswer}
                                <span className="typing-cursor">â–Š</span>
                            </div>
                        </div>
                    </div>
                )}

                <div ref={messagesEndRef} />
            </div>

            <form onSubmit={handleSubmit} className="input-form">
                <input
                    type="text"
                    value={input}
                    onChange={(e) => setInput(e.target.value)}
                    placeholder="ë¡œê·¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."
                    disabled={isStreaming}
                    className="chat-input"
                />
                <button
                    type="submit"
                    disabled={isStreaming || !input.trim()}
                    className="send-button"
                >
                    {isStreaming ? 'â³' : 'ğŸ“¤'}
                </button>
            </form>
        </div>
    );
}

export default ChatBot;
```

---

## 5. ì‹¤ìŠµ ê°€ì´ë“œ

### 5.1. ë‹¨ê³„ë³„ êµ¬í˜„

#### Phase 1: Streamë§Œ ë¨¼ì € êµ¬í˜„

**ëª©í‘œ**: ê¸°ë³¸ ìŠ¤íŠ¸ë¦¬ë° ë™ì‘ í™•ì¸

1. **ë°±ì—”ë“œ**: `app/api/v1/chatbot.py`ì— `/chatbot/ask/stream` ì¶”ê°€
2. **í”„ë¡ íŠ¸ì—”ë“œ**: ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í˜ì´ì§€ ì‘ì„±
3. **í…ŒìŠ¤íŠ¸**: "ìµœê·¼ ì—ëŸ¬ ì•Œë ¤ì¤˜" ì…ë ¥ â†’ ì‹¤ì‹œê°„ íƒ€ì´í•‘ í™•ì¸

**í…ŒìŠ¤íŠ¸ ì½”ë“œ**:
```bash
# cURLë¡œ í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:8000/api/v1/chatbot/ask/stream \
  -H "Content-Type: application/json" \
  -d '{
    "question": "ìµœê·¼ ì—ëŸ¬ ì•Œë ¤ì¤˜",
    "project_id": "proj-123"
  }'

# ì¶œë ¥ ì˜ˆì‹œ:
# data: ìµœê·¼
# data:  24ì‹œê°„
# data:  ë™ì•ˆ
# ...
# data: [DONE]
```

#### Phase 2: History ì¶”ê°€

**ëª©í‘œ**: ì´ì „ ëŒ€í™” ê¸°ì–µí•˜ëŠ”ì§€ í™•ì¸

1. **ëª¨ë¸ ìˆ˜ì •**: `ChatRequest`ì— `chat_history` ì¶”ê°€
2. **ì²´ì¸ ìˆ˜ì •**: `MessagesPlaceholder` ì¶”ê°€
3. **í”„ë¡ íŠ¸ì—”ë“œ**: íˆìŠ¤í† ë¦¬ ì „ë‹¬ ë¡œì§ ì¶”ê°€
4. **í…ŒìŠ¤íŠ¸**: ì—°ì† ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```
Turn 1:
  User: "ìµœê·¼ NPE ì—ëŸ¬ ì•Œë ¤ì¤˜"
  Bot: "UserServiceì—ì„œ 3ê±´ ë°œìƒí–ˆìŠµë‹ˆë‹¤"

Turn 2 (íˆìŠ¤í† ë¦¬ í¬í•¨):
  User: "ê·¸ê±° ì–¸ì œ ë°œìƒí•œ ê±°ì•¼?"
  Bot: "ì•ì„œ ë§ì”€ë“œë¦° NPEëŠ” ì˜¤ëŠ˜ ì˜¤ì „ 10ì‹œì— ë°œìƒí–ˆìŠµë‹ˆë‹¤" âœ…
```

#### Phase 3: ìµœì í™”

1. **ë©”ëª¨ë¦¬ ì œí•œ**: ìµœê·¼ 10ê°œ í„´ë§Œ ìœ ì§€
2. **UI ê°œì„ **: ì•„ë°”íƒ€, íƒ€ì„ìŠ¤íƒ¬í”„, ìë™ ìŠ¤í¬ë¡¤
3. **ì—ëŸ¬ ì²˜ë¦¬**: íƒ€ì„ì•„ì›ƒ, ì¬ì‹œë„ ë¡œì§

---

### 5.2. í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### Stream í…ŒìŠ¤íŠ¸

- [ ] ì²« ì²­í¬ê°€ 1ì´ˆ ì´ë‚´ì— ë„ì°©í•˜ëŠ”ê°€?
- [ ] íƒ€ì´í•‘ íš¨ê³¼ê°€ ìì—°ìŠ¤ëŸ¬ìš´ê°€?
- [ ] ê¸´ ë‹µë³€(500ì ì´ìƒ)ë„ ìŠ¤íŠ¸ë¦¬ë°ë˜ëŠ”ê°€?
- [ ] [DONE] ì‹ í˜¸ ìˆ˜ì‹  í›„ ìŠ¤íŠ¸ë¦¼ì´ ì¢…ë£Œë˜ëŠ”ê°€?
- [ ] ì—ëŸ¬ ë°œìƒ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ê°€ í‘œì‹œë˜ëŠ”ê°€?

#### History í…ŒìŠ¤íŠ¸

- [ ] ì´ì „ ëŒ€í™” ë§¥ë½ì„ ì´í•´í•˜ëŠ”ê°€?
  - "ê·¸ê±°", "ê·¸ ì¤‘", "ì•ì—ì„œ" ë“± ëŒ€ëª…ì‚¬ ì´í•´
- [ ] 10í„´ ì´ìƒ ëŒ€í™” ì‹œ ë©”ëª¨ë¦¬ ì œí•œì´ ë™ì‘í•˜ëŠ”ê°€?
- [ ] ìƒˆ ì„¸ì…˜ ì‹œì‘ ì‹œ íˆìŠ¤í† ë¦¬ê°€ ì´ˆê¸°í™”ë˜ëŠ”ê°€?
- [ ] íˆìŠ¤í† ë¦¬ê°€ ì—†ëŠ” ì²« ì§ˆë¬¸ë„ ì •ìƒ ë™ì‘í•˜ëŠ”ê°€?

#### í†µí•© í…ŒìŠ¤íŠ¸

- [ ] Stream + History ë™ì‹œ ì‚¬ìš© ì‹œ ì •ìƒ ë™ì‘í•˜ëŠ”ê°€?
- [ ] ì—¬ëŸ¬ ì‚¬ìš©ìê°€ ë™ì‹œì— ì‚¬ìš©í•´ë„ íˆìŠ¤í† ë¦¬ê°€ ì„ì´ì§€ ì•ŠëŠ”ê°€?
- [ ] ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨ í›„ íˆìŠ¤í† ë¦¬ê°€ ìœ ì§€ë˜ëŠ”ê°€? (ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ì‚¬ìš© ì‹œ)

---

## 6. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 6.1. Stream ê´€ë ¨

#### ë¬¸ì œ: ì²« ì²­í¬ê°€ ëŠ¦ê²Œ ë„ì°©í•¨

**ì¦ìƒ**: 5-10ì´ˆ í›„ì—ì•¼ ì²« ì²­í¬ê°€ ì˜´

**ì›ì¸**:
- ë²¡í„° ê²€ìƒ‰ì´ ëŠë¦¼
- OpenSearch ì¸ë±ìŠ¤ ìµœì í™” í•„ìš”

**í•´ê²°**:
```python
# ë²¡í„° ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ ì„¤ì •
relevant_logs = await asyncio.wait_for(
    similarity_service.find_similar_logs(...),
    timeout=3.0  # 3ì´ˆ íƒ€ì„ì•„ì›ƒ
)
```

ë˜ëŠ” ì¦‰ì‹œ ì‘ë‹µ:
```python
# ì²­í¬ í•˜ë‚˜ë¥¼ ë¨¼ì € ë³´ë‚´ê¸°
yield "data: ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n\n"

# ê·¸ í›„ ê²€ìƒ‰
relevant_logs = await search_logs(...)
```

#### ë¬¸ì œ: Nginxì—ì„œ ë²„í¼ë§ë¨

**ì¦ìƒ**: ë‹µë³€ì´ ë‹¤ ìƒì„±ëœ í›„ í•œë²ˆì— ì˜´

**ì›ì¸**: Nginxê°€ SSEë¥¼ ë²„í¼ë§

**í•´ê²°**:
```nginx
# nginx.conf
location /api/v1/chatbot/ask/stream {
    proxy_pass http://backend;
    proxy_buffering off;  # ë²„í¼ë§ ë¹„í™œì„±í™”
    proxy_cache off;
    proxy_set_header Connection '';
    proxy_http_version 1.1;
    chunked_transfer_encoding off;
}
```

FastAPI í—¤ë”:
```python
return StreamingResponse(
    generate(),
    headers={
        "X-Accel-Buffering": "no",  # Nginx ë²„í¼ë§ ê°•ì œ ë¹„í™œì„±í™”
    }
)
```

#### ë¬¸ì œ: ì²­í¬ê°€ ê¹¨ì ¸ì„œ ì˜´

**ì¦ìƒ**: "ì•ˆë…•í•˜" + "ì„¸ìš”" â†’ "ì•ˆë…•í•˜Ã¬â€Â¸Ã¬Å¡"" (ì¸ì½”ë”© ê¹¨ì§)

**ì›ì¸**: UTF-8 ë©€í‹°ë°”ì´íŠ¸ ë¬¸ìê°€ ì²­í¬ ê²½ê³„ì—ì„œ ë¶„ë¦¬ë¨

**í•´ê²°**:
```javascript
// decoderì— stream: true ì˜µì…˜
const decoder = new TextDecoder('utf-8');

while (true) {
    const { done, value } = await reader.read();

    // stream: trueë¡œ ë¶ˆì™„ì „í•œ ë¬¸ì ë³´ì¡´
    const chunk = decoder.decode(value, { stream: true });
    // ...
}
```

---

### 6.2. History ê´€ë ¨

#### ë¬¸ì œ: íˆìŠ¤í† ë¦¬ê°€ ë„ˆë¬´ ê¸¸ì–´ì§

**ì¦ìƒ**: 10í„´ ì´ìƒ ëŒ€í™” ì‹œ ì‘ë‹µ ëŠë ¤ì§, ë¹„ìš© ì¦ê°€

**í•´ê²°**:
```python
# ìŠ¬ë¼ì´ë”© ìœˆë„ìš° (ìµœê·¼ 10ê°œë§Œ)
history_messages = []
if chat_history:
    for msg in chat_history[-10:]:  # ìµœê·¼ 10ê°œ
        # ...
```

ë˜ëŠ” í† í° ê¸°ë°˜:
```python
import tiktoken

def trim_history_by_tokens(chat_history, max_tokens=2000):
    """íˆìŠ¤í† ë¦¬ë¥¼ í† í° ì œí•œ ë‚´ë¡œ ìë¥´ê¸°"""
    enc = tiktoken.encoding_for_model("gpt-4o-mini")

    total_tokens = 0
    trimmed = []

    # ìµœì‹  ë©”ì‹œì§€ë¶€í„° ì—­ìˆœìœ¼ë¡œ
    for msg in reversed(chat_history):
        msg_tokens = len(enc.encode(msg["content"]))

        if total_tokens + msg_tokens > max_tokens:
            break

        trimmed.insert(0, msg)
        total_tokens += msg_tokens

    return trimmed
```

#### ë¬¸ì œ: ë§¥ë½ì„ ì˜ëª» ì´í•´í•¨

**ì¦ìƒ**: "ê·¸ê±°" â†’ ì „í˜€ ë‹¤ë¥¸ ê²ƒì„ ê°€ë¦¬í‚´

**ì›ì¸**:
- íˆìŠ¤í† ë¦¬ê°€ ë„ˆë¬´ ì˜¤ë˜ë¨
- ì—¬ëŸ¬ ì£¼ì œê°€ ì„ì—¬ìˆìŒ

**í•´ê²°**:
```python
# í”„ë¡¬í”„íŠ¸ ê°œì„ 
chatbot_prompt = ChatPromptTemplate.from_messages([
    ("system", """...

    Important:
    - Pay special attention to pronouns (ê·¸ê±°, ê·¸ê²ƒ, ì´ê±°) in the current question
    - Refer to the most recent relevant context in the chat history
    - If unsure about what a pronoun refers to, ask for clarification
    """),
    # ...
])
```

#### ë¬¸ì œ: ì„¸ì…˜ ê´€ë¦¬

**ì¦ìƒ**: í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ ì‹œ íˆìŠ¤í† ë¦¬ ì‚¬ë¼ì§

**í•´ê²°**: ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ ì‚¬ìš©

```jsx
// ë©”ì‹œì§€ ì €ì¥
useEffect(() => {
    localStorage.setItem('chatHistory', JSON.stringify(messages));
}, [messages]);

// ë©”ì‹œì§€ ë³µì›
useEffect(() => {
    const saved = localStorage.getItem('chatHistory');
    if (saved) {
        setMessages(JSON.parse(saved));
    }
}, []);

// ì´ˆê¸°í™” ë²„íŠ¼
const clearHistory = () => {
    setMessages([]);
    localStorage.removeItem('chatHistory');
};
```

---

### 6.3. ì„±ëŠ¥ ìµœì í™”

#### ë³‘ë ¬ ì²˜ë¦¬

ìºì‹œ ì²´í¬ì™€ ë²¡í„° ê²€ìƒ‰ì„ ë³‘ë ¬ë¡œ:

```python
import asyncio

# ìˆœì°¨ (ëŠë¦¼)
cached = await check_cache(question)
logs = await search_logs(question)

# ë³‘ë ¬ (ë¹ ë¦„)
cached, logs = await asyncio.gather(
    check_cache(question),
    search_logs(question)
)
```

#### ì¡°ê¸° ì¢…ë£Œ

ìºì‹œ íˆíŠ¸ ì‹œ ì¦‰ì‹œ ë°˜í™˜:

```python
async def generate():
    # ìºì‹œ ì²´í¬ (ë¹ ë¦„)
    cached = await check_cache(...)
    if cached:
        yield f"data: {cached['answer']}\n\n"
        yield "data: [DONE]\n\n"
        return  # ì¡°ê¸° ì¢…ë£Œ, ë²¡í„° ê²€ìƒ‰ ì•ˆ í•¨!

    # ìºì‹œ ë¯¸ìŠ¤ ì‹œì—ë§Œ ê²€ìƒ‰
    logs = await search_logs(...)
```

---

## 7. ì¶”ê°€ ê¸°ëŠ¥ (ì„ íƒ)

### 7.1. íƒ€ì´í•‘ ì†ë„ ì¡°ì ˆ

ëŠë¦° íƒ€ì´í•‘ íš¨ê³¼:

```python
async def generate():
    async for chunk in chatbot_chain.astream({...}):
        yield f"data: {chunk.content}\n\n"

        # ì¸ìœ„ì ì¸ ë”œë ˆì´ (ì„ íƒ)
        await asyncio.sleep(0.05)  # 50ms ë”œë ˆì´
```

### 7.2. ì¤‘ë‹¨ ê¸°ëŠ¥

ì‚¬ìš©ìê°€ ë‹µë³€ ìƒì„±ì„ ì·¨ì†Œ:

```jsx
const abortControllerRef = useRef(null);

const askQuestionStream = async (question) => {
    // AbortController ìƒì„±
    abortControllerRef.current = new AbortController();

    const response = await fetch('/api/v1/chatbot/ask/stream', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({...}),
        signal: abortControllerRef.current.signal  // ì¤‘ë‹¨ ì‹ í˜¸
    });

    // ...
};

const stopGeneration = () => {
    if (abortControllerRef.current) {
        abortControllerRef.current.abort();
        setIsStreaming(false);
    }
};

// UI
{isStreaming && (
    <button onClick={stopGeneration}>ì¤‘ë‹¨</button>
)}
```

### 7.3. ìŒì„± ì…ë ¥

```jsx
const startVoiceInput = () => {
    const recognition = new webkitSpeechRecognition();
    recognition.lang = 'ko-KR';

    recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        setInput(transcript);
    };

    recognition.start();
};
```

---

## 8. ìš”ì•½

### Stream êµ¬í˜„ í•µì‹¬

```python
# ë°±ì—”ë“œ
async def generate():
    async for chunk in chatbot_chain.astream({...}):
        yield f"data: {chunk.content}\n\n"
    yield "data: [DONE]\n\n"

return StreamingResponse(generate(), media_type="text/event-stream")
```

```jsx
// í”„ë¡ íŠ¸ì—”ë“œ
const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    const chunk = decoder.decode(value, { stream: true });
    // SSE íŒŒì‹± í›„ UI ì—…ë°ì´íŠ¸
}
```

### History êµ¬í˜„ í•µì‹¬

```python
# ë°±ì—”ë“œ: MessagesPlaceholder
from langchain_core.prompts import MessagesPlaceholder

chatbot_prompt = ChatPromptTemplate.from_messages([
    ("system", "..."),
    MessagesPlaceholder(variable_name="chat_history", optional=True),
    ("human", "{question}")
])

# íˆìŠ¤í† ë¦¬ ë³€í™˜
history_messages = [
    HumanMessage(content=msg["content"]) if msg["role"] == "user"
    else AIMessage(content=msg["content"])
    for msg in chat_history[-10:]  # ìµœê·¼ 10ê°œ
]
```

```jsx
// í”„ë¡ íŠ¸ì—”ë“œ: íˆìŠ¤í† ë¦¬ êµ¬ì¶•
const buildChatHistory = () => {
    return messages.slice(-20).map(msg => ({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
    }));
};
```

### ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] Stream ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
- [x] SSE í˜•ì‹ ì¤€ìˆ˜
- [x] í”„ë¡ íŠ¸ì—”ë“œ ReadableStream ì²˜ë¦¬
- [x] MessagesPlaceholder ì¶”ê°€
- [x] íˆìŠ¤í† ë¦¬ ì œí•œ (10í„´)
- [x] ì—ëŸ¬ ì²˜ë¦¬
- [x] UI/UX ê°œì„  (íƒ€ì´í•‘ ì»¤ì„œ, ìë™ ìŠ¤í¬ë¡¤)

ì™„ë£Œ! ğŸ‰
