# FastAPI í˜¸ìŠ¤íŒ… ì„¤ì • ê°€ì´ë“œ

AI ë¡œê·¸ ë¶„ì„ ì„œë¹„ìŠ¤ì˜ í™˜ê²½ êµ¬ì„± ë° ë°°í¬ ê°€ì´ë“œ

---

## ğŸ“‹ ëª©ì°¨

1. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
2. [í™˜ê²½ êµ¬ì„±](#-í™˜ê²½-êµ¬ì„±)
3. [ë¡œì»¬ í…ŒìŠ¤íŠ¸ í™˜ê²½](#-ë¡œì»¬-í…ŒìŠ¤íŠ¸-í™˜ê²½-wsllinux)
4. [í”„ë¡œë•ì…˜ ë°°í¬](#-í”„ë¡œë•ì…˜-ë°°í¬)
5. [API ì—”ë“œí¬ì¸íŠ¸](#-api-ì—”ë“œí¬ì¸íŠ¸)
6. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)
7. [ì„±ëŠ¥ ìµœì í™”](#-ì„±ëŠ¥-ìµœì í™”)

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ê¸°ìˆ  ìŠ¤íƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Client (React)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP/SSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                FastAPI Server (Python 3.12)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Log API     â”‚  â”‚  Chatbot API â”‚  â”‚  Health API  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                  â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         Service Layer                           â”‚    â”‚
â”‚  â”‚  - Log Analysis Service (Map-Reduce)            â”‚    â”‚
â”‚  â”‚  - Chatbot Service (RAG + Caching)              â”‚    â”‚
â”‚  â”‚  - Embedding Service (Cache)                    â”‚    â”‚
â”‚  â”‚  - Similarity Service (KNN Search)              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚               â”‚               â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚OpenAI   â”‚    â”‚OpenSearchâ”‚    â”‚  Kafka  â”‚
    â”‚(GPT-4o  â”‚    â”‚(Vector   â”‚    â”‚(Log     â”‚
    â”‚ mini)   â”‚    â”‚ Search)  â”‚    â”‚ Stream) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì£¼ìš” ì»´í¬ë„ŒíŠ¸

| ì»´í¬ë„ŒíŠ¸ | ì—­í•  | ê¸°ìˆ  |
|----------|------|------|
| **FastAPI** | REST API ì„œë²„ | Python 3.12, Uvicorn |
| **OpenSearch** | ë¡œê·¸ ì €ì¥ ë° ë²¡í„° ê²€ìƒ‰ | OpenSearch 2.11.0, KNN |
| **OpenAI** | LLM ë° ì„ë² ë”© | GPT-4o mini, text-embedding-3-large |
| **LangChain** | LLM ì²´ì¸ êµ¬ì„± | LangChain 0.2.16 |
| **Kafka** | ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° | Kafka 7.5.0 (KRaft) |
| **Logstash** | ë¡œê·¸ íŒŒì´í”„ë¼ì¸ | Logstash 8.9.0 |

---

## âš™ï¸ í™˜ê²½ êµ¬ì„±

### í™˜ê²½ë³€ìˆ˜ íŒŒì¼

í”„ë¡œì íŠ¸ëŠ” 2ê°€ì§€ í™˜ê²½ë³€ìˆ˜ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

| íŒŒì¼ | ìš©ë„ | OpenSearch í˜¸ìŠ¤íŠ¸ |
|------|------|------------------|
| `.env` | í”„ë¡œë•ì…˜/ì»¨í…Œì´ë„ˆ í™˜ê²½ | `opensearch` (ì„œë¹„ìŠ¤ëª…) |
| `.env.test` | ë¡œì»¬ í…ŒìŠ¤íŠ¸ í™˜ê²½ | `localhost` |

### í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜

#### 1. OpenAI API (SSAFY GMS)

```bash
OPENAI_API_KEY=S13P32A306-xxxx-xxxx-xxxx-xxxxxxxxxxxx
OPENAI_BASE_URL=https://gms.ssafy.io/gmsapi/api.openai.com/v1
EMBEDDING_MODEL=text-embedding-3-large
LLM_MODEL=gpt-4o-mini
```

**ë°œê¸‰ ë°©ë²•**:
1. SSAFY GMS í¬í„¸ ì ‘ì†: https://gms.ssafy.io/
2. í”„ë¡œì íŠ¸ ë“±ë¡ í›„ API í‚¤ ë°œê¸‰
3. `.env` ë° `.env.test` íŒŒì¼ì— ì¶”ê°€

#### 2. OpenSearch ì„¤ì •

**í”„ë¡œë•ì…˜ (`.env`)**:
```bash
OPENSEARCH_HOST=opensearch  # Docker ì»¨í…Œì´ë„ˆ ì´ë¦„
OPENSEARCH_PORT=9200
OPENSEARCH_USER=admin
OPENSEARCH_PASSWORD=admin
OPENSEARCH_USE_SSL=false
OPENSEARCH_VERIFY_CERTS=false
```

**ë¡œì»¬ í…ŒìŠ¤íŠ¸ (`.env.test`)**:
```bash
OPENSEARCH_HOST=localhost  # í˜¸ìŠ¤íŠ¸ì—ì„œ ì ‘ê·¼
OPENSEARCH_PORT=9200
OPENSEARCH_USER=admin
OPENSEARCH_PASSWORD=admin
OPENSEARCH_USE_SSL=false
OPENSEARCH_VERIFY_CERTS=false
```

#### 3. ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •

```bash
APP_NAME=log-analysis-api
ENVIRONMENT=development  # ë˜ëŠ” production
SERVICE_PORT=8000
LOG_LEVEL=INFO  # DEBUG, INFO, WARN, ERROR

# CORS ì„¤ì •
CORS_ORIGINS=["http://localhost:3000","http://localhost:5173"]

# ë¶„ì„ ì„¤ì •
SIMILARITY_THRESHOLD=0.8
MAX_CONTEXT_LOGS=5

# ìºì‹± ì„¤ì •
CACHE_CANDIDATE_SIZE=5
DEFAULT_CACHE_TTL=1800
SHORT_CACHE_TTL=600
LONG_CACHE_TTL=86400

# Map-Reduce ì„¤ì •
ENABLE_MAP_REDUCE=true
MAP_REDUCE_THRESHOLD=10
LOG_CHUNK_SIZE=5

# LLM íƒ€ì„ì•„ì›ƒ
LLM_REQUEST_TIMEOUT=120
```

---

## ğŸ§ª ë¡œì»¬ í…ŒìŠ¤íŠ¸ í™˜ê²½ (WSL/Linux)

### ì‚¬ì „ ìš”êµ¬ì‚¬í•­

- **Docker Desktop** (WSL í†µí•© í™œì„±í™”)
- **Python 3.11+** (3.12 ê¶Œì¥)
- **pip, venv**
- **ìµœì†Œ 4GB RAM** (OpenSearch)

### 1ë‹¨ê³„: Docker Desktop WSL í†µí•© í™œì„±í™”

#### Docker Desktop ì„¤ì •

1. Docker Desktop ì‹¤í–‰ (Windows)
2. **Settings (âš™ï¸)** â†’ **Resources** â†’ **WSL Integration**
3. **Enable integration with my default WSL distro** ì²´í¬
4. ì‚¬ìš© ì¤‘ì¸ distro (Ubuntu ë“±) í™œì„±í™”
5. **Apply & Restart**

#### í™•ì¸

```bash
# WSL í„°ë¯¸ë„ì—ì„œ
docker --version
docker compose version  # v2 (ê³µë°± ì£¼ì˜)
```

### 2ë‹¨ê³„: Docker ê¶Œí•œ ì„¤ì •

```bash
# ì‚¬ìš©ìë¥¼ docker ê·¸ë£¹ì— ì¶”ê°€
sudo usermod -aG docker $USER

# WSL ì¬ì‹œì‘ (PowerShellì—ì„œ)
# wsl --shutdown
# ê·¸ í›„ WSL ë‹¤ì‹œ ì‹œì‘

# ê·¸ë£¹ í™•ì¸
groups  # ì¶œë ¥ì— "docker" í¬í•¨ë˜ì–´ì•¼ í•¨
```

### 3ë‹¨ê³„: Python ê°€ìƒí™˜ê²½ êµ¬ì„±

```bash
# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd /mnt/c/SSAFY/third_project/AI/S13P31A306

# ê°€ìƒí™˜ê²½ ìƒì„±
python3 -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

**ì„¤ì¹˜ë˜ëŠ” ì£¼ìš” íŒ¨í‚¤ì§€**:
- fastapi==0.109.0
- uvicorn[standard]==0.27.0
- langchain==0.2.16
- langchain-openai==0.1.23
- openai==1.40.0
- opensearch-py==2.4.2
- tiktoken==0.7.0

### 4ë‹¨ê³„: OpenSearch ì‹¤í–‰

```bash
# Docker Composeë¡œ OpenSearch ì‹œì‘
sudo docker compose -f docker-compose.test.yml up -d

# ì»¨í…Œì´ë„ˆ í™•ì¸
sudo docker ps

# OpenSearch ì¤€ë¹„ ëŒ€ê¸° (30ì´ˆ ì •ë„)
sleep 30

# OpenSearch ìƒíƒœ í™•ì¸
curl http://localhost:9200/_cluster/health?pretty
```

**ì˜ˆìƒ ì¶œë ¥**:
```json
{
  "cluster_name" : "opensearch-cluster",
  "status" : "green",
  "number_of_nodes" : 1
}
```

### 5ë‹¨ê³„: OpenSearch ì¸ë±ìŠ¤ ìƒì„±

```bash
# ìŠ¤í¬ë¦½íŠ¸ê°€ ìë™ìœ¼ë¡œ .env.test ì‚¬ìš©
python scripts/create_indices.py
```

**ì˜ˆìƒ ì¶œë ¥**:
```
ğŸ”§ Using .env.test for local testing
ğŸš€ Creating OpenSearch indices...

âœ… Created logs index template
âœ… Created qa-cache index

==================================================
ğŸ“Š Index Creation Results:
==================================================
Logs template        âœ… SUCCESS
QA cache index       âœ… SUCCESS

âœ¨ All indices created successfully!
```

**ìƒì„±ë˜ëŠ” ì¸ë±ìŠ¤**:
- `logs-*`: ë¡œê·¸ ì €ì¥ (KNN ë²¡í„° í¬í•¨)
- `qa-cache`: QA ìºì‹± (KNN ë²¡í„° í¬í•¨)

### 6ë‹¨ê³„: FastAPI ì„œë²„ ì‹¤í–‰

```bash
# ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ëœ ìƒíƒœì—ì„œ
uvicorn app.main:app --reload --env-file .env.test
```

**ì„œë²„ ì‹œì‘ ë©”ì‹œì§€**:
```
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [12345] using StatReload
INFO:     Started server process [12346]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
```

### 7ë‹¨ê³„: API í…ŒìŠ¤íŠ¸

#### Swagger UI (ê¶Œì¥)

ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†:
```
http://localhost:8000/docs
```

#### Health Check

```bash
curl http://localhost:8000/api/v1/health
```

**ì‘ë‹µ**:
```json
{
  "status": "healthy",
  "timestamp": "2025-01-15T10:30:00.000Z",
  "services": {
    "opensearch": "healthy",
    "openai": "healthy"
  }
}
```

### ì¢…ë£Œ

```bash
# FastAPI ì„œë²„ ì¢…ë£Œ
# Ctrl+C

# OpenSearch ì¢…ë£Œ
sudo docker compose -f docker-compose.test.yml down

# ê°€ìƒí™˜ê²½ ë¹„í™œì„±í™”
deactivate
```

---

## ğŸš€ í”„ë¡œë•ì…˜ ë°°í¬

### Blue-Green ë°°í¬ ì•„í‚¤í…ì²˜

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Nginx   â”‚
                    â”‚  (8080)  â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                         â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                             â”‚
     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
     â”‚  Blue   â”‚                   â”‚  Green  â”‚
     â”‚ (8000)  â”‚                   â”‚ (8001)  â”‚
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
          â”‚                             â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                   â”‚OpenSearch â”‚
                   â”‚  Kafka    â”‚
                   â”‚ Logstash  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©

```bash
# Blue ìŠ¬ë¡¯ì— ë°°í¬
./infra/dev/scripts/deploy.sh blue

# Green ìŠ¬ë¡¯ì— ë°°í¬
./infra/dev/scripts/deploy.sh green
```

### ìˆ˜ë™ ë°°í¬

#### 1. Docker ì´ë¯¸ì§€ ë¹Œë“œ

```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ
docker build -t ai-service:latest .
```

**Dockerfile êµ¬ì¡°**:
```dockerfile
FROM python:3.12-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 2. í™˜ê²½ë³€ìˆ˜ ì„¤ì •

í”„ë¡œë•ì…˜ `.env` íŒŒì¼ í™•ì¸:
- `OPENSEARCH_HOST=opensearch` (ì»¨í…Œì´ë„ˆ ì´ë¦„)
- `KAFKA_BOOTSTRAP_SERVERS=kafka:19092`
- OpenAI API í‚¤ ì„¤ì •

#### 3. Blue ìŠ¬ë¡¯ ë°°í¬

```bash
cd infra/dev/docker
docker-compose -f docker-compose-blue.yaml up -d
```

#### 4. Nginx ì„¤ì •

**Blueë¡œ íŠ¸ë˜í”½ ì „í™˜** (`nginx-blue.conf`):
```nginx
upstream backend {
    server ai-service-blue:8000;
}

server {
    listen 8080;

    location / {
        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }

    location /api/v1/chatbot/ask/stream {
        proxy_pass http://backend;
        proxy_buffering off;
        proxy_cache off;
        proxy_set_header Connection '';
        proxy_http_version 1.1;
        chunked_transfer_encoding off;
    }
}
```

#### 5. Health Check

```bash
curl http://localhost:8080/api/v1/health
```

---

## ğŸ“¡ API ì—”ë“œí¬ì¸íŠ¸

### 1. Health Check

**Endpoint**: `GET /api/v1/health`

**ì‘ë‹µ**:
```json
{
  "status": "healthy",
  "timestamp": "2025-01-15T10:30:00.000Z",
  "services": {
    "opensearch": "healthy",
    "openai": "healthy"
  }
}
```

### 2. ë¡œê·¸ ë¶„ì„ (ë‹¨ì¼)

**Endpoint**: `GET /api/v1/logs/{log_id}/analysis`

**Parameters**:
- `log_id` (path): ë¡œê·¸ ID (integer)
- `project_uuid` (query): í”„ë¡œì íŠ¸ UUID

**ì˜ˆì‹œ**:
```bash
curl "http://localhost:8000/api/v1/logs/12345/analysis?project_uuid=550e8400-e29b-41d4-a716-446655440000"
```

**ì‘ë‹µ**:
```json
{
  "log_id": 12345,
  "summary": "user-serviceì—ì„œ NullPointerException ë°œìƒ",
  "error_cause": "User ê°ì²´ê°€ nullì¸ ìƒíƒœì—ì„œ getName() í˜¸ì¶œ",
  "solution": "null ì²´í¬ ë¡œì§ ì¶”ê°€ í•„ìš”",
  "tags": ["NullPointerException", "user-service", "Critical"],
  "analysis_type": "SINGLE",
  "analyzed_at": "2025-01-15T10:30:00.000Z"
}
```

### 3. ë¡œê·¸ ë¶„ì„ (Trace ê¸°ë°˜)

**Endpoint**: `POST /api/v1/logs/trace/analysis`

**Request Body**:
```json
{
  "trace_id": "abc123-def456",
  "center_timestamp": "2025-01-15T10:30:00.000Z",
  "project_uuid": "550e8400-e29b-41d4-a716-446655440000",
  "max_logs": 100,
  "time_window_seconds": 3
}
```

**íŠ¹ì§•**:
- Â±3ì´ˆ ë‚´ ê°™ì€ trace_id ë¡œê·¸ ìˆ˜ì§‘
- 10ê°œ ì´ìƒ ë¡œê·¸ ì‹œ **Map-Reduce íŒ¨í„´** ìë™ ì ìš©

### 4. ì±—ë´‡ (ì¼ë°˜)

**Endpoint**: `POST /api/v1/chatbot/ask`

**Request Body**:
```json
{
  "question": "ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ ì–´ë–¤ ì—ëŸ¬ê°€ ë°œìƒí–ˆì–´?",
  "project_uuid": "550e8400-e29b-41d4-a716-446655440000",
  "chat_history": [
    {"role": "user", "content": "ìµœê·¼ ì—ëŸ¬ ì•Œë ¤ì¤˜"},
    {"role": "assistant", "content": "NullPointerException 3ê±´ ë°œìƒí–ˆìŠµë‹ˆë‹¤"}
  ],
  "filters": {"level": "ERROR"},
  "time_range": {
    "start": "2025-01-14T00:00:00Z",
    "end": "2025-01-15T00:00:00Z"
  }
}
```

**ì‘ë‹µ**:
```json
{
  "answer": "ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ user-serviceì—ì„œ NullPointerException 3ê±´...",
  "from_cache": false,
  "related_logs": [
    {
      "log_id": 12345,
      "timestamp": "2025-01-15T10:30:00Z",
      "level": "ERROR",
      "message": "NullPointerException in UserService",
      "service_name": "user-service",
      "similarity_score": 0.95
    }
  ],
  "answered_at": "2025-01-15T10:35:00.000Z"
}
```

### 5. ì±—ë´‡ (ìŠ¤íŠ¸ë¦¬ë°)

**Endpoint**: `POST /api/v1/chatbot/ask/stream`

**íŠ¹ì§•**:
- Server-Sent Events (SSE) í˜•ì‹
- ì‹¤ì‹œê°„ íƒ€ì´í•‘ íš¨ê³¼
- `data: [DONE]`ìœ¼ë¡œ ì™„ë£Œ ì‹ í˜¸

**ì‘ë‹µ ì˜ˆì‹œ**:
```
data: ìµœê·¼
data:  24ì‹œê°„
data:  ë™ì•ˆ
data:  user-serviceì—ì„œ
data:  NullPointerException
data:  3ê±´ì´
data:  ë°œìƒí–ˆìŠµë‹ˆë‹¤.
data: [DONE]
```

**ì—ëŸ¬ ì‹œ**:
```
data: [ERROR]
data: {"error": "Connection timeout"}
```

---

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. CRLF/LF ì¤„ë°”ê¿ˆ ë¬¸ì œ (WSL)

**ì¦ìƒ**:
```bash
./test_local.sh start
# -bash: ./test_local.sh: cannot execute: required file not found
```

**ì›ì¸**: Windowsì—ì„œ ìƒì„±ëœ íŒŒì¼ì´ CRLF ì¤„ë°”ê¿ˆ ì‚¬ìš©

**í•´ê²°**:
```bash
# ë°©ë²• 1: sed ë³€í™˜
sed -i 's/\r$//' test_local.sh
chmod +x test_local.sh

# ë°©ë²• 2: dos2unix ì‚¬ìš©
sudo apt-get install dos2unix
dos2unix test_local.sh
```

---

### 2. Docker ê¶Œí•œ ë¬¸ì œ

**ì¦ìƒ**:
```
permission denied while trying to connect to the Docker daemon socket
```

**í•´ê²°**:
```bash
# 1. docker ê·¸ë£¹ì— ì¶”ê°€
sudo usermod -aG docker $USER

# 2. WSL ì™„ì „ ì¬ì‹œì‘ (PowerShellì—ì„œ)
wsl --shutdown
# WSL ë‹¤ì‹œ ì‹œì‘

# 3. í™•ì¸
groups  # "docker" í¬í•¨ë˜ì–´ì•¼ í•¨
```

**ì„ì‹œ í•´ê²°** (ê¶Œì¥í•˜ì§€ ì•ŠìŒ):
```bash
sudo docker compose up -d
```

---

### 3. Python ì‹¤í–‰ ê²½ë¡œ ë¬¸ì œ

**ì¦ìƒ**:
```bash
python scripts/create_indices.py
# -bash: python: cannot execute: required file not found
```

**ì›ì¸**: WSLì—ì„œ Windows pyenv shim ì‹¤í–‰ ì‹œë„

**í•´ê²°**:
```bash
# python3 ì‚¬ìš©
python3 scripts/create_indices.py

# ë˜ëŠ” ê°€ìƒí™˜ê²½ ìƒì„±
python3 -m venv venv
source venv/bin/activate
python scripts/create_indices.py
```

---

### 4. OpenSearch ì—°ê²° ì‹¤íŒ¨

**ì¦ìƒ**:
```
ConnectionError: Failed to resolve 'opensearch'
```

**ì›ì¸**: ë¡œì»¬ì—ì„œ ì‹¤í–‰ ì‹œ `localhost` ì‚¬ìš©í•´ì•¼ í•¨

**í•´ê²°**:
```bash
# .env.test íŒŒì¼ ì‚¬ìš© (ìë™)
python scripts/create_indices.py

# ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì§ì ‘ ì§€ì •
OPENSEARCH_HOST=localhost python scripts/create_indices.py
```

---

### 5. OpenSearch ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨

#### 5-1. space_type ì—ëŸ¬

**ì¦ìƒ**:
```
'hnsw' configuration does not support space type: 'cosinesimil'
```

**ì›ì¸**: OpenSearch 2.xëŠ” `cosinesimil` ë¯¸ì§€ì›

**í•´ê²°**: âœ… ì´ë¯¸ ìˆ˜ì •ë¨
- `space_type: "innerproduct"` ì‚¬ìš©
- OpenAI ì„ë² ë”©ì€ ì •ê·œí™”ë¨ â†’ innerproduct = cosine

#### 5-2. flattened íƒ€ì… ì—ëŸ¬

**ì¦ìƒ**:
```
No handler for type [flattened] declared on field
```

**ì›ì¸**: OpenSearchëŠ” Elasticsearchì˜ `flattened` íƒ€ì… ë¯¸ì§€ì›

**í•´ê²°**: âœ… ì´ë¯¸ ìˆ˜ì •ë¨
- `flattened` â†’ `object` ë³€ê²½
- ë™ì¼í•œ ê¸°ëŠ¥ ìœ ì§€

---

### 6. FastAPI ì„œë²„ ì‹œì‘ ì‹¤íŒ¨

#### 6-1. í¬íŠ¸ ì¶©ëŒ

**ì¦ìƒ**:
```
[Errno 98] Address already in use
```

**í•´ê²°**:
```bash
# í¬íŠ¸ ì‚¬ìš© í”„ë¡œì„¸ìŠ¤ í™•ì¸
lsof -i :8000

# í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
kill -9 <PID>

# ë˜ëŠ” ë‹¤ë¥¸ í¬íŠ¸ ì‚¬ìš©
uvicorn app.main:app --port 8001
```

#### 6-2. ëª¨ë“ˆ Import ì—ëŸ¬

**ì¦ìƒ**:
```
ModuleNotFoundError: No module named 'opensearchpy'
```

**í•´ê²°**:
```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” í™•ì¸
source venv/bin/activate

# ì˜ì¡´ì„± ì¬ì„¤ì¹˜
pip install -r requirements.txt
```

---

### 7. OpenAI API ì—ëŸ¬

**ì¦ìƒ**:
```
AuthenticationError: Invalid API key
```

**í•´ê²°**:
1. `.env.test` íŒŒì¼ì˜ API í‚¤ í™•ì¸
2. SSAFY GMSì—ì„œ ìƒˆ í‚¤ ë°œê¸‰: https://gms.ssafy.io/
3. API í‚¤ ì•ë¶€ë¶„ í™•ì¸: `S13P32A306-...`

---

### 8. CORS ì—ëŸ¬ (í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™)

**ì¦ìƒ**:
```
Access to XMLHttpRequest blocked by CORS policy
```

**í•´ê²°**:
`.env.test` íŒŒì¼ì— í”„ë¡ íŠ¸ì—”ë“œ URL ì¶”ê°€:
```bash
CORS_ORIGINS=["http://localhost:3000","http://localhost:5173","http://localhost:8080"]
```

ì„œë²„ ì¬ì‹œì‘ í•„ìš”

---

## âš¡ ì„±ëŠ¥ ìµœì í™”

### 1. 3ë‹¨ê³„ ìºì‹± ì „ëµ

#### ì„ë² ë”© ìºì‹œ (embedding_service.py)
- **ëª©ì **: ë™ì¼í•œ í…ìŠ¤íŠ¸ì˜ ë°˜ë³µ ì„ë² ë”© ë°©ì§€
- **ë°©ì‹**: ë©”ëª¨ë¦¬ ìºì‹œ (cachetools)
- **íš¨ê³¼**: 97-99% ë¹„ìš© ì ˆê°

#### QA ìºì‹œ (chatbot_service.py)
- **ëª©ì **: ìœ ì‚¬í•œ ì§ˆë¬¸ì˜ ì¬ê³„ì‚° ë°©ì§€
- **ë°©ì‹**: OpenSearch ë²¡í„° ê²€ìƒ‰ (similarity >= 0.8)
- **ê²€ì¦**: 2ë‹¨ê³„ (ì˜ë¯¸ ìœ ì‚¬ë„ + ë©”íƒ€ë°ì´í„° ë§¤ì¹­)
- **TTL**: ë™ì  ê³„ì‚°
  - ì¦‰ì‹œì„± ì§ˆë¬¸ ("ë°©ê¸ˆ", "ì§€ê¸ˆ"): 10ë¶„
  - ì¼ë°˜ ì§ˆë¬¸: 30ë¶„
  - ì ˆëŒ€ ë‚ ì§œ ì§ˆë¬¸ ("2024-01-15"): 1ì¼

#### Trace ìºì‹± (log_analysis_service.py)
- **ëª©ì **: ê°™ì€ trace_id ë¡œê·¸ ì¬ë¶„ì„ ë°©ì§€
- **ë°©ì‹**: OpenSearch ì €ì¥ (ai_analysis í•„ë“œ)
- **íš¨ê³¼**: ë™ì¼ trace ì¬ìš”ì²­ ì‹œ ì¦‰ì‹œ ì‘ë‹µ

### 2. Map-Reduce íŒ¨í„´

**íŠ¸ë¦¬ê±° ì¡°ê±´**: ë¡œê·¸ ê°œìˆ˜ > 10ê°œ

**Map ë‹¨ê³„**:
```python
# 15ê°œ ë¡œê·¸ â†’ 3ê°œ ì²­í¬ (5ê°œì”©)
chunks = [logs[0:5], logs[5:10], logs[10:15]]

# ê° ì²­í¬ ìš”ì•½
summaries = []
for chunk in chunks:
    summary = log_summarization_chain.ainvoke(chunk)
    summaries.append(summary)
```

**Reduce ë‹¨ê³„**:
```python
# ìš”ì•½ ê²°í•© ë° ìµœì¢… ë¶„ì„
combined = "\n\n".join(summaries)
result = log_analysis_chain.ainvoke(combined)
```

**íš¨ê³¼**:
- LLM í† í° ì œí•œ ìš°íšŒ (4k â†’ ë¬´ì œí•œ)
- ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ
- ëŒ€ê·œëª¨ trace ë¶„ì„ ê°€ëŠ¥

### 3. Chat History Truncation

**ëª©ì **: LLM ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬

**ì „ëµ**:
```python
def _truncate_history(chat_history, max_tokens=1500):
    """ìµœê·¼ ë©”ì‹œì§€ë¶€í„° ì—­ìˆœìœ¼ë¡œ ì¶”ê°€"""
    truncated = []
    total_tokens = 0

    for msg in reversed(chat_history):
        msg_tokens = len(encoding.encode(msg.content))
        if total_tokens + msg_tokens > max_tokens:
            break
        truncated.append(msg)
        total_tokens += msg_tokens

    return list(reversed(truncated))
```

**íš¨ê³¼**:
- í† í° ì˜ˆì‚° ìœ ì§€ (1500 tokens)
- ìµœì‹  ì»¨í…ìŠ¤íŠ¸ ìš°ì„  ë³´ì¡´

### 4. Vector Search ìµœì í™”

**HNSW ì•Œê³ ë¦¬ì¦˜ ì„¤ì •**:
```python
"method": {
    "name": "hnsw",
    "space_type": "innerproduct",  # OpenAI ì„ë² ë”© ìµœì í™”
    "engine": "faiss",  # GPU ê°€ì† ê°€ëŠ¥
    "parameters": {
        "ef_construction": 128,  # ì¸ë±ìŠ¤ ë¹Œë“œ í’ˆì§ˆ
        "m": 16  # ì—°ê²° ìˆ˜
    }
}
```

**ê²€ìƒ‰ íŒŒë¼ë¯¸í„°**:
- `k=5`: ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
- `similarity >= 0.8`: ìœ ì‚¬ë„ ì„ê³„ê°’

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### Prometheus ë©”íŠ¸ë¦­

**ì—”ë“œí¬ì¸íŠ¸**: `http://localhost:18000/metrics`

**ì£¼ìš” ë©”íŠ¸ë¦­**:
- `http_requests_total`: ì´ ìš”ì²­ ìˆ˜
- `http_request_duration_seconds`: ìš”ì²­ ì²˜ë¦¬ ì‹œê°„
- `cache_hits_total`: ìºì‹œ ì ì¤‘ íšŸìˆ˜
- `opensearch_queries_total`: OpenSearch ì¿¼ë¦¬ ìˆ˜
- `llm_tokens_total`: LLM í† í° ì‚¬ìš©ëŸ‰

### Grafana ëŒ€ì‹œë³´ë“œ

**ì ‘ì†**: `http://localhost:3000`
**ê³„ì •**: admin / admin123

**ì£¼ìš” íŒ¨ë„**:
1. Request Rate (QPS)
2. Response Time (P50, P95, P99)
3. Cache Hit Rate
4. Error Rate
5. LLM Token Usage

---

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

### í”„ë¡œì íŠ¸ ë¬¸ì„œ

- [README.md](./README.md) - í”„ë¡œì íŠ¸ ê°œìš”
- [PROJECT_STATUS.md](./PROJECT_STATUS.md) - í˜„ì¬ ìƒíƒœ
- [DEPLOYMENT_GUIDE.md](./DEPLOYMENT_GUIDE.md) - ë°°í¬ ê°€ì´ë“œ
- [LOCAL_TEST_GUIDE.md](./LOCAL_TEST_GUIDE.md) - ë¡œì»¬ í…ŒìŠ¤íŠ¸ ìƒì„¸ ê°€ì´ë“œ

### ì™¸ë¶€ ë¬¸ì„œ

- [FastAPI ê³µì‹ ë¬¸ì„œ](https://fastapi.tiangolo.com/)
- [OpenSearch ê³µì‹ ë¬¸ì„œ](https://opensearch.org/docs/latest/)
- [LangChain ê³µì‹ ë¬¸ì„œ](https://python.langchain.com/)
- [OpenAI API ë¬¸ì„œ](https://platform.openai.com/docs/)

---

## ğŸ”„ ì—…ë°ì´íŠ¸ ì´ë ¥

| ë‚ ì§œ | ë²„ì „ | ë³€ê²½ ë‚´ì—­ |
|------|------|----------|
| 2025-01-15 | 1.0.0 | ì´ˆê¸° ë¬¸ì„œ ì‘ì„± |

---

**ë¬¸ì˜**: í”„ë¡œì íŠ¸ íŒ€ (S13P31A306)
