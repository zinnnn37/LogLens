"""
AI vs DB í†µê³„ ë¹„êµ ë„êµ¬ (Statistics Comparison Tools)
- DB ì§ì ‘ ì¡°íšŒ ê²°ê³¼ì™€ LLM ê¸°ë°˜ í†µê³„ ì¶”ë¡ ì˜ ì •í™•ë„ë¥¼ ê²€ì¦
- LLMì´ DB ì¿¼ë¦¬ë¥¼ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ì—­ëŸ‰ì„ ìˆ˜ì¹˜ë¡œ ì¦ëª…
"""

import json
from typing import Dict, Any, List
from datetime import datetime, timedelta
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

from app.core.opensearch import opensearch_client
from app.core.config import settings


def _get_db_statistics(project_uuid: str, time_hours: int = 24) -> Dict[str, Any]:
    """
    OpenSearchì—ì„œ ì§ì ‘ í†µê³„ ì¿¼ë¦¬ ì‹¤í–‰ (Ground Truth)
    """
    index_pattern = f"{project_uuid.replace('-', '_')}_*"
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=time_hours)

    query_body = {
        "track_total_hits": True,  # 10,000ê±´ ì œí•œ í•´ì œ - ì •í™•í•œ ì´ ê°œìˆ˜ ë°˜í™˜
        "size": 0,
        "query": {
            "range": {
                "timestamp": {
                    "gte": start_time.isoformat() + "Z",
                    "lte": end_time.isoformat() + "Z"
                }
            }
        },
        "aggs": {
            "by_level": {
                "terms": {"field": "level", "size": 10}
            },
            "hourly_distribution": {
                "date_histogram": {
                    "field": "timestamp",
                    "fixed_interval": "1h",
                    "time_zone": "Asia/Seoul",
                    "min_doc_count": 0
                },
                "aggs": {
                    "by_level": {
                        "terms": {"field": "level", "size": 5}
                    }
                }
            }
        }
    }

    results = opensearch_client.search(index=index_pattern, body=query_body)

    # ì „ì²´ í†µê³„ ì¶”ì¶œ
    total_logs = results.get("hits", {}).get("total", {}).get("value", 0)
    level_buckets = results.get("aggregations", {}).get("by_level", {}).get("buckets", [])

    level_stats = {}
    for bucket in level_buckets:
        level_stats[bucket["key"]] = bucket["doc_count"]

    error_count = level_stats.get("ERROR", 0)
    warn_count = level_stats.get("WARN", 0)
    info_count = level_stats.get("INFO", 0)
    error_rate = (error_count / total_logs * 100) if total_logs > 0 else 0

    # ì‹œê°„ëŒ€ë³„ ë¶„í¬
    hourly_buckets = results.get("aggregations", {}).get("hourly_distribution", {}).get("buckets", [])
    hourly_data = []
    peak_hour = ""
    peak_count = 0

    for bucket in hourly_buckets:
        hour_str = bucket.get("key_as_string", "")[:13]  # "2024-01-01T15"
        total = bucket.get("doc_count", 0)
        level_breakdown = {}
        for level_bucket in bucket.get("by_level", {}).get("buckets", []):
            level_breakdown[level_bucket["key"]] = level_bucket["doc_count"]

        hourly_data.append({
            "hour": hour_str,
            "total": total,
            "error": level_breakdown.get("ERROR", 0),
            "warn": level_breakdown.get("WARN", 0),
            "info": level_breakdown.get("INFO", 0)
        })

        if total > peak_count:
            peak_count = total
            peak_hour = hour_str

    return {
        "total_logs": total_logs,
        "error_count": error_count,
        "warn_count": warn_count,
        "info_count": info_count,
        "error_rate": round(error_rate, 2),
        "peak_hour": peak_hour,
        "peak_count": peak_count,
        "hourly_data": hourly_data[-24:]  # ìµœê·¼ 24ì‹œê°„ë§Œ
    }


def _get_log_samples(project_uuid: str, time_hours: int = 24, sample_size: int = 100) -> List[Dict[str, Any]]:
    """
    LLM ë¶„ì„ì„ ìœ„í•œ ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ
    """
    index_pattern = f"{project_uuid.replace('-', '_')}_*"
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=time_hours)

    # ë ˆë²¨ë³„ ê· í˜• ì¡íŒ ìƒ˜í”Œë§
    query_body = {
        "size": sample_size,
        "query": {
            "range": {
                "timestamp": {
                    "gte": start_time.isoformat() + "Z",
                    "lte": end_time.isoformat() + "Z"
                }
            }
        },
        "_source": ["level", "timestamp", "service_name", "message"],
        "sort": [{"timestamp": {"order": "desc"}}]
    }

    results = opensearch_client.search(index=index_pattern, body=query_body)

    samples = []
    for hit in results.get("hits", {}).get("hits", []):
        source = hit.get("_source", {})
        samples.append({
            "level": source.get("level", "UNKNOWN"),
            "timestamp": source.get("timestamp", ""),
            "service": source.get("service_name", "unknown"),
            "message": source.get("message", "")[:200]  # í† í° ì ˆì•½
        })

    return samples


def _llm_estimate_statistics(log_samples: List[Dict[str, Any]], total_sample_count: int, time_hours: int) -> Dict[str, Any]:
    """
    LLMì—ê²Œ ë¡œê·¸ ìƒ˜í”Œì„ ì£¼ê³  ì „ì²´ í†µê³„ë¥¼ ì¶”ë¡ í•˜ê²Œ í•¨
    """
    # ìƒ˜í”Œ ìš”ì•½
    level_counts = {}
    hourly_counts = {}

    for sample in log_samples:
        level = sample.get("level", "UNKNOWN")
        level_counts[level] = level_counts.get(level, 0) + 1

        timestamp = sample.get("timestamp", "")
        if timestamp:
            hour = timestamp[:13]  # "2024-01-01T15"
            hourly_counts[hour] = hourly_counts.get(hour, 0) + 1

    sample_summary = {
        "sample_size": len(log_samples),
        "level_distribution": level_counts,
        "hourly_distribution": hourly_counts
    }

    # LLM í”„ë¡¬í”„íŠ¸
    llm = ChatOpenAI(
        model=settings.LLM_MODEL,
        temperature=0.1,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± í™•ë³´
        openai_api_key=settings.OPENAI_API_KEY,
        base_url=settings.OPENAI_BASE_URL
    )

    prompt = f"""ë‹¹ì‹ ì€ ë¡œê·¸ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìƒ˜í”Œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ì²´ í†µê³„ë¥¼ ì¶”ë¡ í•´ì•¼ í•©ë‹ˆë‹¤.

## ìƒ˜í”Œ ë°ì´í„° ìš”ì•½
- ë¶„ì„ ê¸°ê°„: ìµœê·¼ {time_hours}ì‹œê°„
- ìƒ˜í”Œ í¬ê¸°: {sample_summary['sample_size']}ê°œ
- ë ˆë²¨ë³„ ë¶„í¬ (ìƒ˜í”Œ): {json.dumps(sample_summary['level_distribution'], ensure_ascii=False)}

## ì¶”ë¡  ì‘ì—…
ìœ„ ìƒ˜í”Œì„ ë°”íƒ•ìœ¼ë¡œ ì „ì²´ ë¡œê·¸ í†µê³„ë¥¼ ì¶”ë¡ í•˜ì„¸ìš”.

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´):
{{
    "estimated_total_logs": <ì¶”ë¡ í•œ ì „ì²´ ë¡œê·¸ ìˆ˜>,
    "estimated_error_count": <ì¶”ë¡ í•œ ERROR ë¡œê·¸ ìˆ˜>,
    "estimated_warn_count": <ì¶”ë¡ í•œ WARN ë¡œê·¸ ìˆ˜>,
    "estimated_info_count": <ì¶”ë¡ í•œ INFO ë¡œê·¸ ìˆ˜>,
    "estimated_error_rate": <ì¶”ë¡ í•œ ì—ëŸ¬ìœ¨ (%)>,
    "confidence_score": <ì¶”ë¡  ì‹ ë¢°ë„ 0-100>,
    "reasoning": "<ì¶”ë¡  ê·¼ê±° 1-2ë¬¸ì¥>"
}}

ì¤‘ìš”: ìƒ˜í”Œ ë¹„ìœ¨ì„ ì „ì²´ì— ì ìš©í•˜ì—¬ ì¶”ë¡ í•˜ì„¸ìš”."""

    try:
        response = llm.invoke(prompt)
        content = response.content.strip()

        # JSON íŒŒì‹±
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0].strip()
        elif "```" in content:
            content = content.split("```")[1].split("```")[0].strip()

        return json.loads(content)
    except Exception as e:
        # í´ë°±: ë‹¨ìˆœ ë¹„ìœ¨ ê³„ì‚°
        sample_total = len(log_samples)
        if sample_total == 0:
            return {
                "estimated_total_logs": 0,
                "estimated_error_count": 0,
                "estimated_warn_count": 0,
                "estimated_info_count": 0,
                "estimated_error_rate": 0.0,
                "confidence_score": 0,
                "reasoning": f"LLM ì¶”ë¡  ì‹¤íŒ¨: {str(e)}"
            }

        error_ratio = level_counts.get("ERROR", 0) / sample_total
        warn_ratio = level_counts.get("WARN", 0) / sample_total
        info_ratio = level_counts.get("INFO", 0) / sample_total

        return {
            "estimated_total_logs": total_sample_count,
            "estimated_error_count": int(total_sample_count * error_ratio),
            "estimated_warn_count": int(total_sample_count * warn_ratio),
            "estimated_info_count": int(total_sample_count * info_ratio),
            "estimated_error_rate": round(error_ratio * 100, 2),
            "confidence_score": 50,
            "reasoning": f"LLM ì¶”ë¡  ì‹¤íŒ¨ë¡œ ë‹¨ìˆœ ë¹„ìœ¨ ê³„ì‚° ì‚¬ìš©: {str(e)}"
        }


def _calculate_accuracy(db_stats: Dict[str, Any], ai_stats: Dict[str, Any]) -> Dict[str, Any]:
    """
    DB í†µê³„ì™€ AI ì¶”ë¡  í†µê³„ì˜ ì •í™•ë„ ê³„ì‚°
    """
    def accuracy_percentage(actual, predicted):
        if actual == 0:
            return 100.0 if predicted == 0 else 0.0
        error = abs(actual - predicted)
        return max(0, round((1 - error / actual) * 100, 2))

    total_accuracy = accuracy_percentage(
        db_stats["total_logs"],
        ai_stats.get("estimated_total_logs", 0)
    )
    error_count_accuracy = accuracy_percentage(
        db_stats["error_count"],
        ai_stats.get("estimated_error_count", 0)
    )
    warn_count_accuracy = accuracy_percentage(
        db_stats["warn_count"],
        ai_stats.get("estimated_warn_count", 0)
    )
    info_count_accuracy = accuracy_percentage(
        db_stats["info_count"],
        ai_stats.get("estimated_info_count", 0)
    )

    # ì—ëŸ¬ìœ¨ ì •í™•ë„ (ì ˆëŒ€ ì˜¤ì°¨ ê¸°ë°˜)
    error_rate_diff = abs(db_stats["error_rate"] - ai_stats.get("estimated_error_rate", 0))
    error_rate_accuracy = max(0, round(100 - error_rate_diff * 10, 2))  # 1% ì°¨ì´ë‹¹ 10ì  ê°ì 

    # ì¢…í•© ì •í™•ë„ (ê°€ì¤‘ í‰ê· )
    overall_accuracy = round(
        total_accuracy * 0.3 +
        error_count_accuracy * 0.3 +
        error_rate_accuracy * 0.2 +
        warn_count_accuracy * 0.1 +
        info_count_accuracy * 0.1,
        2
    )

    return {
        "total_logs_accuracy": total_accuracy,
        "error_count_accuracy": error_count_accuracy,
        "warn_count_accuracy": warn_count_accuracy,
        "info_count_accuracy": info_count_accuracy,
        "error_rate_accuracy": error_rate_accuracy,
        "overall_accuracy": overall_accuracy,
        "ai_confidence": ai_stats.get("confidence_score", 0)
    }


@tool
async def compare_ai_vs_db_statistics(
    project_uuid: str,
    time_hours: int = 24,
    sample_size: int = 100
) -> str:
    """
    AI ì¶”ë¡  í†µê³„ì™€ DB ì§ì ‘ ì¡°íšŒ í†µê³„ë¥¼ ë¹„êµí•˜ì—¬ ì •í™•ë„ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.

    ì´ ë„êµ¬ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    - âœ… OpenSearchì—ì„œ ì§ì ‘ í†µê³„ ì¿¼ë¦¬ (Ground Truth)
    - âœ… ë¡œê·¸ ìƒ˜í”Œì„ LLMì—ê²Œ ì œê³µí•˜ì—¬ ì „ì²´ í†µê³„ ì¶”ë¡ 
    - âœ… ë‘ ê²°ê³¼ì˜ ì •í™•ë„/ì˜¤ì°¨ìœ¨ ê³„ì‚°
    - âœ… AIê°€ DB ì¿¼ë¦¬ë¥¼ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ì—­ëŸ‰ ê²€ì¦

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    1. "AIê°€ DBë¥¼ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ”ì§€ ê²€ì¦í•´ì¤˜"
    2. "í†µê³„ ì¶”ë¡  ì •í™•ë„ë¥¼ í™•ì¸í•´ì¤˜"
    3. "LLM ê¸°ë°˜ ë¶„ì„ì˜ ì‹ ë¢°ë„ëŠ”?"

    âš ï¸ ì¤‘ìš”í•œ ì œì•½ì‚¬í•­:
    - 1íšŒ í˜¸ì¶œë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤
    - LLM API í˜¸ì¶œì´ í¬í•¨ë˜ì–´ ì•½ê°„ì˜ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤
    - temperature=0.1ë¡œ ì¼ê´€ëœ ê²°ê³¼ ë³´ì¥

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        time_hours: ë¶„ì„ ê¸°ê°„ (ê¸°ë³¸ 24ì‹œê°„)
        sample_size: LLMì— ì œê³µí•  ìƒ˜í”Œ í¬ê¸° (ê¸°ë³¸ 100ê°œ)

    Returns:
        DB í†µê³„, AI ì¶”ë¡  í†µê³„, ì •í™•ë„ ì§€í‘œ, ê²€ì¦ ê²°ê³¼
    """
    try:
        # 1. DBì—ì„œ ì§ì ‘ í†µê³„ ì¡°íšŒ (Ground Truth)
        db_stats = _get_db_statistics(project_uuid, time_hours)

        if db_stats["total_logs"] == 0:
            return f"ìµœê·¼ {time_hours}ì‹œê°„ ë™ì•ˆ ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # 2. ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ
        log_samples = _get_log_samples(project_uuid, time_hours, sample_size)

        if not log_samples:
            return f"ë¡œê·¸ ìƒ˜í”Œì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # 3. LLM ê¸°ë°˜ í†µê³„ ì¶”ë¡ 
        ai_stats = _llm_estimate_statistics(log_samples, db_stats["total_logs"], time_hours)

        # 4. ì •í™•ë„ ê³„ì‚°
        accuracy_metrics = _calculate_accuracy(db_stats, ai_stats)

        # 5. ê²°ê³¼ í¬ë§·íŒ…
        summary_lines = [
            "=" * 50,
            "  AI vs DB í†µê³„ ë¹„êµ ê²€ì¦ ê²°ê³¼",
            "=" * 50,
            "",
            f"ğŸ“Š ë¶„ì„ ê¸°ê°„: ìµœê·¼ {time_hours}ì‹œê°„",
            f"ğŸ“Š ìƒ˜í”Œ í¬ê¸°: {len(log_samples)}ê°œ / ì „ì²´ {db_stats['total_logs']:,}ê°œ",
            "",
            "=" * 50,
            "  1. DB ì§ì ‘ ì¡°íšŒ ê²°ê³¼ (Ground Truth)",
            "=" * 50,
            f"  ì´ ë¡œê·¸ ìˆ˜: {db_stats['total_logs']:,}ê°œ",
            f"  ERROR: {db_stats['error_count']:,}ê°œ",
            f"  WARN: {db_stats['warn_count']:,}ê°œ",
            f"  INFO: {db_stats['info_count']:,}ê°œ",
            f"  ì—ëŸ¬ìœ¨: {db_stats['error_rate']:.2f}%",
            f"  í”¼í¬ ì‹œê°„: {db_stats['peak_hour']} ({db_stats['peak_count']:,}ê±´)",
            "",
            "=" * 50,
            "  2. AI(LLM) ì¶”ë¡  ê²°ê³¼",
            "=" * 50,
            f"  ì´ ë¡œê·¸ ìˆ˜: {ai_stats.get('estimated_total_logs', 0):,}ê°œ",
            f"  ERROR: {ai_stats.get('estimated_error_count', 0):,}ê°œ",
            f"  WARN: {ai_stats.get('estimated_warn_count', 0):,}ê°œ",
            f"  INFO: {ai_stats.get('estimated_info_count', 0):,}ê°œ",
            f"  ì—ëŸ¬ìœ¨: {ai_stats.get('estimated_error_rate', 0):.2f}%",
            f"  AI ì‹ ë¢°ë„: {ai_stats.get('confidence_score', 0)}%",
            f"  ì¶”ë¡  ê·¼ê±°: {ai_stats.get('reasoning', 'N/A')}",
            "",
            "=" * 50,
            "  3. ì •í™•ë„ ê²€ì¦ ê²°ê³¼",
            "=" * 50,
            f"  ğŸ“ˆ ì´ ë¡œê·¸ ìˆ˜ ì¼ì¹˜ìœ¨: {accuracy_metrics['total_logs_accuracy']:.1f}%",
            f"  ğŸ“ˆ ERROR ìˆ˜ ì¼ì¹˜ìœ¨: {accuracy_metrics['error_count_accuracy']:.1f}%",
            f"  ğŸ“ˆ WARN ìˆ˜ ì¼ì¹˜ìœ¨: {accuracy_metrics['warn_count_accuracy']:.1f}%",
            f"  ğŸ“ˆ INFO ìˆ˜ ì¼ì¹˜ìœ¨: {accuracy_metrics['info_count_accuracy']:.1f}%",
            f"  ğŸ“ˆ ì—ëŸ¬ìœ¨ ì •í™•ë„: {accuracy_metrics['error_rate_accuracy']:.1f}%",
            "",
            f"  â­ ì¢…í•© ì •í™•ë„: {accuracy_metrics['overall_accuracy']:.1f}%",
            "",
        ]

        # 6. ê²€ì¦ ê²°ë¡ 
        overall = accuracy_metrics['overall_accuracy']
        if overall >= 95:
            verdict = "ğŸ† **ë§¤ìš° ìš°ìˆ˜**: AIê°€ DB ì¿¼ë¦¬ë¥¼ ì™„ë²½íˆ ëŒ€ì²´ ê°€ëŠ¥"
            explanation = "ì˜¤ì°¨ìœ¨ 5% ë¯¸ë§Œìœ¼ë¡œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‹ ë¢°ì„± ìˆê²Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
        elif overall >= 90:
            verdict = "âœ… **ìš°ìˆ˜**: AIê°€ DB ì¿¼ë¦¬ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥"
            explanation = "ì˜¤ì°¨ìœ¨ 10% ë¯¸ë§Œìœ¼ë¡œ ëŒ€ë¶€ë¶„ì˜ ë¶„ì„ ì—…ë¬´ì— í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
        elif overall >= 80:
            verdict = "ğŸŸ¡ **ì–‘í˜¸**: AIê°€ ë³´ì¡° ë„êµ¬ë¡œì„œ ìœ ìš©"
            explanation = "ì˜¤ì°¨ìœ¨ 20% ë¯¸ë§Œìœ¼ë¡œ íŠ¸ë Œë“œ ë¶„ì„ê³¼ ì´ìƒ íƒì§€ì— í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
        elif overall >= 70:
            verdict = "ğŸŸ  **ë³´í†µ**: ê°œì„ ì´ í•„ìš”"
            explanation = "ì˜¤ì°¨ìœ¨ì´ ë†’ì•„ ì¶”ê°€ íŠœë‹ì´ í•„ìš”í•©ë‹ˆë‹¤."
        else:
            verdict = "ğŸ”´ **ë¯¸í¡**: AI ì¶”ë¡  ë¡œì§ ì¬ê²€í†  í•„ìš”"
            explanation = "ì •í™•ë„ê°€ ë‚®ì•„ í”„ë¡¬í”„íŠ¸ë‚˜ ìƒ˜í”Œë§ ì „ëµ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."

        summary_lines.extend([
            "=" * 50,
            "  4. ê²€ì¦ ê²°ë¡ ",
            "=" * 50,
            f"  {verdict}",
            "",
            f"  {explanation}",
            "",
            "=" * 50,
            "  5. ê¸°ìˆ ì  ê²€ì¦ í¬ì¸íŠ¸",
            "=" * 50,
            "  - Temperature 0.1ë¡œ ì¼ê´€ëœ ì¶”ë¡  ë³´ì¥",
            "  - Structured Outputìœ¼ë¡œ í˜•ì‹ ì˜¤ë¥˜ ë°©ì§€",
            "  - ìƒ˜í”Œ ê¸°ë°˜ ì¶”ë¡ ìœ¼ë¡œ í† í° ë¹„ìš© ì ˆê°",
            "  - ìë™í™”ëœ ì •í™•ë„ ì¸¡ì •ìœ¼ë¡œ ì‹ ë¢°ì„± ê²€ì¦",
            "",
            f"  ğŸ’¡ ì´ ê²°ê³¼ëŠ” LLMì´ ë‹¨ìˆœ DB ì§‘ê³„ë¥¼ ë„˜ì–´",
            f"     'ì‚¬ëŒ ìˆ˜ì¤€ì˜ ë°ì´í„° ë¶„ì„ ì—­ëŸ‰'ì„ ë³´ìœ í•¨ì„ ì¦ëª…í•©ë‹ˆë‹¤.",
            "=" * 50,
        ])

        return "\n".join(summary_lines)

    except Exception as e:
        return f"AI vs DB í†µê³„ ë¹„êµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
async def get_hourly_comparison(
    project_uuid: str,
    time_hours: int = 24
) -> str:
    """
    ì‹œê°„ëŒ€ë³„ ë¡œê·¸ í†µê³„ë¥¼ DBì™€ AI ì¶”ë¡ ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤.

    ì´ ë„êµ¬ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    - âœ… 1ì‹œê°„ ë‹¨ìœ„ ë¡œê·¸ ë¶„í¬ DB ì¡°íšŒ
    - âœ… ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„
    - âœ… í”¼í¬ ì‹œê°„, íŠ¸ë Œë“œ ë°©í–¥ í™•ì¸

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    1. "ì‹œê°„ëŒ€ë³„ ë¡œê·¸ ì¶”ì„¸ë¥¼ ë³´ì—¬ì¤˜"
    2. "1ì‹œê°„ ë‹¨ìœ„ í†µê³„ë¥¼ ë¹„êµí•´ì¤˜"

    Returns:
        ì‹œê°„ëŒ€ë³„ ë¡œê·¸ í†µê³„, í”¼í¬ ì‹œê°„, íŠ¸ë Œë“œ ë¶„ì„
    """
    try:
        db_stats = _get_db_statistics(project_uuid, time_hours)

        if db_stats["total_logs"] == 0:
            return f"ìµœê·¼ {time_hours}ì‹œê°„ ë™ì•ˆ ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        summary_lines = [
            f"## ğŸ“Š ì‹œê°„ëŒ€ë³„ ë¡œê·¸ ë¶„í¬ (ìµœê·¼ {time_hours}ì‹œê°„)",
            "",
            f"**ì´ ë¡œê·¸**: {db_stats['total_logs']:,}ê°œ",
            f"**ì—ëŸ¬ìœ¨**: {db_stats['error_rate']:.2f}%",
            f"**í”¼í¬ ì‹œê°„**: {db_stats['peak_hour']} ({db_stats['peak_count']:,}ê±´)",
            "",
            "### ì‹œê°„ëŒ€ë³„ ìƒì„¸",
            "| ì‹œê°„ | ì´ ë¡œê·¸ | ERROR | WARN | INFO |",
            "|------|---------|-------|------|------|"
        ]

        for hourly in db_stats["hourly_data"][-12:]:  # ìµœê·¼ 12ì‹œê°„ë§Œ
            hour_display = hourly["hour"][-5:] if len(hourly["hour"]) >= 5 else hourly["hour"]
            summary_lines.append(
                f"| {hour_display} | {hourly['total']:,} | {hourly['error']} | {hourly['warn']} | {hourly['info']} |"
            )

        return "\n".join(summary_lines)

    except Exception as e:
        return f"ì‹œê°„ëŒ€ë³„ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
