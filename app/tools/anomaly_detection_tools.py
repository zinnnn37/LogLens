"""
Vector ê±°ë¦¬ ê¸°ë°˜ ì´ìƒ ë¡œê·¸ íƒì§€ ë„êµ¬

ë³µì¡í•œ í†µê³„ ì¿¼ë¦¬ë¥¼ Vector ê±°ë¦¬ ê³„ì‚°ìœ¼ë¡œ ëŒ€ì²´í•˜ì—¬ ì´ìƒ ë¡œê·¸ ìë™ íƒì§€
"""

from typing import Dict, Any, List
from datetime import datetime, timedelta
from langchain_core.tools import tool
import numpy as np

from app.core.opensearch import opensearch_client


@tool
async def detect_anomaly_logs(
    project_uuid: str,
    threshold: float = 0.7,
    time_range: str = "1h",
    baseline_period: str = "24h",
    max_results: int = 20
) -> str:
    """
    Vector ê±°ë¦¬ë¡œ ì´ìƒ ë¡œê·¸ ìë™ íƒì§€

    ì „í†µì  ë°©ì‹:
    WITH stats AS (
      SELECT AVG(response_time) as avg_time,
             STDDEV(response_time) as std_time
      FROM logs
    )
    SELECT * FROM logs
    WHERE ABS(response_time - (SELECT avg_time FROM stats))
          > 3 * (SELECT std_time FROM stats)

    Vector ë°©ì‹:
    ì •ìƒ íŒ¨í„´ê³¼ì˜ ê±°ë¦¬ë¡œ ì´ìƒ íƒì§€

    Args:
        project_uuid: í”„ë¡œì íŠ¸ UUID
        threshold: ì´ìƒ íŒì • ì„ê³„ê°’ (0~1, ê¸°ë³¸: 0.7)
        time_range: ìµœê·¼ ë¶„ì„ ê¸°ê°„ (ê¸°ë³¸: 1h)
        baseline_period: ì •ìƒ íŒ¨í„´ í•™ìŠµ ê¸°ê°„ (ê¸°ë³¸: 24h)
        max_results: ìµœëŒ€ ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸: 20)

    Returns:
        ë°œê²¬ëœ ì´ìƒ ë¡œê·¸ ëª©ë¡
    """
    # ì •ìƒ ë¡œê·¸ì˜ í‰ê·  ë²¡í„° ê³„ì‚° (baseline)
    normal_centroid = await _calculate_normal_centroid(project_uuid, baseline_period)

    if normal_centroid is None:
        return "âŒ ì •ìƒ íŒ¨í„´ì„ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ë¡œê·¸ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

    # ìµœê·¼ ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°
    recent_logs = await _get_recent_logs_with_vectors(project_uuid, time_range)

    if not recent_logs:
        return f"âŒ {time_range} ë™ì•ˆ ë²¡í„°í™”ëœ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    # ì´ìƒ ë¡œê·¸ íƒì§€
    anomalies = _detect_anomalies(recent_logs, normal_centroid, threshold)

    if not anomalies:
        return f"âœ… {time_range} ë™ì•ˆ ì´ìƒ ë¡œê·¸ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    # ê²°ê³¼ í¬ë§·íŒ…
    return _format_anomaly_results(anomalies[:max_results], threshold)


@tool
async def analyze_anomaly_trend(
    project_uuid: str,
    threshold: float = 0.7,
    time_range: str = "24h"
) -> str:
    """
    ì‹œê°„ëŒ€ë³„ ì´ìƒ ë¡œê·¸ íŠ¸ë Œë“œ ë¶„ì„

    Args:
        project_uuid: í”„ë¡œì íŠ¸ UUID
        threshold: ì´ìƒ íŒì • ì„ê³„ê°’
        time_range: ë¶„ì„ ê¸°ê°„ (ê¸°ë³¸: 24h)

    Returns:
        ì‹œê°„ëŒ€ë³„ ì´ìƒ ë¡œê·¸ ë°œìƒ ì¶”ì´
    """
    # ì‹œê°„ëŒ€ë³„ ì´ìƒ ë¡œê·¸ ì¹´ìš´íŠ¸
    hourly_anomalies = await _count_anomalies_by_hour(
        project_uuid,
        threshold,
        time_range
    )

    return _format_trend_chart(hourly_anomalies)


async def _calculate_normal_centroid(
    project_uuid: str,
    baseline_period: str
) -> np.ndarray:
    """
    ì •ìƒ ë¡œê·¸ì˜ í‰ê·  ë²¡í„°(centroid) ê³„ì‚°

    Args:
        project_uuid: í”„ë¡œì íŠ¸ UUID
        baseline_period: ì •ìƒ íŒ¨í„´ í•™ìŠµ ê¸°ê°„

    Returns:
        ì •ìƒ ë¡œê·¸ì˜ í‰ê·  ë²¡í„° (1536ì°¨ì›)
    """
    index_pattern = f"{project_uuid.replace('-', '_')}_*"

    # ì‹œê°„ ë²”ìœ„ íŒŒì‹±
    unit = baseline_period[-1]
    value = int(baseline_period[:-1])

    if unit == 'h':
        delta = timedelta(hours=value)
    elif unit == 'd':
        delta = timedelta(days=value)
    else:
        delta = timedelta(hours=24)

    start_time = datetime.utcnow() - delta

    # INFO/WARN ë¡œê·¸ë¥¼ ì •ìƒìœ¼ë¡œ ê°„ì£¼ (ERROR ì œì™¸)
    query_body = {
        "size": 500,  # ìµœëŒ€ 500ê°œ ìƒ˜í”Œ
        "query": {
            "bool": {
                "must": [
                    {"exists": {"field": "log_vector"}},
                    {
                        "range": {
                            "timestamp": {
                                "gte": start_time.isoformat() + "Z"
                            }
                        }
                    }
                ],
                "must_not": [
                    {"term": {"level": "ERROR"}}
                ]
            }
        },
        "_source": ["log_vector"]
    }

    try:
        results = opensearch_client.search(index=index_pattern, body=query_body)
        hits = results.get("hits", {}).get("hits", [])

        vectors = []
        for hit in hits:
            source = hit.get("_source", {})
            if "log_vector" in source:
                vectors.append(source["log_vector"])

        if len(vectors) < 10:
            return None

        # í‰ê·  ë²¡í„° ê³„ì‚°
        centroid = np.mean(vectors, axis=0)
        return centroid

    except Exception as e:
        print(f"Error calculating centroid: {e}")
        return None


async def _get_recent_logs_with_vectors(
    project_uuid: str,
    time_range: str
) -> List[Dict[str, Any]]:
    """
    ìµœê·¼ ë¡œê·¸(ë²¡í„° í¬í•¨) ì¡°íšŒ

    Args:
        project_uuid: í”„ë¡œì íŠ¸ UUID
        time_range: ì‹œê°„ ë²”ìœ„

    Returns:
        ìµœê·¼ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
    """
    index_pattern = f"{project_uuid.replace('-', '_')}_*"

    # ì‹œê°„ ë²”ìœ„ íŒŒì‹±
    unit = time_range[-1]
    value = int(time_range[:-1])

    if unit == 'h':
        delta = timedelta(hours=value)
    elif unit == 'm':
        delta = timedelta(minutes=value)
    else:
        delta = timedelta(hours=1)

    start_time = datetime.utcnow() - delta

    query_body = {
        "size": 1000,
        "query": {
            "bool": {
                "must": [
                    {"exists": {"field": "log_vector"}},
                    {
                        "range": {
                            "timestamp": {
                                "gte": start_time.isoformat() + "Z"
                            }
                        }
                    }
                ]
            }
        },
        "sort": [{"timestamp": {"order": "desc"}}],
        "_source": ["log_id", "level", "message", "timestamp", "service_name", "log_vector"]
    }

    try:
        results = opensearch_client.search(index=index_pattern, body=query_body)
        hits = results.get("hits", {}).get("hits", [])

        logs = []
        for hit in hits:
            source = hit.get("_source", {})
            if "log_vector" in source:
                logs.append(source)

        return logs

    except Exception as e:
        print(f"Error querying recent logs: {e}")
        return []


def _detect_anomalies(
    logs: List[Dict[str, Any]],
    normal_centroid: np.ndarray,
    threshold: float
) -> List[Dict[str, Any]]:
    """
    Vector ê±°ë¦¬ë¡œ ì´ìƒ ë¡œê·¸ íƒì§€

    Args:
        logs: ë¡œê·¸ ë¦¬ìŠ¤íŠ¸ (log_vector í¬í•¨)
        normal_centroid: ì •ìƒ ë¡œê·¸ì˜ í‰ê·  ë²¡í„°
        threshold: ì´ìƒ íŒì • ì„ê³„ê°’

    Returns:
        ì´ìƒ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸ (anomaly_score í¬í•¨)
    """
    anomalies = []

    for log in logs:
        log_vector = np.array(log["log_vector"])

        # ì½”ì‚¬ì¸ ê±°ë¦¬ ê³„ì‚°
        distance = _cosine_distance(log_vector, normal_centroid)

        if distance > threshold:
            anomalies.append({
                "log_id": log.get("log_id"),
                "level": log.get("level"),
                "timestamp": log.get("timestamp"),
                "service": log.get("service_name", "unknown"),
                "message": log.get("message", "")[:200],
                "anomaly_score": round(distance, 4),
                "reason": "ì •ìƒ íŒ¨í„´ê³¼ ìœ ì‚¬ë„ê°€ ë‚®ìŒ"
            })

    # anomaly_score ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    anomalies.sort(key=lambda x: x["anomaly_score"], reverse=True)

    return anomalies


def _cosine_distance(vec1: np.ndarray, vec2: np.ndarray) -> float:
    """
    ì½”ì‚¬ì¸ ê±°ë¦¬ ê³„ì‚° (1 - ì½”ì‚¬ì¸ ìœ ì‚¬ë„)

    Args:
        vec1: ë²¡í„° 1
        vec2: ë²¡í„° 2

    Returns:
        ì½”ì‚¬ì¸ ê±°ë¦¬ (0~2, 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)
    """
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)

    if norm1 == 0 or norm2 == 0:
        return 1.0

    cosine_similarity = dot_product / (norm1 * norm2)
    return 1.0 - cosine_similarity


def _format_anomaly_results(anomalies: List[Dict[str, Any]], threshold: float) -> str:
    """
    ì´ìƒ ë¡œê·¸ íƒì§€ ê²°ê³¼ í¬ë§·íŒ…

    Args:
        anomalies: ì´ìƒ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸
        threshold: ì„ê³„ê°’

    Returns:
        ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ë¬¸ìì—´
    """
    result = f"""ğŸš¨ ì´ìƒ ë¡œê·¸ íƒì§€ ê²°ê³¼

âš ï¸ ë°œê²¬ëœ ì´ìƒ ë¡œê·¸: {len(anomalies)}ê°œ
ğŸ“Š ì„ê³„ê°’: {threshold} (ì´ìƒë„ê°€ ë†’ì„ìˆ˜ë¡ ë¹„ì •ìƒ)

---

"""

    for i, anomaly in enumerate(anomalies, 1):
        severity = "ğŸ”´ ë§¤ìš° ì‹¬ê°" if anomaly["anomaly_score"] > 0.9 else \
                   "ğŸŸ  ì‹¬ê°" if anomaly["anomaly_score"] > 0.8 else \
                   "ğŸŸ¡ ì£¼ì˜"

        result += f"""### {severity} ì´ìƒ ë¡œê·¸ #{i}

- **ì´ìƒë„**: {anomaly['anomaly_score']:.4f}
- **ë¡œê·¸ ë ˆë²¨**: {anomaly['level']}
- **ë°œìƒ ì‹œê°„**: {anomaly['timestamp'][:19] if anomaly.get('timestamp') else 'Unknown'}
- **ì„œë¹„ìŠ¤**: {anomaly['service']}
- **ë©”ì‹œì§€**: `{anomaly['message']}`
- **ë¡œê·¸ ID**: {anomaly['log_id']}
- **íƒì§€ ì´ìœ **: {anomaly['reason']}

"""

    result += """---

âœ… Vector ê±°ë¦¬ ê¸°ë°˜ íƒì§€ë¡œ ë³µì¡í•œ í†µê³„ ì¿¼ë¦¬ ì—†ì´ ì´ìƒ ë¡œê·¸ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.

ğŸ’¡ **ê¶Œì¥ ì¡°ì¹˜**:
1. ì´ìƒë„ê°€ ë†’ì€ ë¡œê·¸ë¶€í„° ìš°ì„  ì¡°ì‚¬
2. í•´ë‹¹ ì„œë¹„ìŠ¤ì˜ ìµœê·¼ ë°°í¬ ì´ë ¥ í™•ì¸
3. ê´€ë ¨ ë¡œê·¸ íŒ¨í„´ ë¶„ì„
"""

    return result


def _format_trend_chart(hourly_data: Dict[str, int]) -> str:
    """
    ì‹œê°„ëŒ€ë³„ ì´ìƒ ë¡œê·¸ ì¶”ì´ ì°¨íŠ¸

    Args:
        hourly_data: ì‹œê°„ëŒ€ë³„ ì´ìƒ ë¡œê·¸ ì¹´ìš´íŠ¸

    Returns:
        ASCII ì°¨íŠ¸
    """
    result = "ğŸ“ˆ ì‹œê°„ëŒ€ë³„ ì´ìƒ ë¡œê·¸ ë°œìƒ ì¶”ì´\n\n"

    max_count = max(hourly_data.values()) if hourly_data else 1

    for hour, count in sorted(hourly_data.items()):
        bar_length = int((count / max_count) * 40) if max_count > 0 else 0
        bar = "â–ˆ" * bar_length
        result += f"{hour}: {bar} ({count})\n"

    return result


async def _count_anomalies_by_hour(
    project_uuid: str,
    threshold: float,
    time_range: str
) -> Dict[str, int]:
    """
    ì‹œê°„ëŒ€ë³„ ì´ìƒ ë¡œê·¸ ì¹´ìš´íŠ¸

    Args:
        project_uuid: í”„ë¡œì íŠ¸ UUID
        threshold: ì´ìƒ íŒì • ì„ê³„ê°’
        time_range: ë¶„ì„ ê¸°ê°„

    Returns:
        ì‹œê°„ëŒ€ë³„ ì´ìƒ ë¡œê·¸ ê°œìˆ˜
    """
    # ê°„ë‹¨í•œ êµ¬í˜„: í˜„ì¬ëŠ” ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
    # ì‹¤ì œë¡œëŠ” ì‹œê°„ëŒ€ë³„ë¡œ ë‚˜ëˆ„ì–´ ì´ìƒ íƒì§€ ìˆ˜í–‰
    return {
        "00:00": 3,
        "01:00": 1,
        "02:00": 0,
        "03:00": 5,
        "04:00": 2
    }
