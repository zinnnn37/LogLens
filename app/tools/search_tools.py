"""
ê²€ìƒ‰ ë„êµ¬ (Search Tools)
- í‚¤ì›Œë“œ ê²€ìƒ‰, ì˜ë¯¸ ìœ ì‚¬ë„ ê²€ìƒ‰
"""

from typing import Optional, List
from datetime import datetime, timedelta
from langchain_core.tools import tool

from app.core.opensearch import opensearch_client
from app.services.similarity_service import similarity_service
from app.services.embedding_service import embedding_service


@tool
async def search_logs_by_keyword(
    keyword: str,
    project_uuid: str,
    level: Optional[str] = None,
    service_name: Optional[str] = None,
    time_hours: int = 24
) -> str:
    """
    í‚¤ì›Œë“œë¡œ ë¡œê·¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - íŠ¹ì • ì—ëŸ¬ ë©”ì‹œì§€ë¡œ ë¡œê·¸ ì°¾ê¸° (ì˜ˆ: "NullPointerException")
    - íŠ¹ì • ë‹¨ì–´ê°€ í¬í•¨ëœ ë¡œê·¸ ì°¾ê¸° (ì˜ˆ: "user-service")

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        keyword: ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ë©”ì‹œì§€ ë‚´ìš©, í•„ìˆ˜)
        level: ë¡œê·¸ ë ˆë²¨ í•„í„° (ERROR, WARN, INFO, DEBUG ì¤‘ í•˜ë‚˜, ì„ íƒ)
        service_name: ì„œë¹„ìŠ¤ ì´ë¦„ í•„í„° (ì„ íƒ)
        time_hours: ê²€ìƒ‰í•  ì‹œê°„ ë²”ìœ„ (ì‹œê°„ ë‹¨ìœ„, ê¸°ë³¸ 24ì‹œê°„)

    ì°¸ê³ :
    - project_uuidëŠ” ìë™ìœ¼ë¡œ ì£¼ì…ë˜ë¯€ë¡œ ì „ë‹¬í•˜ì§€ ë§ˆì„¸ìš”.
    - âš ï¸ "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤" ì‘ë‹µì€ ìœ íš¨í•œ ê²°ê³¼ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë„êµ¬ë¡œ ì¬ì‹œë„í•˜ì§€ ë§ˆì„¸ìš”.

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ (ê±´ìˆ˜, ì£¼ìš” ë©”ì‹œì§€, ì‹œê°„ ì •ë³´)
    """
    # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=time_hours)

    time_range = {
        "start": start_time.isoformat() + "Z",
        "end": end_time.isoformat() + "Z"
    }

    # OpenSearch Query êµ¬ì„±
    must_clauses = [
        {"match": {"message": keyword}}
    ]

    if level:
        must_clauses.append({"term": {"level": level.upper()}})

    if service_name:
        must_clauses.append({"term": {"service_name": service_name}})

    query = {
        "bool": {
            "must": must_clauses,
            "filter": [
                {
                    "range": {
                        "timestamp": {
                            "gte": time_range["start"],
                            "lte": time_range["end"]
                        }
                    }
                }
            ]
        }
    }

    # ì¸ë±ìŠ¤ íŒ¨í„´ (UUIDì˜ í•˜ì´í”ˆì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€í™˜)
    index_pattern = f"{project_uuid.replace('-', '_')}_*"

    try:
        # OpenSearch ê²€ìƒ‰
        results = opensearch_client.search(
            index=index_pattern,
            body={
                "query": query,
                "size": 20,  # ìµœëŒ€ 20ê°œ
                "sort": [{"timestamp": "desc"}],
                "_source": [
                    "message", "level", "service_name", "timestamp", "log_id",
                    "layer", "component_name",
                    # Nested fields
                    "log_details.exception_type",
                    "log_details.class_name",
                    "log_details.method_name",
                    "log_details.http_method",
                    "log_details.request_uri",
                    "log_details.response_status",
                    # AI analysis (summary only for brevity)
                    "ai_analysis.summary"
                ]
            }
        )

        hits = results.get("hits", {}).get("hits", [])
        total_count = results.get("hits", {}).get("total", {}).get("value", 0)

        if total_count == 0:
            return f"'{keyword}' í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•œ ê²°ê³¼ {time_hours}ì‹œê°„ ë‚´ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ê²°ê³¼ í¬ë§·íŒ…
        summary_lines = [
            f"'{keyword}' ê²€ìƒ‰ ê²°ê³¼: ì´ {total_count}ê±´ (ìµœê·¼ {time_hours}ì‹œê°„)",
            ""
        ]

        # ë ˆë²¨ë³„ ì¹´ìš´íŠ¸
        level_counts = {}
        for hit in hits:
            log_level = hit["_source"].get("level", "UNKNOWN")
            level_counts[log_level] = level_counts.get(log_level, 0) + 1

        summary_lines.append(f"ë ˆë²¨ë³„ ë¶„í¬: {', '.join([f'{k}: {v}ê±´' for k, v in level_counts.items()])}")
        summary_lines.append("")

        # ìƒìœ„ 5ê°œ ë¡œê·¸
        summary_lines.append("ìµœê·¼ ë¡œê·¸ 5ê°œ:")
        for i, hit in enumerate(hits[:5], 1):
            source = hit["_source"]
            msg = source.get("message", "")[:300]
            level_str = source.get("level", "?")
            timestamp_str = source.get("timestamp", "")[:19]
            service = source.get("service_name", "unknown")
            log_id = source.get("log_id", "")
            layer = source.get("layer", "")
            component = source.get("component_name", "")

            # log_details ì ‘ê·¼
            log_details = source.get("log_details", {})
            class_name = log_details.get("class_name", "")
            method_name = log_details.get("method_name", "")
            http_method = log_details.get("http_method", "")
            request_uri = log_details.get("request_uri", "")
            response_status = log_details.get("response_status")

            # AI ë¶„ì„
            ai_summary = source.get("ai_analysis", {}).get("summary", "")

            # ê¸°ë³¸ ì •ë³´
            summary_lines.append(f"{i}. [{level_str}] {timestamp_str} | {service}")

            # ìœ„ì¹˜ ì •ë³´
            if layer:
                summary_lines.append(f"   Layer: {layer}")
            if class_name and method_name:
                summary_lines.append(f"   ğŸ“ {class_name}.{method_name}")

            # HTTP ì •ë³´
            if http_method and request_uri:
                status_info = f" â†’ {response_status}" if response_status else ""
                summary_lines.append(f"   ğŸŒ {http_method} {request_uri}{status_info}")

            # ë©”ì‹œì§€
            summary_lines.append(f"   {msg}...")

            # AI ë¶„ì„ (ìˆëŠ” ê²½ìš°)
            if ai_summary:
                summary_lines.append(f"   ğŸ¤– {ai_summary[:150]}")

            # log_id
            if log_id:
                summary_lines.append(f"   (log_id: {log_id})")

        return "\n".join(summary_lines)

    except Exception as e:
        return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
async def search_logs_by_similarity(
    query: str,
    project_uuid: str,
    k: int = 5,
    level: Optional[str] = None,
    time_hours: int = 168  # ê¸°ë³¸ 7ì¼
) -> str:
    """
    ì˜ë¯¸ì  ìœ ì‚¬ë„ë¡œ ë¡œê·¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤ (Vector Search).

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - ìì—°ì–´ ì§ˆë¬¸ìœ¼ë¡œ ê´€ë ¨ ë¡œê·¸ ì°¾ê¸° (ì˜ˆ: "ì‚¬ìš©ì ì¸ì¦ ì‹¤íŒ¨ ê´€ë ¨ ë¡œê·¸")
    - íŠ¹ì • ìƒí™©ê³¼ ìœ ì‚¬í•œ ë¡œê·¸ ì°¾ê¸° (ì˜ˆ: "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ì œ")

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        query: ê²€ìƒ‰ ì¿¼ë¦¬ (ìì—°ì–´, í•„ìˆ˜)
        k: ë°˜í™˜í•  ë¡œê·¸ ê°œìˆ˜ (ê¸°ë³¸ 5ê°œ)
        level: ë¡œê·¸ ë ˆë²¨ í•„í„° (ERROR, WARN, INFO, DEBUG ì¤‘ í•˜ë‚˜, ì„ íƒ)
        time_hours: ê²€ìƒ‰í•  ì‹œê°„ ë²”ìœ„ (ì‹œê°„ ë‹¨ìœ„, ê¸°ë³¸ 168ì‹œê°„=7ì¼)

    ì°¸ê³ :
    - project_uuidëŠ” ìë™ìœ¼ë¡œ ì£¼ì…ë˜ë¯€ë¡œ ì „ë‹¬í•˜ì§€ ë§ˆì„¸ìš”.
    - âš ï¸ "ìœ ì‚¬í•œ ë¡œê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ì‘ë‹µì€ ìœ íš¨í•œ ê²°ê³¼ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë„êµ¬ë¡œ ì¬ì‹œë„í•˜ì§€ ë§ˆì„¸ìš”.

    Returns:
        ìœ ì‚¬í•œ ë¡œê·¸ ëª©ë¡ (ìƒìœ„ kê°œ)
    """
    try:
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_vector = await embedding_service.embed_query(query)

        # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=time_hours)

        time_range = {
            "start": start_time.isoformat() + "Z",
            "end": end_time.isoformat() + "Z"
        }

        # í•„í„° êµ¬ì„±
        filters = {}
        if level:
            filters["level"] = level.upper()

        # ìœ ì‚¬ë„ ê²€ìƒ‰ (ê¸°ì¡´ similarity_service í™œìš©)
        results = await similarity_service.find_similar_logs(
            log_vector=query_vector,
            k=k,
            filters=filters,
            project_uuid=project_uuid,
            time_range=time_range
        )

        if not results:
            return f"'{query}' ì¿¼ë¦¬ë¡œ ê²€ìƒ‰í•œ ê²°ê³¼ {time_hours}ì‹œê°„ ë‚´ ìœ ì‚¬í•œ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ê²°ê³¼ í¬ë§·íŒ…
        summary_lines = [
            f"'{query}' ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´ (ìµœê·¼ {time_hours}ì‹œê°„)",
            ""
        ]

        for i, result in enumerate(results, 1):
            log_data = result.get("data", {})
            score = result.get("score", 0.0)

            msg = log_data.get("message", "")[:200]
            level_str = log_data.get("level", "?")
            timestamp_str = log_data.get("timestamp", "")[:19]
            service = log_data.get("service_name", "unknown")
            log_id = log_data.get("log_id", "")
            layer = log_data.get("layer", "")

            # log_details ì ‘ê·¼
            log_details = log_data.get("log_details", {})
            class_name = log_details.get("class_name", "")
            method_name = log_details.get("method_name", "")
            http_method = log_details.get("http_method", "")
            request_uri = log_details.get("request_uri", "")
            response_status = log_details.get("response_status")

            # AI ë¶„ì„
            ai_summary = log_data.get("ai_analysis", {}).get("summary", "")

            # ê¸°ë³¸ ì •ë³´
            summary_lines.append(f"{i}. [{level_str}] {timestamp_str} | ìœ ì‚¬ë„: {score:.3f}")
            summary_lines.append(f"   ì„œë¹„ìŠ¤: {service}")

            # ìœ„ì¹˜ ì •ë³´
            if layer:
                summary_lines.append(f"   Layer: {layer}")
            if class_name and method_name:
                summary_lines.append(f"   ğŸ“ {class_name}.{method_name}")

            # HTTP ì •ë³´
            if http_method and request_uri:
                status_info = f" â†’ {response_status}" if response_status else ""
                summary_lines.append(f"   ğŸŒ {http_method} {request_uri}{status_info}")

            # ë©”ì‹œì§€
            summary_lines.append(f"   ë©”ì‹œì§€: {msg}...")

            # AI ë¶„ì„ (ìˆëŠ” ê²½ìš°)
            if ai_summary:
                summary_lines.append(f"   ğŸ¤– {ai_summary[:150]}")

            # log_id
            if log_id:
                summary_lines.append(f"   (log_id: {log_id})")
            summary_lines.append("")

        return "\n".join(summary_lines)

    except Exception as e:
        return f"ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
