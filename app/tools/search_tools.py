"""
ê²€ìƒ‰ ë„êµ¬ (Search Tools)
- í‚¤ì›Œë“œ ê²€ìƒ‰, ì˜ë¯¸ ìœ ì‚¬ë„ ê²€ìƒ‰
"""

from typing import Optional, List
from datetime import datetime, timedelta
from langchain_core.tools import tool

from app.core.opensearch import opensearch_client
from app.services.similarity_service import similarity_service
from app.services.embedding_service import embedding_service
from app.tools.common_fields import BASE_FIELDS, LOG_DETAILS_FIELDS


@tool
async def search_logs_by_keyword(
    keyword: str,
    project_uuid: str,
    level: Optional[str] = None,
    service_name: Optional[str] = None,
    time_hours: int = 24
) -> str:
    """
    í‚¤ì›Œë“œë¡œ ë¡œê·¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - íŠ¹ì • ì—ëŸ¬ ë©”ì‹œì§€ë¡œ ë¡œê·¸ ì°¾ê¸° (ì˜ˆ: "NullPointerException")
    - íŠ¹ì • ë‹¨ì–´ê°€ í¬í•¨ëœ ë¡œê·¸ ì°¾ê¸° (ì˜ˆ: "user-service")

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        keyword: ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ë©”ì‹œì§€ ë‚´ìš©, í•„ìˆ˜)
        level: ë¡œê·¸ ë ˆë²¨ í•„í„° (ERROR, WARN, INFO, DEBUG ì¤‘ í•˜ë‚˜, ì„ íƒ)
        service_name: ì„œë¹„ìŠ¤ ì´ë¦„ í•„í„° (ì„ íƒ)
        time_hours: ê²€ìƒ‰í•  ì‹œê°„ ë²”ìœ„ (ì‹œê°„ ë‹¨ìœ„, ê¸°ë³¸ 24ì‹œê°„)

    ì°¸ê³ :
    - project_uuidëŠ” ìë™ìœ¼ë¡œ ì£¼ì…ë˜ë¯€ë¡œ ì „ë‹¬í•˜ì§€ ë§ˆì„¸ìš”.
    - âš ï¸ "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤" ì‘ë‹µì€ ìœ íš¨í•œ ê²°ê³¼ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë„êµ¬ë¡œ ì¬ì‹œë„í•˜ì§€ ë§ˆì„¸ìš”.

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ (ê±´ìˆ˜, ì£¼ìš” ë©”ì‹œì§€, ì‹œê°„ ì •ë³´)
    """
    # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=time_hours)

    time_range = {
        "start": start_time.isoformat() + "Z",
        "end": end_time.isoformat() + "Z"
    }

    # OpenSearch Query êµ¬ì„±
    must_clauses = [
        {"match": {"message": keyword}}
    ]

    if level:
        must_clauses.append({"term": {"level": level.upper()}})

    if service_name:
        must_clauses.append({"term": {"service_name": service_name}})

    query = {
        "bool": {
            "must": must_clauses,
            "filter": [
                {
                    "range": {
                        "timestamp": {
                            "gte": time_range["start"],
                            "lte": time_range["end"]
                        }
                    }
                }
            ]
        }
    }

    # ì¸ë±ìŠ¤ íŒ¨í„´ (UUIDì˜ í•˜ì´í”ˆì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€í™˜)
    index_pattern = f"{project_uuid.replace('-', '_')}_*"

    try:
        # OpenSearch ê²€ìƒ‰
        results = opensearch_client.search(
            index=index_pattern,
            body={
                "query": query,
                "size": 20,  # ìµœëŒ€ 20ê°œ
                "sort": [{"timestamp": "desc"}],
                "_source": BASE_FIELDS + LOG_DETAILS_FIELDS + ["ai_analysis.summary"]  # ê³µí†µ í•„ë“œ ì‚¬ìš©
            }
        )

        hits = results.get("hits", {}).get("hits", [])
        total_count = results.get("hits", {}).get("total", {}).get("value", 0)

        if total_count == 0:
            return f"'{keyword}' í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•œ ê²°ê³¼ {time_hours}ì‹œê°„ ë‚´ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ê²°ê³¼ í¬ë§·íŒ…
        summary_lines = [
            f"'{keyword}' ê²€ìƒ‰ ê²°ê³¼: ì´ {total_count}ê±´ (ìµœê·¼ {time_hours}ì‹œê°„)",
            ""
        ]

        # ë ˆë²¨ë³„ ì¹´ìš´íŠ¸
        level_counts = {}
        for hit in hits:
            log_level = hit["_source"].get("level", "UNKNOWN")
            level_counts[log_level] = level_counts.get(log_level, 0) + 1

        summary_lines.append(f"ë ˆë²¨ë³„ ë¶„í¬: {', '.join([f'{k}: {v}ê±´' for k, v in level_counts.items()])}")
        summary_lines.append("")

        # ìƒìœ„ 5ê°œ ë¡œê·¸
        summary_lines.append("ìµœê·¼ ë¡œê·¸ 5ê°œ:")
        for i, hit in enumerate(hits[:5], 1):
            source = hit["_source"]
            msg = source.get("message", "")[:300]
            level_str = source.get("level", "?")
            timestamp_str = source.get("timestamp", "")[:19]
            service = source.get("service_name", "unknown")
            log_id = source.get("log_id", "")
            layer = source.get("layer", "")
            component = source.get("component_name", "")

            # log_details ì ‘ê·¼
            log_details = source.get("log_details", {})
            class_name = log_details.get("class_name", "")
            method_name = log_details.get("method_name", "")
            http_method = log_details.get("http_method", "")
            request_uri = log_details.get("request_uri", "")
            response_status = log_details.get("response_status")

            # AI ë¶„ì„
            ai_summary = source.get("ai_analysis", {}).get("summary", "")

            # ê¸°ë³¸ ì •ë³´
            summary_lines.append(f"{i}. [{level_str}] {timestamp_str} | {service}")

            # ìœ„ì¹˜ ì •ë³´
            if layer:
                summary_lines.append(f"   Layer: {layer}")
            if class_name and method_name:
                summary_lines.append(f"   ğŸ“ {class_name}.{method_name}")

            # HTTP ì •ë³´
            if http_method and request_uri:
                status_info = f" â†’ {response_status}" if response_status else ""
                summary_lines.append(f"   ğŸŒ {http_method} {request_uri}{status_info}")

            # ë©”ì‹œì§€
            summary_lines.append(f"   {msg}...")

            # AI ë¶„ì„ (ìˆëŠ” ê²½ìš°)
            if ai_summary:
                summary_lines.append(f"   ğŸ¤– {ai_summary[:150]}")

            # log_id
            if log_id:
                summary_lines.append(f"   (log_id: {log_id})")

        return "\n".join(summary_lines)

    except Exception as e:
        return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
async def search_logs_by_similarity(
    query: str,
    project_uuid: str,
    k: int = 5,
    level: Optional[str] = None,
    time_hours: int = 168  # ê¸°ë³¸ 7ì¼
) -> str:
    """
    ì˜ë¯¸ì  ìœ ì‚¬ë„ë¡œ ë¡œê·¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤ (Vector Search).

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - ìì—°ì–´ ì§ˆë¬¸ìœ¼ë¡œ ê´€ë ¨ ë¡œê·¸ ì°¾ê¸° (ì˜ˆ: "ì‚¬ìš©ì ì¸ì¦ ì‹¤íŒ¨ ê´€ë ¨ ë¡œê·¸")
    - íŠ¹ì • ìƒí™©ê³¼ ìœ ì‚¬í•œ ë¡œê·¸ ì°¾ê¸° (ì˜ˆ: "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ì œ")

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        query: ê²€ìƒ‰ ì¿¼ë¦¬ (ìì—°ì–´, í•„ìˆ˜)
        k: ë°˜í™˜í•  ë¡œê·¸ ê°œìˆ˜ (ê¸°ë³¸ 5ê°œ)
        level: ë¡œê·¸ ë ˆë²¨ í•„í„° (ERROR, WARN, INFO, DEBUG ì¤‘ í•˜ë‚˜, ì„ íƒ)
        time_hours: ê²€ìƒ‰í•  ì‹œê°„ ë²”ìœ„ (ì‹œê°„ ë‹¨ìœ„, ê¸°ë³¸ 168ì‹œê°„=7ì¼)

    ì°¸ê³ :
    - project_uuidëŠ” ìë™ìœ¼ë¡œ ì£¼ì…ë˜ë¯€ë¡œ ì „ë‹¬í•˜ì§€ ë§ˆì„¸ìš”.
    - âš ï¸ "ìœ ì‚¬í•œ ë¡œê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ì‘ë‹µì€ ìœ íš¨í•œ ê²°ê³¼ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë„êµ¬ë¡œ ì¬ì‹œë„í•˜ì§€ ë§ˆì„¸ìš”.

    Returns:
        ìœ ì‚¬í•œ ë¡œê·¸ ëª©ë¡ (ìƒìœ„ kê°œ)
    """
    try:
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_vector = await embedding_service.embed_query(query)

        # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=time_hours)

        time_range = {
            "start": start_time.isoformat() + "Z",
            "end": end_time.isoformat() + "Z"
        }

        # í•„í„° êµ¬ì„±
        filters = {}
        if level:
            filters["level"] = level.upper()

        # ìœ ì‚¬ë„ ê²€ìƒ‰ (ê¸°ì¡´ similarity_service í™œìš©)
        results = await similarity_service.find_similar_logs(
            log_vector=query_vector,
            k=k,
            filters=filters,
            project_uuid=project_uuid,
            time_range=time_range
        )

        if not results:
            return f"'{query}' ì¿¼ë¦¬ë¡œ ê²€ìƒ‰í•œ ê²°ê³¼ {time_hours}ì‹œê°„ ë‚´ ìœ ì‚¬í•œ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ê²°ê³¼ í¬ë§·íŒ…
        summary_lines = [
            f"'{query}' ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´ (ìµœê·¼ {time_hours}ì‹œê°„)",
            ""
        ]

        for i, result in enumerate(results, 1):
            log_data = result.get("data", {})
            score = result.get("score", 0.0)

            msg = log_data.get("message", "")[:200]
            level_str = log_data.get("level", "?")
            timestamp_str = log_data.get("timestamp", "")[:19]
            service = log_data.get("service_name", "unknown")
            log_id = log_data.get("log_id", "")
            layer = log_data.get("layer", "")

            # log_details ì ‘ê·¼
            log_details = log_data.get("log_details", {})
            class_name = log_details.get("class_name", "")
            method_name = log_details.get("method_name", "")
            http_method = log_details.get("http_method", "")
            request_uri = log_details.get("request_uri", "")
            response_status = log_details.get("response_status")

            # AI ë¶„ì„
            ai_summary = log_data.get("ai_analysis", {}).get("summary", "")

            # ê¸°ë³¸ ì •ë³´
            summary_lines.append(f"{i}. [{level_str}] {timestamp_str} | ìœ ì‚¬ë„: {score:.3f}")
            summary_lines.append(f"   ì„œë¹„ìŠ¤: {service}")

            # ìœ„ì¹˜ ì •ë³´
            if layer:
                summary_lines.append(f"   Layer: {layer}")
            if class_name and method_name:
                summary_lines.append(f"   ğŸ“ {class_name}.{method_name}")

            # HTTP ì •ë³´
            if http_method and request_uri:
                status_info = f" â†’ {response_status}" if response_status else ""
                summary_lines.append(f"   ğŸŒ {http_method} {request_uri}{status_info}")

            # ë©”ì‹œì§€
            summary_lines.append(f"   ë©”ì‹œì§€: {msg}...")

            # AI ë¶„ì„ (ìˆëŠ” ê²½ìš°)
            if ai_summary:
                summary_lines.append(f"   ğŸ¤– {ai_summary[:150]}")

            # log_id
            if log_id:
                summary_lines.append(f"   (log_id: {log_id})")
            summary_lines.append("")

        return "\n".join(summary_lines)

    except Exception as e:
        return f"ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
async def search_logs_advanced(
    project_uuid: str,
    start_time: Optional[str] = None,
    end_time: Optional[str] = None,
    service_name: Optional[str] = None,
    level: Optional[str] = None,
    keyword: Optional[str] = None,
    limit: int = 50
) -> str:
    """
    ê³ ê¸‰ ë¡œê·¸ ê²€ìƒ‰ (ì»¤ìŠ¤í…€ ì‹œê°„ ë²”ìœ„ + ë‹¤ì¤‘ í•„í„°)

    íŠ¹ì • ë‚ ì§œ/ì‹œê°„ ë²”ìœ„ ì§€ì •, ì—¬ëŸ¬ ì¡°ê±´ ë™ì‹œ í•„í„°ë§ ê°€ëŠ¥

    Args:
        project_uuid: í”„ë¡œì íŠ¸ UUID (ì–¸ë”ìŠ¤ì½”ì–´ í˜•ì‹)
        start_time: ì‹œì‘ ì‹œê°„ (ISO 8601 í˜•ì‹: "2025-11-05T14:00:00" ë˜ëŠ” "2025-11-05")
        end_time: ì¢…ë£Œ ì‹œê°„ (ISO 8601 í˜•ì‹)
        service_name: ì„œë¹„ìŠ¤ ì´ë¦„ (ì„ íƒ)
        level: ë¡œê·¸ ë ˆë²¨ (ERROR, WARN, INFO ë“±, ì„ íƒ)
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ (message í•„ë“œ, ì„ íƒ)
        limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ 50)

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ (ì‹œê°„ ë²”ìœ„ + ì¡°ê±´ + ê²°ê³¼)

    Examples:
        - "2025-11-05 14:00ë¶€í„° 16:00ê¹Œì§€ payment-service ì—ëŸ¬ ê²€ìƒ‰"
        - "ì–´ì œ ì˜¤í›„ 2ì‹œ~4ì‹œ ì‚¬ì´ DatabaseTimeout ë¡œê·¸"
    """
    try:
        from datetime import datetime, timezone
        from app.db.opensearch import get_opensearch_client

        client = get_opensearch_client()
        index_name = f"logs_{project_uuid}"

        # ì¿¼ë¦¬ êµ¬ì„±
        must_conditions = []

        # ì‹œê°„ ë²”ìœ„
        if start_time or end_time:
            time_range = {}
            if start_time:
                # ISO 8601 íŒŒì‹±
                if 'T' not in start_time:
                    start_time += 'T00:00:00'
                time_range['gte'] = start_time
            if end_time:
                if 'T' not in end_time:
                    end_time += 'T23:59:59'
                time_range['lte'] = end_time

            must_conditions.append({
                "range": {
                    "timestamp": time_range
                }
            })

        # ì„œë¹„ìŠ¤ í•„í„°
        if service_name:
            must_conditions.append({
                "term": {"service_name.keyword": service_name}
            })

        # ë ˆë²¨ í•„í„°
        if level:
            must_conditions.append({
                "term": {"level.keyword": level.upper()}
            })

        # í‚¤ì›Œë“œ ê²€ìƒ‰
        if keyword:
            must_conditions.append({
                "match": {"message": keyword}
            })

        # ì¿¼ë¦¬ ì‹¤í–‰
        query = {
            "bool": {
                "must": must_conditions if must_conditions else [{"match_all": {}}]
            }
        }

        response = client.search(
            index=index_name,
            body={
                "query": query,
                "sort": [{"timestamp": "desc"}],
                "size": limit
            }
        )

        hits = response['hits']['hits']
        total_count = response['hits']['total']['value']

        if total_count == 0:
            conditions_desc = []
            if start_time: conditions_desc.append(f"ì‹œì‘: {start_time}")
            if end_time: conditions_desc.append(f"ì¢…ë£Œ: {end_time}")
            if service_name: conditions_desc.append(f"ì„œë¹„ìŠ¤: {service_name}")
            if level: conditions_desc.append(f"ë ˆë²¨: {level}")
            if keyword: conditions_desc.append(f"í‚¤ì›Œë“œ: {keyword}")

            return f"=== ê³ ê¸‰ ê²€ìƒ‰ ê²°ê³¼ ===\n\nì¡°ê±´: {', '.join(conditions_desc) if conditions_desc else 'ì „ì²´'}\n\nê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ê²°ê³¼ í¬ë§·íŒ…
        summary_lines = ["=== ê³ ê¸‰ ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ ===", ""]

        # ê²€ìƒ‰ ì¡°ê±´ ìš”ì•½
        conditions = []
        if start_time: conditions.append(f"ğŸ“… ì‹œì‘: {start_time}")
        if end_time: conditions.append(f"ğŸ“… ì¢…ë£Œ: {end_time}")
        if service_name: conditions.append(f"ğŸ”§ ì„œë¹„ìŠ¤: {service_name}")
        if level: conditions.append(f"ğŸ“Š ë ˆë²¨: {level}")
        if keyword: conditions.append(f"ğŸ” í‚¤ì›Œë“œ: {keyword}")

        summary_lines.append("**ê²€ìƒ‰ ì¡°ê±´:**")
        summary_lines.extend([f"- {cond}" for cond in conditions])
        summary_lines.append("")
        summary_lines.append(f"**ê²°ê³¼:** ì´ {total_count}ê±´ ì¤‘ ìƒìœ„ {len(hits)}ê±´ í‘œì‹œ")
        summary_lines.append("")

        # ë¡œê·¸ ëª©ë¡
        for i, hit in enumerate(hits, 1):
            source = hit['_source']
            log_id = hit.get('_id')
            timestamp = source.get('timestamp', 'N/A')
            level_val = source.get('level', 'INFO')
            service = source.get('service_name', 'unknown')
            message = source.get('message', '')[:200]

            summary_lines.append(f"{i}. [{level_val}] {timestamp}")
            summary_lines.append(f"   ğŸ”§ {service}")
            summary_lines.append(f"   ğŸ’¬ {message}")
            if log_id:
                summary_lines.append(f"   (log_id: {log_id})")
            summary_lines.append("")

        return "\n".join(summary_lines)

    except Exception as e:
        return f"ê³ ê¸‰ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
