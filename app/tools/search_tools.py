"""
ê²€ìƒ‰ ë„êµ¬ (Search Tools)
- í‚¤ì›Œë“œ ê²€ìƒ‰, ì˜ë¯¸ ìœ ì‚¬ë„ ê²€ìƒ‰
"""

from typing import Optional, List
from datetime import datetime, timedelta
from langchain_core.tools import tool

from app.core.opensearch import opensearch_client
from app.services.similarity_service import similarity_service
from app.services.embedding_service import embedding_service
from app.tools.common_fields import BASE_FIELDS, LOG_DETAILS_FIELDS
from app.utils.sanitizer import sanitize_for_display, log_security_warning


@tool
async def search_logs_by_keyword(
    keyword: str,
    project_uuid: str,
    level: Optional[str] = None,
    service_name: Optional[str] = None,
    time_hours: int = 24
) -> str:
    """
    í‚¤ì›Œë“œë¡œ ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤ (í…ìŠ¤íŠ¸ ë§¤ì¹­).

    ì´ ë„êµ¬ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    - âœ… íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¡œê·¸ ê²€ìƒ‰ (message í•„ë“œ ëŒ€ìƒ)
    - âœ… ë ˆë²¨ë³„, ì„œë¹„ìŠ¤ë³„ í•„í„°ë§ ì§€ì›
    - âœ… ìµœê·¼ 20ê°œ ë¡œê·¸ ë°˜í™˜ (ì‹œê°„ ì—­ìˆœ)
    - âœ… ë ˆë²¨ë³„ ë¶„í¬ í†µê³„ ì œê³µ
    - âŒ ì˜ë¯¸ì  ìœ ì‚¬ë„ ê²€ìƒ‰ì€ í•˜ì§€ ì•ŠìŒ (search_logs_by_similarity ì‚¬ìš©)
    - âŒ AI ê¸°ë°˜ ë¶„ì„ì€ í•˜ì§€ ì•ŠìŒ (analyze_single_log ì‚¬ìš©)
    - âŒ íŠ¹ì • ì‹œê°„ëŒ€ ì§€ì • ë¶ˆê°€ (search_logs_advanced ì‚¬ìš©)

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    1. "NullPointerExceptionì´ í¬í•¨ëœ ë¡œê·¸ ì°¾ì•„ì¤˜"
    2. "user-serviceë¼ëŠ” ë‹¨ì–´ê°€ ë“¤ì–´ê°„ ERROR ë¡œê·¸"
    3. "timeout ë¬¸ì œ ê²€ìƒ‰"

    âš ï¸ ì¤‘ìš”í•œ ì œì•½ì‚¬í•­:
    - "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤" ì‘ë‹µì€ **ì •ìƒ ê²°ê³¼**ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë„êµ¬ë¡œ ì¬ì‹œë„í•˜ì§€ ë§ˆì„¸ìš”
    - 1íšŒ í˜¸ì¶œë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤. ê°™ì€ í‚¤ì›Œë“œë¡œ ë°˜ë³µ ê²€ìƒ‰í•˜ì§€ ë§ˆì„¸ìš”

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ (í•„ìˆ˜, ì˜ˆ: "NullPointerException")
        level: ë¡œê·¸ ë ˆë²¨ í•„í„° (ì„ íƒ, ERROR/WARN/INFO/DEBUG)
        service_name: ì„œë¹„ìŠ¤ í•„í„° (ì„ íƒ, ì˜ˆ: "user-service")
        time_hours: ê²€ìƒ‰ ì‹œê°„ ë²”ìœ„ (ê¸°ë³¸ 24ì‹œê°„)

    ê´€ë ¨ ë„êµ¬:
    - search_logs_by_similarity: ìì—°ì–´ ì§ˆë¬¸ìœ¼ë¡œ ì˜ë¯¸ì  ìœ ì‚¬ ë¡œê·¸ ê²€ìƒ‰
    - search_logs_advanced: ì»¤ìŠ¤í…€ ì‹œê°„ ë²”ìœ„ + ë‹¤ì¤‘ í•„í„°
    - get_log_detail: íŠ¹ì • log_idì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ (ê±´ìˆ˜, ë ˆë²¨ë³„ ë¶„í¬, ìƒìœ„ 5ê°œ ë¡œê·¸)
    """
    # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=time_hours)

    time_range = {
        "start": start_time.isoformat() + "Z",
        "end": end_time.isoformat() + "Z"
    }

    # OpenSearch Query êµ¬ì„±
    must_clauses = [
        {"match": {"message": keyword}}
    ]

    if level:
        must_clauses.append({"term": {"level": level.upper()}})

    if service_name:
        must_clauses.append({"term": {"service_name": service_name}})

    query = {
        "bool": {
            "must": must_clauses,
            "filter": [
                {
                    "range": {
                        "timestamp": {
                            "gte": time_range["start"],
                            "lte": time_range["end"]
                        }
                    }
                }
            ]
        }
    }

    # ì¸ë±ìŠ¤ íŒ¨í„´ (UUIDì˜ í•˜ì´í”ˆì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€í™˜)
    index_pattern = f"{project_uuid.replace('-', '_')}_*"

    try:
        # OpenSearch ê²€ìƒ‰
        results = opensearch_client.search(
            index=index_pattern,
            body={
                "query": query,
                "size": 20,  # ìµœëŒ€ 20ê°œ
                "sort": [{"timestamp": "desc"}],
                "_source": BASE_FIELDS + LOG_DETAILS_FIELDS + ["ai_analysis.summary"]  # ê³µí†µ í•„ë“œ ì‚¬ìš©
            }
        )

        hits = results.get("hits", {}).get("hits", [])
        total_count = results.get("hits", {}).get("total", {}).get("value", 0)

        # ë³´ì•ˆ ê²½ê³  ë¡œê¹…
        log_security_warning(keyword, "keyword_search")

        # ì‘ë‹µì— í‘œì‹œí•  í‚¤ì›Œë“œ ìœ„ìƒì²˜ë¦¬ (XSS/SQL ì¸ì ì…˜ ë°©ì§€)
        safe_keyword = sanitize_for_display(keyword)

        if total_count == 0:
            return f"'{safe_keyword}' í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•œ ê²°ê³¼ {time_hours}ì‹œê°„ ë‚´ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ê²°ê³¼ í¬ë§·íŒ…
        summary_lines = [
            f"'{safe_keyword}' ê²€ìƒ‰ ê²°ê³¼: ì´ {total_count}ê±´ (ìµœê·¼ {time_hours}ì‹œê°„)",
            ""
        ]

        # ë ˆë²¨ë³„ ì¹´ìš´íŠ¸
        level_counts = {}
        for hit in hits:
            log_level = hit["_source"].get("level", "UNKNOWN")
            level_counts[log_level] = level_counts.get(log_level, 0) + 1

        summary_lines.append(f"ë ˆë²¨ë³„ ë¶„í¬: {', '.join([f'{k}: {v}ê±´' for k, v in level_counts.items()])}")
        summary_lines.append("")

        # ìƒìœ„ 5ê°œ ë¡œê·¸
        summary_lines.append("ìµœê·¼ ë¡œê·¸ 5ê°œ:")
        for i, hit in enumerate(hits[:5], 1):
            source = hit["_source"]
            msg = source.get("message", "")[:300]
            level_str = source.get("level", "?")
            timestamp_str = source.get("timestamp", "")[:19]
            service = source.get("service_name", "unknown")
            log_id = source.get("log_id", "")
            layer = source.get("layer", "")
            component = source.get("component_name", "")

            # log_details ì ‘ê·¼
            log_details = source.get("log_details", {})
            class_name = log_details.get("class_name", "")
            method_name = log_details.get("method_name", "")
            http_method = log_details.get("http_method", "")
            request_uri = log_details.get("request_uri", "")
            response_status = log_details.get("response_status")

            # AI ë¶„ì„
            ai_summary = source.get("ai_analysis", {}).get("summary", "")

            # ê¸°ë³¸ ì •ë³´
            summary_lines.append(f"{i}. [{level_str}] {timestamp_str} | {service}")

            # ìœ„ì¹˜ ì •ë³´
            if layer:
                summary_lines.append(f"   Layer: {layer}")
            if class_name and method_name:
                summary_lines.append(f"   ğŸ“ {class_name}.{method_name}")

            # HTTP ì •ë³´
            if http_method and request_uri:
                status_info = f" â†’ {response_status}" if response_status else ""
                summary_lines.append(f"   ğŸŒ {http_method} {request_uri}{status_info}")

            # ë©”ì‹œì§€
            summary_lines.append(f"   {msg}...")

            # AI ë¶„ì„ (ìˆëŠ” ê²½ìš°)
            if ai_summary:
                summary_lines.append(f"   ğŸ¤– {ai_summary[:150]}")

            # log_id
            if log_id:
                summary_lines.append(f"   (log_id: {log_id})")

        return "\n".join(summary_lines)

    except Exception as e:
        return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
async def search_logs_by_similarity(
    query: str,
    project_uuid: str,
    k: int = 5,
    level: Optional[str] = None,
    time_hours: int = 168  # ê¸°ë³¸ 7ì¼
) -> str:
    """
    ì˜ë¯¸ì  ìœ ì‚¬ë„ë¡œ ë¡œê·¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤ (Vector ì„ë² ë”© ê¸°ë°˜).

    ì´ ë„êµ¬ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    - âœ… ìì—°ì–´ ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì˜ë¯¸ì  ìœ ì‚¬ ë¡œê·¸ ê²€ìƒ‰
    - âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ìƒìœ„ kê°œ ë°˜í™˜
    - âœ… ìœ ì‚¬ë„ ì ìˆ˜ ì œê³µ (0.0~1.0)
    - âœ… ë ˆë²¨ë³„ í•„í„°ë§ ì§€ì›
    - âŒ ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ì€ í•˜ì§€ ì•ŠìŒ (search_logs_by_keyword ì‚¬ìš©)
    - âŒ AI ë¶„ì„ì€ í•˜ì§€ ì•ŠìŒ (analyze_single_log ì‚¬ìš©)
    - âŒ íŠ¹ì • ì‹œê°„ëŒ€ ì§€ì • ë¶ˆê°€ (search_logs_advanced ì‚¬ìš©)

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    1. "ì‚¬ìš©ì ì¸ì¦ ì‹¤íŒ¨ì™€ ìœ ì‚¬í•œ ë¡œê·¸ ì°¾ì•„ì¤˜"
    2. "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ì œ ë¹„ìŠ·í•œ ìƒí™©"
    3. "ê²°ì œ ì‹¤íŒ¨ ê´€ë ¨ ë¡œê·¸"

    âš ï¸ ì¤‘ìš”í•œ ì œì•½ì‚¬í•­:
    - "ìœ ì‚¬í•œ ë¡œê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ì‘ë‹µì€ **ì •ìƒ ê²°ê³¼**ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë„êµ¬ë¡œ ì¬ì‹œë„í•˜ì§€ ë§ˆì„¸ìš”
    - 1íšŒ í˜¸ì¶œë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤. ê°™ì€ ì¿¼ë¦¬ë¡œ ë°˜ë³µ ê²€ìƒ‰í•˜ì§€ ë§ˆì„¸ìš”
    - ê¸°ë³¸ ê²€ìƒ‰ ë²”ìœ„ëŠ” 7ì¼ì…ë‹ˆë‹¤ (í‚¤ì›Œë“œ ê²€ìƒ‰ë³´ë‹¤ ë„“ìŒ)

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        query: ìì—°ì–´ ê²€ìƒ‰ ì¿¼ë¦¬ (í•„ìˆ˜, ì˜ˆ: "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ì œ")
        k: ë°˜í™˜ ê°œìˆ˜ (ê¸°ë³¸ 5ê°œ, ìµœëŒ€ 20ê°œ)
        level: ë¡œê·¸ ë ˆë²¨ í•„í„° (ì„ íƒ, ERROR/WARN/INFO/DEBUG)
        time_hours: ê²€ìƒ‰ ì‹œê°„ ë²”ìœ„ (ê¸°ë³¸ 168ì‹œê°„=7ì¼)

    ê´€ë ¨ ë„êµ¬:
    - search_logs_by_keyword: ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ê²€ìƒ‰
    - search_logs_advanced: ì»¤ìŠ¤í…€ ì‹œê°„ ë²”ìœ„ + ë‹¤ì¤‘ í•„í„°
    - analyze_single_log: íŠ¹ì • log_id AI ë¶„ì„

    Returns:
        ìœ ì‚¬ë„ìˆœ ë¡œê·¸ ëª©ë¡ (ìœ ì‚¬ë„ ì ìˆ˜, ìƒì„¸ ì •ë³´ í¬í•¨)
    """
    try:
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_vector = await embedding_service.embed_query(query)

        # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=time_hours)

        time_range = {
            "start": start_time.isoformat() + "Z",
            "end": end_time.isoformat() + "Z"
        }

        # í•„í„° êµ¬ì„±
        filters = {}
        if level:
            filters["level"] = level.upper()

        # ìœ ì‚¬ë„ ê²€ìƒ‰ (ê¸°ì¡´ similarity_service í™œìš©)
        results = await similarity_service.find_similar_logs(
            log_vector=query_vector,
            k=k,
            filters=filters,
            project_uuid=project_uuid,
            time_range=time_range
        )

        # ë³´ì•ˆ ê²½ê³  ë¡œê¹… ë° ìœ„ìƒì²˜ë¦¬
        log_security_warning(query, "similarity_search")
        safe_query = sanitize_for_display(query)

        if not results:
            return f"'{safe_query}' ì¿¼ë¦¬ë¡œ ê²€ìƒ‰í•œ ê²°ê³¼ {time_hours}ì‹œê°„ ë‚´ ìœ ì‚¬í•œ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ê²°ê³¼ í¬ë§·íŒ…
        summary_lines = [
            f"'{safe_query}' ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê±´ (ìµœê·¼ {time_hours}ì‹œê°„)",
            ""
        ]

        for i, result in enumerate(results, 1):
            log_data = result.get("data", {})
            score = result.get("score", 0.0)

            msg = log_data.get("message", "")[:200]
            level_str = log_data.get("level", "?")
            timestamp_str = log_data.get("timestamp", "")[:19]
            service = log_data.get("service_name", "unknown")
            log_id = log_data.get("log_id", "")
            layer = log_data.get("layer", "")

            # log_details ì ‘ê·¼
            log_details = log_data.get("log_details", {})
            class_name = log_details.get("class_name", "")
            method_name = log_details.get("method_name", "")
            http_method = log_details.get("http_method", "")
            request_uri = log_details.get("request_uri", "")
            response_status = log_details.get("response_status")

            # AI ë¶„ì„
            ai_summary = log_data.get("ai_analysis", {}).get("summary", "")

            # ê¸°ë³¸ ì •ë³´
            summary_lines.append(f"{i}. [{level_str}] {timestamp_str} | ìœ ì‚¬ë„: {score:.3f}")
            summary_lines.append(f"   ì„œë¹„ìŠ¤: {service}")

            # ìœ„ì¹˜ ì •ë³´
            if layer:
                summary_lines.append(f"   Layer: {layer}")
            if class_name and method_name:
                summary_lines.append(f"   ğŸ“ {class_name}.{method_name}")

            # HTTP ì •ë³´
            if http_method and request_uri:
                status_info = f" â†’ {response_status}" if response_status else ""
                summary_lines.append(f"   ğŸŒ {http_method} {request_uri}{status_info}")

            # ë©”ì‹œì§€
            summary_lines.append(f"   ë©”ì‹œì§€: {msg}...")

            # AI ë¶„ì„ (ìˆëŠ” ê²½ìš°)
            if ai_summary:
                summary_lines.append(f"   ğŸ¤– {ai_summary[:150]}")

            # log_id
            if log_id:
                summary_lines.append(f"   (log_id: {log_id})")
            summary_lines.append("")

        return "\n".join(summary_lines)

    except Exception as e:
        return f"ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
async def search_logs_advanced(
    project_uuid: str,
    start_time: Optional[str] = None,
    end_time: Optional[str] = None,
    service_name: Optional[str] = None,
    level: Optional[str] = None,
    keyword: Optional[str] = None,
    limit: int = 50
) -> str:
    """
    ê³ ê¸‰ ë¡œê·¸ ê²€ìƒ‰ (ì»¤ìŠ¤í…€ ì‹œê°„ ë²”ìœ„ + ë‹¤ì¤‘ í•„í„° ì¡°í•©).

    ì´ ë„êµ¬ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    - âœ… ì •í™•í•œ ë‚ ì§œ/ì‹œê°„ ë²”ìœ„ ì§€ì • ê°€ëŠ¥ (ISO 8601 í˜•ì‹)
    - âœ… ì—¬ëŸ¬ ì¡°ê±´ ë™ì‹œ í•„í„°ë§ (ì„œë¹„ìŠ¤, ë ˆë²¨, í‚¤ì›Œë“œ)
    - âœ… ìµœëŒ€ 50ê°œ ë¡œê·¸ ë°˜í™˜
    - âœ… ì¡°ê±´ë³„ ì¹´ìš´íŠ¸ í†µê³„ ì œê³µ
    - âŒ ì˜ë¯¸ì  ìœ ì‚¬ë„ ê²€ìƒ‰ì€ í•˜ì§€ ì•ŠìŒ (search_logs_by_similarity ì‚¬ìš©)
    - âŒ AI ë¶„ì„ì€ í•˜ì§€ ì•ŠìŒ (analyze_single_log ì‚¬ìš©)
    - âŒ ìƒëŒ€ì  ì‹œê°„ í‘œí˜„ ë¶ˆê°€ ("ìµœê·¼ 24ì‹œê°„"ì€ time_hours íŒŒë¼ë¯¸í„°ë¥¼ ì“°ëŠ” ë‹¤ë¥¸ ë„êµ¬ ì‚¬ìš©)

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    1. "2025-11-05 14:00ë¶€í„° 16:00ê¹Œì§€ payment-service ERROR ë¡œê·¸"
    2. "ì–´ì œ ì˜¤í›„ 2ì‹œ~4ì‹œ ì‚¬ì´ DatabaseTimeout ê²€ìƒ‰"
    3. "íŠ¹ì • ë°°í¬ ì‹œì  ì „í›„ ë¡œê·¸ ë¹„êµ"

    âš ï¸ ì¤‘ìš”í•œ ì œì•½ì‚¬í•­:
    - ì‹œê°„ í˜•ì‹ì€ ISO 8601 ì¤€ìˆ˜ ("2025-11-05T14:00:00" ë˜ëŠ” "2025-11-05")
    - "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤" ì‘ë‹µì€ **ì •ìƒ ê²°ê³¼**ì…ë‹ˆë‹¤
    - 1íšŒ í˜¸ì¶œë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        start_time: ì‹œì‘ ì‹œê°„ (ISO í˜•ì‹, ì˜ˆ: "2025-11-05T14:00:00")
        end_time: ì¢…ë£Œ ì‹œê°„ (ISO í˜•ì‹, ì˜ˆ: "2025-11-05T16:00:00")
        service_name: ì„œë¹„ìŠ¤ í•„í„° (ì„ íƒ)
        level: ë¡œê·¸ ë ˆë²¨ (ì„ íƒ, ERROR/WARN/INFO/DEBUG)
        keyword: í‚¤ì›Œë“œ í•„í„° (ì„ íƒ)
        limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ 50)

    ê´€ë ¨ ë„êµ¬:
    - search_logs_by_keyword: ìƒëŒ€ì  ì‹œê°„ (time_hours) ì‚¬ìš© ê²€ìƒ‰
    - compare_time_periods: ë‘ ì‹œê°„ëŒ€ ë¹„êµ ë¶„ì„
    - analyze_deployment_impact: ë°°í¬ ì „í›„ ì˜í–¥ ë¶„ì„

    Returns:
        ê²€ìƒ‰ ì¡°ê±´ ìš”ì•½, ê²°ê³¼ ëª©ë¡ (ìµœëŒ€ 50ê°œ)
    """
    try:
        from datetime import datetime, timezone
        from app.core.opensearch import opensearch_client

        client = opensearch_client
        index_name = f"logs_{project_uuid}"

        # ì¿¼ë¦¬ êµ¬ì„±
        must_conditions = []

        # ì‹œê°„ ë²”ìœ„
        if start_time or end_time:
            time_range = {}
            if start_time:
                # ISO 8601 íŒŒì‹±
                if 'T' not in start_time:
                    start_time += 'T00:00:00'
                time_range['gte'] = start_time
            if end_time:
                if 'T' not in end_time:
                    end_time += 'T23:59:59'
                time_range['lte'] = end_time

            must_conditions.append({
                "range": {
                    "timestamp": time_range
                }
            })

        # ì„œë¹„ìŠ¤ í•„í„°
        if service_name:
            must_conditions.append({
                "term": {"service_name.keyword": service_name}
            })

        # ë ˆë²¨ í•„í„°
        if level:
            must_conditions.append({
                "term": {"level.keyword": level.upper()}
            })

        # í‚¤ì›Œë“œ ê²€ìƒ‰
        if keyword:
            must_conditions.append({
                "match": {"message": keyword}
            })

        # ì¿¼ë¦¬ ì‹¤í–‰
        query = {
            "bool": {
                "must": must_conditions if must_conditions else [{"match_all": {}}]
            }
        }

        response = client.search(
            index=index_name,
            body={
                "query": query,
                "sort": [{"timestamp": "desc"}],
                "size": limit
            }
        )

        hits = response['hits']['hits']
        total_count = response['hits']['total']['value']

        # í‚¤ì›Œë“œ ìœ„ìƒì²˜ë¦¬ (ë³´ì•ˆ)
        if keyword:
            log_security_warning(keyword, "advanced_search")
        safe_keyword = sanitize_for_display(keyword) if keyword else None

        if total_count == 0:
            conditions_desc = []
            if start_time: conditions_desc.append(f"ì‹œì‘: {start_time}")
            if end_time: conditions_desc.append(f"ì¢…ë£Œ: {end_time}")
            if service_name: conditions_desc.append(f"ì„œë¹„ìŠ¤: {service_name}")
            if level: conditions_desc.append(f"ë ˆë²¨: {level}")
            if safe_keyword: conditions_desc.append(f"í‚¤ì›Œë“œ: {safe_keyword}")

            return f"=== ê³ ê¸‰ ê²€ìƒ‰ ê²°ê³¼ ===\n\nì¡°ê±´: {', '.join(conditions_desc) if conditions_desc else 'ì „ì²´'}\n\nê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ê²°ê³¼ í¬ë§·íŒ…
        summary_lines = ["=== ê³ ê¸‰ ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ ===", ""]

        # ê²€ìƒ‰ ì¡°ê±´ ìš”ì•½
        conditions = []
        if start_time: conditions.append(f"ğŸ“… ì‹œì‘: {start_time}")
        if end_time: conditions.append(f"ğŸ“… ì¢…ë£Œ: {end_time}")
        if service_name: conditions.append(f"ğŸ”§ ì„œë¹„ìŠ¤: {service_name}")
        if level: conditions.append(f"ğŸ“Š ë ˆë²¨: {level}")
        if safe_keyword: conditions.append(f"ğŸ” í‚¤ì›Œë“œ: {safe_keyword}")

        summary_lines.append("**ê²€ìƒ‰ ì¡°ê±´:**")
        summary_lines.extend([f"- {cond}" for cond in conditions])
        summary_lines.append("")
        summary_lines.append(f"**ê²°ê³¼:** ì´ {total_count}ê±´ ì¤‘ ìƒìœ„ {len(hits)}ê±´ í‘œì‹œ")
        summary_lines.append("")

        # ë¡œê·¸ ëª©ë¡
        for i, hit in enumerate(hits, 1):
            source = hit['_source']
            log_id = hit.get('_id')
            timestamp = source.get('timestamp', 'N/A')
            level_val = source.get('level', 'INFO')
            service = source.get('service_name', 'unknown')
            message = source.get('message', '')[:200]

            summary_lines.append(f"{i}. [{level_val}] {timestamp}")
            summary_lines.append(f"   ğŸ”§ {service}")
            summary_lines.append(f"   ğŸ’¬ {message}")
            if log_id:
                summary_lines.append(f"   (log_id: {log_id})")
            summary_lines.append("")

        return "\n".join(summary_lines)

    except Exception as e:
        return f"ê³ ê¸‰ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
