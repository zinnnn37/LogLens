"""
ì•„í‚¤í…ì²˜ ë¶„ì„ ë„êµ¬ (Architecture Analysis Tools)
- ë ˆì´ì–´ë³„ ì—ëŸ¬ ë¶„ì„, ì»´í¬ë„ŒíŠ¸ í˜¸ì¶œ ê·¸ë˜í”„, í•«ìŠ¤íŒŸ ë©”ì„œë“œ
"""

from typing import Optional
from datetime import datetime, timedelta
from langchain_core.tools import tool

from app.core.opensearch import opensearch_client
from app.tools.common_fields import BASE_FIELDS, LOG_DETAILS_FIELDS


@tool
async def analyze_error_by_layer(
    project_uuid: str,
    time_hours: int = 24,
    min_error_count: int = 1
) -> str:
    """
    ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆì´ì–´ë³„ ì—ëŸ¬ ë¶„í¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

    ì´ ë„êµ¬ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    - âœ… layer í•„ë“œë¡œ ê·¸ë£¹í•‘ (Controller/Service/Repository/Filter/Util)
    - âœ… ë ˆì´ì–´ë³„ ì—ëŸ¬ ê±´ìˆ˜, ì—ëŸ¬ìœ¨ ê³„ì‚°
    - âœ… class_nameê³¼ method_nameìœ¼ë¡œ í•«ìŠ¤íŒŸ ì‹ë³„
    - âœ… ë ˆì´ì–´ ê°„ ì—ëŸ¬ ë¹„ìœ¨ ë¹„êµ
    - âŒ ë ˆì´ì–´ ê°„ í˜¸ì¶œ ê´€ê³„ëŠ” ì¶”ì  ì•ˆ í•¨ (trace_component_calls ì‚¬ìš©)

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    1. "Controller/Service/Repository ì¤‘ ì–´ë””ì„œ ì—ëŸ¬ê°€ ë§ì•„?"
    2. "ë ˆì´ì–´ë³„ ì—ëŸ¬ í†µê³„"
    3. "ì–´ëŠ ê³„ì¸µì´ ë¶ˆì•ˆì •í•´?"
    4. "ì•„í‚¤í…ì²˜ ë¬¸ì œ ì§„ë‹¨"

    âš ï¸ ì¤‘ìš”í•œ ì œì•½ì‚¬í•­:
    - 1íšŒ í˜¸ì¶œë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤
    - layer í•„ë“œê°€ ì—†ëŠ” ë¡œê·¸ëŠ” "Other"ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤
    - ê¸°ë³¸ ë¶„ì„ ê¸°ê°„ì€ 24ì‹œê°„ì…ë‹ˆë‹¤

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        time_hours: ë¶„ì„ ê¸°ê°„ (ê¸°ë³¸ 24ì‹œê°„)
        min_error_count: í‘œì‹œí•  ìµœì†Œ ì—ëŸ¬ ìˆ˜ (ê¸°ë³¸ 1ê±´)

    ê´€ë ¨ ë„êµ¬:
    - get_service_health_status: ì„œë¹„ìŠ¤ë³„ í—¬ìŠ¤ ìƒíƒœ
    - trace_component_calls: ì»´í¬ë„ŒíŠ¸ í˜¸ì¶œ ê·¸ë˜í”„
    - get_error_frequency_ranking: ì—ëŸ¬ íƒ€ì…ë³„ ë¹ˆë„

    Returns:
        ë ˆì´ì–´ë³„ ì—ëŸ¬ ë¶„í¬, í•«ìŠ¤íŒŸ í´ë˜ìŠ¤/ë©”ì„œë“œ
    """
    # ì¸ë±ìŠ¤ íŒ¨í„´
    index_pattern = f"{project_uuid.replace('-', '_')}_*"

    # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=time_hours)

    try:
        # OpenSearch ì§‘ê³„ ì¿¼ë¦¬
        results = opensearch_client.search(
            index=index_pattern,
            body={
                "size": 0,  # ì§‘ê³„ë§Œ í•„ìš”
                "query": {
                    "range": {
                        "timestamp": {
                            "gte": start_time.isoformat() + "Z",
                            "lte": end_time.isoformat() + "Z"
                        }
                    }
                },
                "aggs": {
                    "by_layer": {
                        "terms": {
                            "field": "layer",
                            "size": 10,
                            "missing": "Other"  # layer ì—†ëŠ” ë¡œê·¸
                        },
                        "aggs": {
                            "total_logs": {
                                "value_count": {"field": "log_id"}
                            },
                            "error_logs": {
                                "filter": {"term": {"level": "ERROR"}}
                            },
                            "error_rate": {
                                "bucket_script": {
                                    "buckets_path": {
                                        "errors": "error_logs>_count",
                                        "total": "total_logs"
                                    },
                                    "script": "params.total > 0 ? (params.errors / params.total * 100) : 0"
                                }
                            },
                            "top_classes": {
                                "terms": {
                                    "field": "class_name",
                                    "size": 5
                                },
                                "aggs": {
                                    "error_count": {
                                        "filter": {"term": {"level": "ERROR"}}
                                    }
                                }
                            }
                        }
                    },
                    "total_errors": {
                        "filter": {"term": {"level": "ERROR"}}
                    }
                }
            }
        )

        aggs = results.get("aggregations", {})
        layer_buckets = aggs.get("by_layer", {}).get("buckets", [])
        total_errors = aggs.get("total_errors", {}).get("doc_count", 0)

        if total_errors == 0:
            return (
                f"ìµœê·¼ {time_hours}ì‹œê°„ ë™ì•ˆ ì—ëŸ¬ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n\n"
                f"ğŸŸ¢ ì‹œìŠ¤í…œì´ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤."
            )

        # ê²°ê³¼ í¬ë§·íŒ…
        lines = [
            f"## ğŸ“Š ë ˆì´ì–´ë³„ ì—ëŸ¬ ë¶„í¬ ë¶„ì„",
            f"**ê¸°ê°„:** ìµœê·¼ {time_hours}ì‹œê°„",
            f"**ì´ ì—ëŸ¬:** {total_errors}ê±´",
            ""
        ]

        # ë ˆì´ì–´ë³„ í†µê³„ í…Œì´ë¸”
        lines.append("### ğŸ” ë ˆì´ì–´ë³„ ì—ëŸ¬ í˜„í™©")
        lines.append("")
        lines.append("| ë ˆì´ì–´ | ì´ ë¡œê·¸ | ì—ëŸ¬ ìˆ˜ | ì—ëŸ¬ìœ¨ | ì£¼ìš” í´ë˜ìŠ¤ |")
        lines.append("|--------|---------|---------|--------|-------------|")

        layer_stats = []  # ë‚˜ì¤‘ì— ì •ë ¬ìš©

        for bucket in layer_buckets:
            layer_name = bucket.get("key", "Other")
            total_count = bucket.get("total_logs", {}).get("value", 0)
            error_count = bucket.get("error_logs", {}).get("doc_count", 0)
            error_rate = bucket.get("error_rate", {}).get("value", 0)

            # í•„í„°ë§
            if error_count < min_error_count:
                continue

            # ì£¼ìš” í´ë˜ìŠ¤
            top_classes = bucket.get("top_classes", {}).get("buckets", [])
            class_str = ", ".join([
                f"{cls['key']}({cls.get('error_count', {}).get('doc_count', 0)})"
                for cls in top_classes[:3]
            ])

            # ì—ëŸ¬ìœ¨ ë“±ê¸‰
            if error_rate > 5:
                rate_badge = f"ğŸ”´ **{error_rate:.1f}%**"
            elif error_rate > 2:
                rate_badge = f"ğŸŸ¡ {error_rate:.1f}%"
            else:
                rate_badge = f"ğŸŸ¢ {error_rate:.1f}%"

            lines.append(
                f"| {layer_name} | {total_count} | **{error_count}ê±´** | {rate_badge} | {class_str} |"
            )

            layer_stats.append({
                "layer": layer_name,
                "error_count": error_count,
                "error_rate": error_rate,
                "classes": top_classes
            })

        lines.append("")

        # ë ˆì´ì–´ë³„ ì—ëŸ¬ ë¹„ìœ¨ (íŒŒì´ ì°¨íŠ¸ ëŒ€ì‹  í…ìŠ¤íŠ¸)
        if layer_stats:
            lines.append("### ğŸ“ˆ ë ˆì´ì–´ë³„ ì—ëŸ¬ ë¹„ì¤‘")
            lines.append("")

            # ì—ëŸ¬ ìˆ˜ ê¸°ì¤€ ì •ë ¬
            sorted_layers = sorted(layer_stats, key=lambda x: x["error_count"], reverse=True)

            for i, layer in enumerate(sorted_layers[:5], 1):
                percentage = (layer["error_count"] / total_errors * 100) if total_errors > 0 else 0
                bar = "â–ˆ" * int(percentage / 5)  # 5%ë‹¹ â–ˆ 1ê°œ
                lines.append(f"{i}. **{layer['layer']}**: {layer['error_count']}ê±´ ({percentage:.1f}%) {bar}")

            lines.append("")

        # í•«ìŠ¤íŒŸ í´ë˜ìŠ¤/ë©”ì„œë“œ ë¶„ì„
        lines.append("### ğŸ”¥ í•«ìŠ¤íŒŸ í´ë˜ìŠ¤ (ì—ëŸ¬ ë§ì€ ìˆœ)")
        lines.append("")

        # ëª¨ë“  ë ˆì´ì–´ì˜ í´ë˜ìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ì •ë ¬
        all_classes = []
        for layer_stat in layer_stats:
            for cls in layer_stat["classes"]:
                all_classes.append({
                    "layer": layer_stat["layer"],
                    "class_name": cls.get("key", ""),
                    "error_count": cls.get("error_count", {}).get("doc_count", 0)
                })

        # ì—ëŸ¬ ìˆ˜ ê¸°ì¤€ ì •ë ¬
        sorted_classes = sorted(all_classes, key=lambda x: x["error_count"], reverse=True)

        if sorted_classes:
            for i, cls in enumerate(sorted_classes[:10], 1):
                lines.append(
                    f"{i}. **{cls['class_name']}** ({cls['layer']}) - {cls['error_count']}ê±´"
                )
        else:
            lines.append("í´ë˜ìŠ¤ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

        lines.append("")

        # ë¶„ì„ ìš”ì•½
        lines.append("### ğŸ’¡ ì•„í‚¤í…ì²˜ ì§„ë‹¨")
        lines.append("")

        # ê°€ì¥ ë¬¸ì œ ë§ì€ ë ˆì´ì–´
        if sorted_layers:
            worst_layer = sorted_layers[0]
            worst_layer_percentage = (worst_layer["error_count"] / total_errors * 100)

            if worst_layer_percentage > 60:
                lines.append(f"- ğŸ”´ **{worst_layer['layer']} ë ˆì´ì–´ì— ì—ëŸ¬ ì§‘ì¤‘** ({worst_layer_percentage:.1f}%)")
                lines.append(f"  â†’ ì´ ë ˆì´ì–´ì˜ ì½”ë“œ í’ˆì§ˆ ê°œì„ ì´ ì‹œê¸‰í•©ë‹ˆë‹¤.")
            elif worst_layer_percentage > 40:
                lines.append(f"- ğŸŸ¡ **{worst_layer['layer']} ë ˆì´ì–´ ì—ëŸ¬ ë¹„ì¤‘ ë†’ìŒ** ({worst_layer_percentage:.1f}%)")
            else:
                lines.append(f"- ğŸŸ¢ **ì—ëŸ¬ê°€ ì—¬ëŸ¬ ë ˆì´ì–´ì— ë¶„ì‚°**ë˜ì–´ íŠ¹ì • ê³„ì¸µì˜ ë¬¸ì œëŠ” ì•„ë‹™ë‹ˆë‹¤.")

        # ì—ëŸ¬ìœ¨ í‰ê°€
        high_error_rate_layers = [l for l in layer_stats if l["error_rate"] > 5]
        if high_error_rate_layers:
            layer_names = ", ".join([l["layer"] for l in high_error_rate_layers])
            lines.append(f"- ğŸ”´ **ì—ëŸ¬ìœ¨ ë†’ì€ ë ˆì´ì–´**: {layer_names} (5% ì´ˆê³¼)")

        # ê¶Œì¥ ì¡°ì¹˜
        lines.append("")
        lines.append("### âœ… ê¶Œì¥ ì¡°ì¹˜")
        lines.append("")

        if sorted_layers:
            top_layer = sorted_layers[0]
            lines.append(f"1. **{top_layer['layer']} ë ˆì´ì–´ ì§‘ì¤‘ ì ê²€** ({top_layer['error_count']}ê±´ ë°œìƒ)")

        if sorted_classes:
            top_class = sorted_classes[0]
            lines.append(f"2. **{top_class['class_name']} í´ë˜ìŠ¤ ìš°ì„  ìˆ˜ì •** ({top_class['error_count']}ê±´)")

        lines.append(f"3. **ë ˆì´ì–´ ê°„ ì—ëŸ¬ ì „íŒŒ í™•ì¸**: trace_component_calls ë„êµ¬ í™œìš©")
        lines.append(f"4. **ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê°•í™”**: ì—ëŸ¬ ë‹¤ë°œ í´ë˜ìŠ¤ ì§‘ì¤‘ í…ŒìŠ¤íŠ¸")

        return "\n".join(lines)

    except Exception as e:
        return f"ë ˆì´ì–´ë³„ ì—ëŸ¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
async def trace_component_calls(
    project_uuid: str,
    trace_id: str,
    visualize: bool = True
) -> str:
    """
    trace_idë¡œ ì»´í¬ë„ŒíŠ¸ ê°„ í˜¸ì¶œ ìˆœì„œë¥¼ ì¶”ì í•©ë‹ˆë‹¤.

    ì´ ë„êµ¬ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    - âœ… trace_idë¡œ ë¡œê·¸ ìˆ˜ì§‘ ë° ì‹œê°„ìˆœ ì •ë ¬
    - âœ… layer, class_name, method_nameìœ¼ë¡œ í˜¸ì¶œ ì²´ì¸ êµ¬ì„±
    - âœ… execution_timeìœ¼ë¡œ ë³‘ëª© ì§€ì  í‘œì‹œ
    - âœ… ì—ëŸ¬ ë°œìƒ ì§€ì  ê°•ì¡°
    - âŒ ë¹„ë™ê¸° í˜¸ì¶œì€ ìˆœì„œ ë³´ì¥ ì•ˆ ë¨

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    1. "ì´ ìš”ì²­ì´ ì–´ë–¤ ì»´í¬ë„ŒíŠ¸ë¥¼ ê±°ì³¤ì–´?"
    2. "í˜¸ì¶œ ìˆœì„œ ë³´ì—¬ì¤˜"
    3. "ì–´ë””ì„œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë ¸ì–´?"
    4. "ìš”ì²­ íë¦„ ì‹œê°í™”"

    âš ï¸ ì¤‘ìš”í•œ ì œì•½ì‚¬í•­:
    - 1íšŒ í˜¸ì¶œë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤
    - trace_idê°€ ì—†ëŠ” ë¡œê·¸ëŠ” ì¶”ì  ë¶ˆê°€
    - execution_timeì´ ì—†ìœ¼ë©´ ì„±ëŠ¥ ë¶„ì„ ì œí•œì 

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        trace_id: ì¶”ì í•  Trace ID (í•„ìˆ˜)
        visualize: ASCII ê·¸ë˜í”„ í‘œì‹œ ì—¬ë¶€ (ê¸°ë³¸ True)

    ê´€ë ¨ ë„êµ¬:
    - get_logs_by_trace_id: trace_idë¡œ ë¡œê·¸ ì¡°íšŒ (ê°„ë‹¨ ë²„ì „)
    - trace_error_propagation: ì—ëŸ¬ ì „íŒŒ ê²½ë¡œ ì¶”ì 
    - get_slowest_apis: ëŠë¦° API ë¶„ì„

    Returns:
        ì»´í¬ë„ŒíŠ¸ í˜¸ì¶œ ê·¸ë˜í”„, ì„±ëŠ¥ ë¶„ì„
    """
    # ì¸ë±ìŠ¤ íŒ¨í„´
    index_pattern = f"{project_uuid.replace('-', '_')}_*"

    try:
        # trace_idë¡œ ë¡œê·¸ ê²€ìƒ‰
        results = opensearch_client.search(
            index=index_pattern,
            body={
                "size": 100,
                "query": {"term": {"trace_id": trace_id}},
                "sort": [{"timestamp": "asc"}],
                "_source": BASE_FIELDS + LOG_DETAILS_FIELDS
            }
        )

        hits = results.get("hits", {}).get("hits", [])

        if not hits:
            return (
                f"trace_id '{trace_id}'ì— í•´ë‹¹í•˜ëŠ” ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n\n"
                f"ğŸ’¡ í™•ì¸ ì‚¬í•­:\n"
                f"1. trace_idê°€ ì •í™•í•œì§€ í™•ì¸í•˜ì„¸ìš”\n"
                f"2. ë¡œê·¸ê°€ ì•„ì§ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
            )

        # ê²°ê³¼ í¬ë§·íŒ…
        lines = [
            f"## ğŸ”— ì»´í¬ë„ŒíŠ¸ í˜¸ì¶œ ê·¸ë˜í”„ (trace_id: {trace_id})",
            f"**ì´ ë¡œê·¸:** {len(hits)}ê±´",
            ""
        ]

        # í˜¸ì¶œ ì²´ì¸ êµ¬ì„±
        call_chain = []
        total_time = 0
        error_point = None

        for i, hit in enumerate(hits, 1):
            source = hit["_source"]

            timestamp = source.get("timestamp", "")
            level = source.get("level", "INFO")
            service = source.get("service_name", "unknown")
            layer = source.get("layer", "")
            class_name = source.get("class_name", "")
            method_name = source.get("method_name", "")

            log_details = source.get("log_details", {})
            execution_time = log_details.get("execution_time") or source.get("duration", 0)
            exception_type = log_details.get("exception_type", "")

            # í˜¸ì¶œ ì •ë³´
            call_info = {
                "index": i,
                "timestamp": timestamp,
                "level": level,
                "service": service,
                "layer": layer,
                "class_name": class_name,
                "method_name": method_name,
                "execution_time": execution_time,
                "exception": exception_type
            }

            call_chain.append(call_info)

            if execution_time:
                total_time += execution_time

            if level == "ERROR" and not error_point:
                error_point = i

        # ì‹œê°í™”
        if visualize:
            lines.append("### ğŸ“ í˜¸ì¶œ íë¦„ (ì‹œê°„ìˆœ)")
            lines.append("")
            lines.append("```")

            for call in call_chain:
                # ë ˆì´ì–´ íƒœê·¸
                layer_tag = f"[{call['layer']}] " if call['layer'] else ""

                # ì»´í¬ë„ŒíŠ¸ ì´ë¦„
                if call['class_name'] and call['method_name']:
                    component = f"{call['class_name']}.{call['method_name']}"
                elif call['class_name']:
                    component = call['class_name']
                else:
                    component = call['service']

                # ì‹¤í–‰ ì‹œê°„
                time_str = f" ({call['execution_time']}ms)" if call['execution_time'] else ""

                # ë³‘ëª© í‘œì‹œ (100ms ì´ìƒ)
                bottleneck = " âš ï¸ ë³‘ëª©" if call['execution_time'] and call['execution_time'] > 100 else ""

                # ì—ëŸ¬ í‘œì‹œ
                error_marker = ""
                if call['level'] == "ERROR":
                    error_marker = f" âŒ {call['exception']}" if call['exception'] else " âŒ ERROR"

                lines.append(f"{call['index']}. {layer_tag}{component}{time_str}{bottleneck}{error_marker}")

                # ë‹¤ìŒ í˜¸ì¶œë¡œì˜ í™”ì‚´í‘œ
                if call['index'] < len(call_chain):
                    lines.append("     â†“")

            lines.append("```")
            lines.append("")

        # ì„±ëŠ¥ ë¶„ì„
        if total_time > 0:
            lines.append("### â±ï¸ ì„±ëŠ¥ ë¶„ì„")
            lines.append("")
            lines.append(f"**ì „ì²´ ì†Œìš” ì‹œê°„:** {total_time}ms")
            lines.append("")

            # ê°€ì¥ ëŠë¦° í˜¸ì¶œ ì°¾ê¸°
            sorted_calls = sorted(call_chain, key=lambda x: x['execution_time'] or 0, reverse=True)
            slow_calls = [c for c in sorted_calls if c['execution_time'] and c['execution_time'] > 50]

            if slow_calls:
                lines.append("**ë³‘ëª© ì§€ì :**")
                for i, call in enumerate(slow_calls[:5], 1):
                    component = f"{call['class_name']}.{call['method_name']}" if call['class_name'] and call['method_name'] else call['service']
                    percentage = (call['execution_time'] / total_time * 100) if total_time > 0 else 0
                    lines.append(f"{i}. {component}: {call['execution_time']}ms ({percentage:.1f}%)")

                lines.append("")

        # ì—ëŸ¬ ë¶„ì„
        if error_point:
            lines.append("### ğŸ”´ ì—ëŸ¬ ë°œìƒ ì§€ì ")
            lines.append("")
            error_call = call_chain[error_point - 1]
            lines.append(f"**ìœ„ì¹˜:** {error_call['index']}ë²ˆì§¸ í˜¸ì¶œ")
            lines.append(f"**ë ˆì´ì–´:** {error_call['layer']}")
            lines.append(f"**ì»´í¬ë„ŒíŠ¸:** {error_call['class_name']}.{error_call['method_name']}" if error_call['class_name'] else error_call['service'])

            if error_call['exception']:
                lines.append(f"**ì˜ˆì™¸:** {error_call['exception']}")

            lines.append("")

        # ìš”ì•½
        lines.append("### ğŸ’¡ ìš”ì•½")
        lines.append("")
        lines.append(f"- **ì´ í˜¸ì¶œ ìˆ˜:** {len(call_chain)}ê±´")

        if total_time > 0:
            lines.append(f"- **ì´ ì‹¤í–‰ ì‹œê°„:** {total_time}ms")

            if total_time > 1000:
                lines.append(f"- **ì„±ëŠ¥ í‰ê°€:** ğŸ”´ ëŠë¦¼ (1ì´ˆ ì´ˆê³¼)")
            elif total_time > 500:
                lines.append(f"- **ì„±ëŠ¥ í‰ê°€:** ğŸŸ¡ ë³´í†µ (500ms ì´ˆê³¼)")
            else:
                lines.append(f"- **ì„±ëŠ¥ í‰ê°€:** ğŸŸ¢ ë¹ ë¦„ (500ms ì´í•˜)")

        if error_point:
            lines.append(f"- **ì—ëŸ¬ ë°œìƒ:** {error_point}ë²ˆì§¸ í˜¸ì¶œì—ì„œ ì‹¤íŒ¨")

        # ê¶Œì¥ ì¡°ì¹˜
        if slow_calls or error_point:
            lines.append("")
            lines.append("### âœ… ê¶Œì¥ ì¡°ì¹˜")
            lines.append("")

            if slow_calls:
                slowest = slow_calls[0]
                component = f"{slowest['class_name']}.{slowest['method_name']}" if slowest['class_name'] and slowest['method_name'] else slowest['service']
                lines.append(f"1. **{component} ì„±ëŠ¥ ê°œì„ ** ({slowest['execution_time']}ms ì†Œìš”)")

            if error_point:
                lines.append(f"2. **ì—ëŸ¬ ë°œìƒ ì»´í¬ë„ŒíŠ¸ ìˆ˜ì •**: {error_call['index']}ë²ˆì§¸ í˜¸ì¶œ")

        return "\n".join(lines)

    except Exception as e:
        return f"ì»´í¬ë„ŒíŠ¸ í˜¸ì¶œ ì¶”ì  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
async def get_hottest_methods(
    project_uuid: str,
    time_hours: int = 24,
    limit: int = 20,
    only_errors: bool = False
) -> str:
    """
    ê°€ì¥ ë§ì´ í˜¸ì¶œ/ì‹¤í–‰ëœ ë©”ì„œë“œ ìˆœìœ„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

    ì´ ë„êµ¬ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    - âœ… class_name + method_name ì¡°í•©ìœ¼ë¡œ í˜¸ì¶œ ë¹ˆë„ ì§‘ê³„
    - âœ… ì—ëŸ¬ ë°œìƒ ë¹ˆë„ í•¨ê»˜ í‘œì‹œ
    - âœ… ë ˆì´ì–´ ë° ì„œë¹„ìŠ¤ ì •ë³´ í¬í•¨
    - âœ… ì‹¤í–‰ ì‹œê°„ í‰ê·  ê³„ì‚°
    - âŒ íŠ¹ì • íŒŒë¼ë¯¸í„°ë³„ í˜¸ì¶œì€ ë¶„ì„ ì•ˆ í•¨

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    1. "ì–´ë–¤ ë©”ì„œë“œê°€ ê°€ì¥ ë§ì´ ì‹¤í–‰ë¼?"
    2. "í•«ìŠ¤íŒŸ ë©”ì„œë“œ ì°¾ê¸°"
    3. "ì—ëŸ¬ ë§ì´ ë°œìƒí•˜ëŠ” ë©”ì„œë“œ"
    4. "ì„±ëŠ¥ ìµœì í™” ëŒ€ìƒ ì„ ì •"

    âš ï¸ ì¤‘ìš”í•œ ì œì•½ì‚¬í•­:
    - 1íšŒ í˜¸ì¶œë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤
    - method_nameì´ ì—†ëŠ” ë¡œê·¸ëŠ” ì œì™¸ë©ë‹ˆë‹¤
    - ê¸°ë³¸ ë¶„ì„ ê¸°ê°„ì€ 24ì‹œê°„ì…ë‹ˆë‹¤

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        time_hours: ë¶„ì„ ê¸°ê°„ (ê¸°ë³¸ 24ì‹œê°„)
        limit: ì¡°íšŒí•  ë©”ì„œë“œ ê°œìˆ˜ (ê¸°ë³¸ 20ê°œ)
        only_errors: ì—ëŸ¬ ë°œìƒ ë©”ì„œë“œë§Œ ì¡°íšŒ (ê¸°ë³¸ False)

    ê´€ë ¨ ë„êµ¬:
    - analyze_error_by_layer: ë ˆì´ì–´ë³„ ì—ëŸ¬ ë¶„í¬
    - get_slowest_apis: ëŠë¦° API ë¶„ì„
    - get_error_frequency_ranking: ì—ëŸ¬ íƒ€ì…ë³„ ë¹ˆë„

    Returns:
        ë©”ì„œë“œ í˜¸ì¶œ ë¹ˆë„ TOP-N, ì—ëŸ¬ ë°œìƒ í†µê³„
    """
    # ì¸ë±ìŠ¤ íŒ¨í„´
    index_pattern = f"{project_uuid.replace('-', '_')}_*"

    # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=time_hours)

    # Query êµ¬ì„±
    must_clauses = [
        {"exists": {"field": "method_name"}},
        {"range": {
            "timestamp": {
                "gte": start_time.isoformat() + "Z",
                "lte": end_time.isoformat() + "Z"
            }
        }}
    ]

    if only_errors:
        must_clauses.append({"term": {"level": "ERROR"}})

    try:
        # OpenSearch ì§‘ê³„ ì¿¼ë¦¬
        results = opensearch_client.search(
            index=index_pattern,
            body={
                "size": 0,
                "query": {"bool": {"must": must_clauses}},
                "aggs": {
                    "by_method": {
                        "terms": {
                            "script": {
                                "source": "doc['class_name'].value + '.' + doc['method_name'].value",
                                "lang": "painless"
                            },
                            "size": limit
                        },
                        "aggs": {
                            "error_count": {
                                "filter": {"term": {"level": "ERROR"}}
                            },
                            "avg_execution_time": {
                                "avg": {"field": "log_details.execution_time"}
                            },
                            "sample": {
                                "top_hits": {
                                    "size": 1,
                                    "_source": ["service_name", "layer", "class_name", "method_name"]
                                }
                            }
                        }
                    }
                }
            }
        )

        aggs = results.get("aggregations", {})
        method_buckets = aggs.get("by_method", {}).get("buckets", [])

        if not method_buckets:
            filter_msg = "ì—ëŸ¬ ë°œìƒ " if only_errors else ""
            return (
                f"ìµœê·¼ {time_hours}ì‹œê°„ ë™ì•ˆ {filter_msg}ë©”ì„œë“œ í˜¸ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n\n"
                f"ğŸ’¡ í™•ì¸ ì‚¬í•­:\n"
                f"1. ë¡œê·¸ì— method_name í•„ë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”\n"
                f"2. ì‹œê°„ ë²”ìœ„ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš” (time_hours ì¦ê°€)\n"
                f"3. only_errors=Falseë¡œ ì „ì²´ ë©”ì„œë“œë¥¼ ì¡°íšŒí•´ë³´ì„¸ìš”"
            )

        # ê²°ê³¼ í¬ë§·íŒ…
        title_suffix = " (ì—ëŸ¬ ë°œìƒë§Œ)" if only_errors else ""
        lines = [
            f"## ğŸ”¥ í•«ìŠ¤íŒŸ ë©”ì„œë“œ TOP {limit}{title_suffix}",
            f"**ê¸°ê°„:** ìµœê·¼ {time_hours}ì‹œê°„",
            f"**ë©”ì„œë“œ ìˆ˜:** {len(method_buckets)}ê°œ",
            ""
        ]

        # ë©”ì„œë“œë³„ í†µê³„ í…Œì´ë¸”
        lines.append("| ìˆœìœ„ | ë©”ì„œë“œ | í˜¸ì¶œ ìˆ˜ | ì—ëŸ¬ | í‰ê·  ì‹œê°„ | ì„œë¹„ìŠ¤ | ë ˆì´ì–´ |")
        lines.append("|------|--------|---------|------|-----------|---------|--------|")

        for i, bucket in enumerate(method_buckets, 1):
            method_full = bucket.get("key", "Unknown")
            call_count = bucket.get("doc_count", 0)
            error_count = bucket.get("error_count", {}).get("doc_count", 0)
            avg_time = bucket.get("avg_execution_time", {}).get("value")

            # ìƒ˜í”Œ ì •ë³´
            sample_hits = bucket.get("sample", {}).get("hits", {}).get("hits", [])
            if sample_hits:
                sample = sample_hits[0]["_source"]
                service = sample.get("service_name", "unknown")
                layer = sample.get("layer", "-")
            else:
                service = "unknown"
                layer = "-"

            # ì—ëŸ¬ìœ¨
            error_rate = (error_count / call_count * 100) if call_count > 0 else 0

            # í‰ê·  ì‹œê°„ í¬ë§·íŒ…
            if avg_time:
                time_str = f"{avg_time:.0f}ms"
                if avg_time > 500:
                    time_str = f"ğŸ”´ {time_str}"
                elif avg_time > 200:
                    time_str = f"ğŸŸ¡ {time_str}"
            else:
                time_str = "-"

            # ì—ëŸ¬ í‘œì‹œ
            if error_count > 0:
                error_str = f"ğŸ”´ **{error_count}ê±´** ({error_rate:.1f}%)"
            else:
                error_str = "ğŸŸ¢ 0"

            lines.append(
                f"| {i} | {method_full} | **{call_count}** | {error_str} | {time_str} | {service} | {layer} |"
            )

        lines.append("")

        # í†µê³„ ìš”ì•½
        total_calls = sum([b.get("doc_count", 0) for b in method_buckets])
        total_errors = sum([b.get("error_count", {}).get("doc_count", 0) for b in method_buckets])

        lines.append("### ğŸ“Š í†µê³„ ìš”ì•½")
        lines.append("")
        lines.append(f"- **ì´ í˜¸ì¶œ ìˆ˜:** {total_calls:,}ê±´ (ìƒìœ„ {len(method_buckets)}ê°œ ë©”ì„œë“œ)")
        lines.append(f"- **ì´ ì—ëŸ¬ ìˆ˜:** {total_errors}ê±´")

        if total_calls > 0:
            overall_error_rate = (total_errors / total_calls * 100)
            lines.append(f"- **ì „ì²´ ì—ëŸ¬ìœ¨:** {overall_error_rate:.2f}%")

        # ê°€ì¥ ë¬¸ì œ ë§ì€ ë©”ì„œë“œ
        error_sorted = sorted(method_buckets, key=lambda x: x.get("error_count", {}).get("doc_count", 0), reverse=True)
        if error_sorted[0].get("error_count", {}).get("doc_count", 0) > 0:
            lines.append("")
            lines.append("### ğŸš¨ ì—ëŸ¬ ë§ì€ ë©”ì„œë“œ TOP 5")
            lines.append("")

            for i, bucket in enumerate(error_sorted[:5], 1):
                method = bucket.get("key", "")
                err_count = bucket.get("error_count", {}).get("doc_count", 0)
                if err_count == 0:
                    break
                lines.append(f"{i}. **{method}** - {err_count}ê±´")

        # ê¶Œì¥ ì¡°ì¹˜
        lines.append("")
        lines.append("### âœ… ê¶Œì¥ ì¡°ì¹˜")
        lines.append("")

        # ì—ëŸ¬ ë§ì€ ë©”ì„œë“œ
        if total_errors > 0:
            worst_method = error_sorted[0]
            worst_error_count = worst_method.get("error_count", {}).get("doc_count", 0)
            if worst_error_count > 5:
                lines.append(f"1. **{worst_method.get('key', '')} ë©”ì„œë“œ ìš°ì„  ìˆ˜ì •** ({worst_error_count}ê±´ ì—ëŸ¬)")

        # í˜¸ì¶œ ë¹ˆë„ ë†’ì€ ë©”ì„œë“œ
        hottest = method_buckets[0]
        hottest_count = hottest.get("doc_count", 0)
        if hottest_count > 100:
            lines.append(f"2. **{hottest.get('key', '')} ì„±ëŠ¥ ìµœì í™”** (í˜¸ì¶œ ë¹ˆë„ ë†’ìŒ: {hottest_count}ê±´)")

        # í‰ê·  ì‹œê°„ ëŠë¦° ë©”ì„œë“œ
        time_sorted = sorted(method_buckets, key=lambda x: x.get("avg_execution_time", {}).get("value") or 0, reverse=True)
        if time_sorted[0].get("avg_execution_time", {}).get("value", 0) > 500:
            slowest = time_sorted[0]
            lines.append(f"3. **{slowest.get('key', '')} ì‘ë‹µ ì‹œê°„ ê°œì„ ** (í‰ê·  {slowest.get('avg_execution_time', {}).get('value', 0):.0f}ms)")

        return "\n".join(lines)

    except Exception as e:
        return f"í•«ìŠ¤íŒŸ ë©”ì„œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
