"""
ì„±ëŠ¥ ë¶„ì„ ë„êµ¬ (Performance Analysis Tools)
- API ì‘ë‹µ ì‹œê°„ ë¶„ì„, íŠ¸ë˜í”½ ë¶„í¬ ë¶„ì„
"""

from typing import Optional
from datetime import datetime, timedelta
from langchain_core.tools import tool

from app.core.opensearch import opensearch_client


@tool
async def get_slowest_apis(
    project_uuid: str,
    limit: int = 10,
    time_hours: int = 168,  # ê¸°ë³¸ 7ì¼
    service_name: Optional[str] = None,
    min_execution_time: Optional[int] = None
) -> str:
    """
    ì‘ë‹µ ì‹œê°„ì´ ê°€ì¥ ëŠë¦° API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤ (í‰ê·  ì‹œê°„ ê¸°ì¤€).

    ì´ ë„êµ¬ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    - âœ… APIë³„ í‰ê· /ìµœëŒ€/ìµœì†Œ ì‘ë‹µ ì‹œê°„ ì§‘ê³„
    - âœ… P50/P95/P99 ë°±ë¶„ìœ„ìˆ˜ ì œê³µ
    - âœ… ì„±ëŠ¥ ë“±ê¸‰ íŒì • (ë¹ ë¦„/ë³´í†µ/ëŠë¦¼/ë§¤ìš° ëŠë¦¼)
    - âœ… ìš”ì²­ ìˆ˜ í†µê³„ í¬í•¨
    - âŒ íŠ¹ì • ì‹œê°„ëŒ€ íŠ¸ë˜í”½ ë¶„í¬ëŠ” ì œê³µ ì•ˆ í•¨ (get_traffic_by_time ì‚¬ìš©)
    - âŒ ì—ëŸ¬ ë¶„ì„ì€ í•˜ì§€ ì•ŠìŒ (get_recent_errors ì‚¬ìš©)
    - âŒ ì‹œê°„ëŒ€ë³„ ì¶”ì„¸ëŠ” ì œê³µ ì•ˆ í•¨ (get_traffic_by_time ì‚¬ìš©)

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    1. "ê°€ì¥ ëŠë¦° APIëŠ”?"
    2. "ì‘ë‹µ ì‹œê°„ì´ 5ì´ˆ ë„˜ëŠ” API ì°¾ì•„ì¤˜"
    3. "ì„±ëŠ¥ ë³‘ëª© ì§€ì  íŒŒì•…"

    âš ï¸ ì¤‘ìš”í•œ ì œì•½ì‚¬í•­:
    - 1íšŒ í˜¸ì¶œë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤
    - execution_time ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê²°ê³¼ ì—†ìŒ (ì •ìƒ)
    - ê¸°ë³¸ ë¶„ì„ ê¸°ê°„ì€ 7ì¼ì…ë‹ˆë‹¤

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        limit: ì¡°íšŒí•  API ê°œìˆ˜ (ê¸°ë³¸ 10ê°œ)
        time_hours: ë¶„ì„ ê¸°ê°„ (ê¸°ë³¸ 168ì‹œê°„=7ì¼)
        service_name: ì„œë¹„ìŠ¤ í•„í„° (ì„ íƒ)
        min_execution_time: ìµœì†Œ ì‹¤í–‰ ì‹œê°„ (ë°€ë¦¬ì´ˆ, ì„ íƒ)

    ê´€ë ¨ ë„êµ¬:
    - get_traffic_by_time: ì‹œê°„ëŒ€ë³„ íŠ¸ë˜í”½ ë¶„í¬
    - get_error_rate_trend: ì‹œê°„ëŒ€ë³„ ì—ëŸ¬ìœ¨ ì¶”ì„¸
    - analyze_deployment_impact: ë°°í¬ ì „í›„ ì„±ëŠ¥ ë¹„êµ

    Returns:
        ëŠë¦° API ëª©ë¡ (í‰ê· /P95/P99, ì„±ëŠ¥ ë“±ê¸‰)
    """
    # ì¸ë±ìŠ¤ íŒ¨í„´ (UUIDì˜ í•˜ì´í”ˆì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€í™˜)
    index_pattern = f"{project_uuid.replace('-', '_')}_*"

    # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=time_hours)

    # Query êµ¬ì„±
    # í‰ë©´ êµ¬ì¡°ì™€ nested êµ¬ì¡° ëª¨ë‘ ì§€ì› (execution_time, duration, log_details.execution_time)
    must_clauses = [
        {
            "bool": {
                "should": [
                    {"exists": {"field": "log_details.execution_time"}},
                    {"exists": {"field": "execution_time"}},  # í‰ë©´ êµ¬ì¡° ì§€ì›
                    {"exists": {"field": "duration"}}
                ],
                "minimum_should_match": 1
            }
        },
        {"range": {
            "timestamp": {
                "gte": start_time.isoformat() + "Z",
                "lte": end_time.isoformat() + "Z"
            }
        }}
        # ì£¼ì˜: HTTP API í•„ìˆ˜ í•„í„° ì œê±° (ë°ì´í„° ìˆ˜ì§‘ ë²”ìœ„ í™•ëŒ€)
        # request_uriê°€ ì—†ëŠ” ë¡œê·¸ë„ í¬í•¨í•˜ì—¬ ë” ë§ì€ ë°ì´í„° ë¶„ì„
    ]

    if service_name:
        must_clauses.append({"term": {"service_name": service_name}})

    if min_execution_time:
        # ëª¨ë“  execution_time í•„ë“œì— ëŒ€í•´ í•„í„° ì ìš©
        must_clauses.append({
            "bool": {
                "should": [
                    {"range": {"log_details.execution_time": {"gte": min_execution_time}}},
                    {"range": {"execution_time": {"gte": min_execution_time}}},  # í‰ë©´ êµ¬ì¡°
                    {"range": {"duration": {"gte": min_execution_time}}}
                ],
                "minimum_should_match": 1
            }
        })

    try:
        # OpenSearch Aggregation Query
        results = opensearch_client.search(
            index=index_pattern,
            body={
                "size": 0,  # ì§‘ê³„ë§Œ ìˆ˜í–‰
                "query": {
                    "bool": {"must": must_clauses}
                },
                "aggs": {
                    "by_api": {
                        "terms": {
                            # HTTP ë©”ì„œë“œ + request_uri ì¡°í•©ìœ¼ë¡œ API ì‹ë³„ (í´ë°±: class_name.method_name)
                            "script": {
                                "source": """
                                    String httpMethod = 'N/A';
                                    String requestUri = 'unknown';
                                    String className = null;
                                    String methodName = null;

                                    // HTTP ë©”ì„œë“œ ì¶”ì¶œ
                                    if (doc.containsKey('log_details.http_method') &&
                                        doc['log_details.http_method'].size() > 0) {
                                        httpMethod = doc['log_details.http_method'].value;
                                    }

                                    // Request URI ì¶”ì¶œ (.keyword ì„œë¸Œí•„ë“œ ì‚¬ìš©)
                                    if (doc['log_details.request_uri.keyword'].size() > 0) {
                                        requestUri = doc['log_details.request_uri.keyword'].value;
                                    }

                                    // Request URIê°€ ìˆìœ¼ë©´ HTTP APIë¡œ ì‹ë³„
                                    if (requestUri != 'unknown') {
                                        return httpMethod + ' ' + requestUri;
                                    }

                                    // ì—†ìœ¼ë©´ class_name.method_nameìœ¼ë¡œ í´ë°±
                                    if (doc.containsKey('class_name') && doc['class_name'].size() > 0) {
                                        className = doc['class_name'].value;
                                    }
                                    if (doc.containsKey('method_name') && doc['method_name'].size() > 0) {
                                        methodName = doc['method_name'].value;
                                    }

                                    if (className != null && methodName != null) {
                                        return className + '.' + methodName;
                                    } else if (className != null) {
                                        return className;
                                    } else {
                                        return 'unknown';
                                    }
                                """
                            },
                            "size": limit,
                            "order": {"avg_time": "desc"}  # í‰ê·  ì‹œê°„ ë‚´ë¦¼ì°¨ìˆœ
                        },
                        "aggs": {
                            "avg_time": {
                                "avg": {
                                    # í‰ë©´/nested êµ¬ì¡° ëª¨ë‘ ì§€ì›
                                    "script": {
                                        "source": """
                                            if (doc.containsKey('log_details.execution_time') &&
                                                doc['log_details.execution_time'].size() > 0) {
                                                return doc['log_details.execution_time'].value;
                                            } else if (doc.containsKey('execution_time') &&
                                                       doc['execution_time'].size() > 0) {
                                                return doc['execution_time'].value;
                                            } else if (doc.containsKey('duration') &&
                                                       doc['duration'].size() > 0) {
                                                return doc['duration'].value;
                                            } else {
                                                return null;
                                            }
                                        """
                                    }
                                }
                            },
                            "max_time": {
                                "max": {
                                    "script": {
                                        "source": """
                                            if (doc.containsKey('log_details.execution_time') &&
                                                doc['log_details.execution_time'].size() > 0) {
                                                return doc['log_details.execution_time'].value;
                                            } else if (doc.containsKey('execution_time') &&
                                                       doc['execution_time'].size() > 0) {
                                                return doc['execution_time'].value;
                                            } else if (doc.containsKey('duration') &&
                                                       doc['duration'].size() > 0) {
                                                return doc['duration'].value;
                                            } else {
                                                return null;
                                            }
                                        """
                                    }
                                }
                            },
                            "min_time": {
                                "min": {
                                    "script": {
                                        "source": """
                                            if (doc.containsKey('log_details.execution_time') &&
                                                doc['log_details.execution_time'].size() > 0) {
                                                return doc['log_details.execution_time'].value;
                                            } else if (doc.containsKey('execution_time') &&
                                                       doc['execution_time'].size() > 0) {
                                                return doc['execution_time'].value;
                                            } else if (doc.containsKey('duration') &&
                                                       doc['duration'].size() > 0) {
                                                return doc['duration'].value;
                                            } else {
                                                return null;
                                            }
                                        """
                                    }
                                }
                            },
                            "percentiles": {
                                "percentiles": {
                                    "script": {
                                        "source": """
                                            if (doc.containsKey('log_details.execution_time') &&
                                                doc['log_details.execution_time'].size() > 0) {
                                                return doc['log_details.execution_time'].value;
                                            } else if (doc.containsKey('execution_time') &&
                                                       doc['execution_time'].size() > 0) {
                                                return doc['execution_time'].value;
                                            } else if (doc.containsKey('duration') &&
                                                       doc['duration'].size() > 0) {
                                                return doc['duration'].value;
                                            } else {
                                                return null;
                                            }
                                        """
                                    },
                                    "percents": [50, 95, 99]
                                }
                            },
                            "by_http_method": {
                                "terms": {
                                    "field": "log_details.http_method",
                                    "size": 5,
                                    "missing": "N/A"  # í•„ë“œê°€ ì—†ìœ¼ë©´ N/Aë¡œ í‘œì‹œ
                                }
                            }
                        }
                    }
                }
            }
        )

        # ì§‘ê³„ ê²°ê³¼ ì¶”ì¶œ
        buckets = results.get("aggregations", {}).get("by_api", {}).get("buckets", [])
        total_hits = results.get("hits", {}).get("total", {}).get("value", 0)

        # 'unknown' API ì œì™¸ (request_uriê°€ ì—†ëŠ” ë‚´ë¶€ ë©”ì„œë“œ)
        buckets = [b for b in buckets if b.get("key", "unknown") != "unknown"]

        if not buckets:
            from app.tools.response_templates import get_empty_result_message

            conditions = []
            if min_execution_time:
                conditions.append(f"ìµœì†Œ ì‹¤í–‰ì‹œê°„ â‰¥ {min_execution_time}ms")
            if service_name:
                conditions.append(f"ì„œë¹„ìŠ¤ëª… = {service_name}")
            conditions.append("execution_time í•„ë“œ ì¡´ì¬")

            condition_str = ", ".join(conditions)

            suggestions = [
                f"min_execution_time ì¡°ê±´ì„ ë‚®ì¶°ë³´ì„¸ìš” (í˜„ì¬: {min_execution_time}ms)" if min_execution_time else "í•„í„° ì—†ì´ ì „ì²´ ì¡°íšŒ (limit=10)",
                "ì‹œê°„ ë²”ìœ„ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš” (time_hours=336 for 14ì¼)",
                "ë¡œê·¸ì— execution_time í•„ë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"
            ]

            return get_empty_result_message(
                conditions=condition_str,
                time_hours=time_hours,
                suggestions=suggestions
            )

        # ê²°ê³¼ í¬ë§·íŒ…
        summary_lines = [
            f"=== ì‘ë‹µ ì‹œê°„ì´ ëŠë¦° API ë¶„ì„ (ìµœê·¼ {time_hours}ì‹œê°„) ===",
            f"ì´ {total_hits}ê±´ì˜ ìš”ì²­ ë¶„ì„, ìƒìœ„ {len(buckets)}ê°œ API í‘œì‹œ",
            ""
        ]

        # API ëª©ë¡
        for i, bucket in enumerate(buckets, 1):
            api_path = bucket.get("key", "N/A")
            doc_count = bucket.get("doc_count", 0)
            avg_time = bucket.get("avg_time", {}).get("value", 0)
            max_time = bucket.get("max_time", {}).get("value", 0)
            min_time = bucket.get("min_time", {}).get("value", 0)
            percentiles = bucket.get("percentiles", {}).get("values", {})
            p50 = percentiles.get("50.0", 0)
            p95 = percentiles.get("95.0", 0)
            p99 = percentiles.get("99.0", 0)

            summary_lines.append(f"{i}. {api_path}")
            summary_lines.append(f"   ğŸ“Š ìš”ì²­ ìˆ˜: {doc_count}ê±´")
            summary_lines.append(f"   â±ï¸  í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.0f}ms")
            summary_lines.append(f"   â±ï¸  ìµœëŒ€ ì‘ë‹µ ì‹œê°„: {max_time:.0f}ms")
            summary_lines.append(f"   â±ï¸  ìµœì†Œ ì‘ë‹µ ì‹œê°„: {min_time:.0f}ms")
            summary_lines.append(f"   ğŸ“ˆ P50 (ì¤‘ì•™ê°’): {p50:.0f}ms")
            summary_lines.append(f"   ğŸ“ˆ P95: {p95:.0f}ms")
            summary_lines.append(f"   ğŸ“ˆ P99: {p99:.0f}ms")

            # ì„±ëŠ¥ ë“±ê¸‰ íŒì •
            if avg_time > 5000:
                grade = "ğŸ”´ ë§¤ìš° ëŠë¦¼ (5ì´ˆ ì´ìƒ)"
            elif avg_time > 2000:
                grade = "ğŸŸ  ëŠë¦¼ (2-5ì´ˆ)"
            elif avg_time > 1000:
                grade = "ğŸŸ¡ ë³´í†µ (1-2ì´ˆ)"
            else:
                grade = "ğŸŸ¢ ë¹ ë¦„ (1ì´ˆ ì´í•˜)"
            summary_lines.append(f"   ë“±ê¸‰: {grade}")
            summary_lines.append("")

        return "\n".join(summary_lines)

    except Exception as e:
        return f"API ì„±ëŠ¥ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
async def get_traffic_by_time(
    project_uuid: str,
    interval: str = "1h",  # 1h, 30m, 1d ë“±
    time_hours: int = 168,  # ê¸°ë³¸ 7ì¼
    level: Optional[str] = None,
    service_name: Optional[str] = None
) -> str:
    """
    ì‹œê°„ëŒ€ë³„ íŠ¸ë˜í”½ ë¶„í¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤ (í”¼í¬ íƒ€ì„ íŒŒì•…).

    ì´ ë„êµ¬ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    - âœ… ì‹œê°„ëŒ€ë³„ ë¡œê·¸ ê±´ìˆ˜ ì§‘ê³„
    - âœ… í”¼í¬ íƒ€ì„ ìë™ ê°ì§€
    - âœ… ì‹œê°„ëŒ€ë³„ ë ˆë²¨ ë¶„í¬ (ERROR/WARN/INFO/DEBUG)
    - âœ… ì‹œê°„ëŒ€ë³„ ì£¼ìš” ì„œë¹„ìŠ¤ í‘œì‹œ
    - âŒ ì—ëŸ¬ìœ¨ ì¶”ì„¸ëŠ” ì œê³µ ì•ˆ í•¨ (get_error_rate_trend ì‚¬ìš©)
    - âŒ API ì‘ë‹µ ì‹œê°„ì€ ë¶„ì„ ì•ˆ í•¨ (get_slowest_apis ì‚¬ìš©)
    - âŒ ì„œë¹„ìŠ¤ë³„ í—¬ìŠ¤ëŠ” ì œê³µ ì•ˆ í•¨ (get_service_health_status ì‚¬ìš©)

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    1. "íŠ¸ë˜í”½ì´ ê°€ì¥ ë§ì€ ì‹œê°„ëŒ€ëŠ”?"
    2. "ì‹œê°„ëŒ€ë³„ ERROR ë°œìƒ íŒ¨í„´"
    3. "í”¼í¬ íƒ€ì„ íŒŒì•…"

    âš ï¸ ì¤‘ìš”í•œ ì œì•½ì‚¬í•­:
    - 1íšŒ í˜¸ì¶œë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤
    - ë°ì´í„° ì—†ëŠ” ì‹œê°„ëŒ€ë„ í‘œì‹œë©ë‹ˆë‹¤ (0ê±´ìœ¼ë¡œ)
    - KST ì‹œê°„ëŒ€ë¡œ í‘œì‹œë©ë‹ˆë‹¤

    ì…ë ¥ íŒŒë¼ë¯¸í„° (JSON í˜•ì‹):
        interval: ì§‘ê³„ ê°„ê²© (ê¸°ë³¸ 1h, ì˜µì…˜: 30m/1d)
        time_hours: ë¶„ì„ ê¸°ê°„ (ê¸°ë³¸ 168ì‹œê°„=7ì¼)
        level: ë¡œê·¸ ë ˆë²¨ í•„í„° (ì„ íƒ)
        service_name: ì„œë¹„ìŠ¤ í•„í„° (ì„ íƒ)

    ê´€ë ¨ ë„êµ¬:
    - get_error_rate_trend: ì‹œê°„ëŒ€ë³„ ì—ëŸ¬ìœ¨ ì¶”ì„¸
    - get_slowest_apis: API ì‘ë‹µ ì‹œê°„ ë¶„ì„
    - compare_time_periods: ë‘ ì‹œê°„ëŒ€ ë¹„êµ

    Returns:
        ì‹œê°„ëŒ€ë³„ íŠ¸ë˜í”½ (í”¼í¬ íƒ€ì„, ë ˆë²¨ë³„ ë¶„í¬, ì „ì²´ í†µê³„)
    """
    # ì¸ë±ìŠ¤ íŒ¨í„´ (UUIDì˜ í•˜ì´í”ˆì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€í™˜)
    index_pattern = f"{project_uuid.replace('-', '_')}_*"

    # ì‹œê°„ ë²”ìœ„ ê³„ì‚°
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=time_hours)

    # Query êµ¬ì„±
    must_clauses = [
        {"range": {
            "timestamp": {
                "gte": start_time.isoformat() + "Z",
                "lte": end_time.isoformat() + "Z"
            }
        }}
    ]

    if level:
        must_clauses.append({"term": {"level": level.upper()}})

    if service_name:
        must_clauses.append({"term": {"service_name": service_name}})

    try:
        # OpenSearch Date Histogram Aggregation
        results = opensearch_client.search(
            index=index_pattern,
            body={
                "size": 0,  # ì§‘ê³„ë§Œ ìˆ˜í–‰
                "query": {
                    "bool": {"must": must_clauses}
                },
                "aggs": {
                    "traffic_over_time": {
                        "date_histogram": {
                            "field": "timestamp",
                            "fixed_interval": interval,
                            "time_zone": "Asia/Seoul",  # KST ì‹œê°„ëŒ€
                            "min_doc_count": 0  # ë°ì´í„° ì—†ëŠ” ì‹œê°„ëŒ€ë„ í‘œì‹œ
                        },
                        "aggs": {
                            "by_level": {
                                "terms": {
                                    "field": "level",
                                    "size": 10
                                }
                            },
                            "by_service": {
                                "terms": {
                                    "field": "service_name",
                                    "size": 5
                                }
                            }
                        }
                    }
                }
            }
        )

        # ì§‘ê³„ ê²°ê³¼ ì¶”ì¶œ
        buckets = results.get("aggregations", {}).get("traffic_over_time", {}).get("buckets", [])
        total_hits = results.get("hits", {}).get("total", {}).get("value", 0)

        if not buckets:
            return f"ìµœê·¼ {time_hours}ì‹œê°„ ë™ì•ˆ íŠ¸ë˜í”½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ê²°ê³¼ í¬ë§·íŒ…
        summary_lines = [
            f"=== ì‹œê°„ëŒ€ë³„ íŠ¸ë˜í”½ ë¶„ì„ (ìµœê·¼ {time_hours}ì‹œê°„, ê°„ê²©: {interval}) ===",
            f"ì´ {total_hits}ê±´ì˜ ë¡œê·¸ ë¶„ì„, {len(buckets)}ê°œ ì‹œê°„ëŒ€",
            ""
        ]

        # í”¼í¬ íƒ€ì„ ì°¾ê¸°
        peak_bucket = max(buckets, key=lambda b: b.get("doc_count", 0))
        peak_time = peak_bucket.get("key_as_string", "N/A")
        peak_count = peak_bucket.get("doc_count", 0)

        summary_lines.append(f"ğŸ”¥ í”¼í¬ íƒ€ì„: {peak_time[:16].replace('T', ' ')} ({peak_count}ê±´)")
        summary_lines.append("")

        # ì‹œê°„ëŒ€ë³„ ìƒì„¸ ì •ë³´ (ìƒìœ„ 10ê°œ ë˜ëŠ” ì „ì²´)
        summary_lines.append("ì‹œê°„ëŒ€ë³„ íŠ¸ë˜í”½:")
        display_buckets = sorted(buckets, key=lambda b: b.get("doc_count", 0), reverse=True)[:15]

        for bucket in display_buckets:
            time_str = bucket.get("key_as_string", "")[:16].replace("T", " ")  # YYYY-MM-DD HH:MM
            doc_count = bucket.get("doc_count", 0)

            # ë ˆë²¨ë³„ ë¶„í¬
            level_buckets = bucket.get("by_level", {}).get("buckets", [])
            level_dist = {lb["key"]: lb["doc_count"] for lb in level_buckets}

            # ì„œë¹„ìŠ¤ë³„ ë¶„í¬
            service_buckets = bucket.get("by_service", {}).get("buckets", [])
            top_service = service_buckets[0]["key"] if service_buckets else "N/A"

            # ê¸°ë³¸ ì •ë³´
            summary_lines.append(f"  ğŸ“… {time_str} | ì´ {doc_count}ê±´")

            # ë ˆë²¨ë³„ ë¶„í¬ (ERRORê°€ ìˆìœ¼ë©´ ê°•ì¡°)
            if level_dist:
                level_str_parts = []
                for lvl in ["ERROR", "WARN", "INFO", "DEBUG"]:
                    if lvl in level_dist:
                        count = level_dist[lvl]
                        emoji = "âŒ" if lvl == "ERROR" else "âš ï¸" if lvl == "WARN" else "â„¹ï¸" if lvl == "INFO" else "ğŸ›"
                        level_str_parts.append(f"{emoji}{lvl}({count})")
                if level_str_parts:
                    summary_lines.append(f"     ë ˆë²¨: {', '.join(level_str_parts)}")

            # ì£¼ìš” ì„œë¹„ìŠ¤
            if top_service != "N/A":
                summary_lines.append(f"     ì£¼ìš” ì„œë¹„ìŠ¤: {top_service}")

            summary_lines.append("")

        # ì „ì²´ ë ˆë²¨ ë¶„í¬ ìš”ì•½
        summary_lines.append("ì „ì²´ ë ˆë²¨ ë¶„í¬:")
        all_level_counts = {}
        for bucket in buckets:
            for lb in bucket.get("by_level", {}).get("buckets", []):
                level_key = lb["key"]
                all_level_counts[level_key] = all_level_counts.get(level_key, 0) + lb["doc_count"]

        for lvl in ["ERROR", "WARN", "INFO", "DEBUG"]:
            if lvl in all_level_counts:
                count = all_level_counts[lvl]
                percentage = (count / total_hits * 100) if total_hits > 0 else 0
                summary_lines.append(f"  - {lvl}: {count}ê±´ ({percentage:.1f}%)")

        return "\n".join(summary_lines)

    except Exception as e:
        return f"íŠ¸ë˜í”½ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@tool
async def analyze_http_error_matrix(
    project_uuid: str,
    time_hours: int = 168,
    group_by_status: bool = True
) -> str:
    """HTTP ìƒíƒœ ì½”ë“œë³„ ì—”ë“œí¬ì¸íŠ¸ ì—ëŸ¬ ë§¤íŠ¸ë¦­ìŠ¤. ì‚¬ìš©: "ì–´ë–¤ APIê°€ 500 ì—ëŸ¬ë¥¼ ë§ì´ ë‚´?", "4xx vs 5xx ë¶„í¬" âš ï¸ 1íšŒ í˜¸ì¶œ ì¶©ë¶„"""
    from datetime import datetime, timedelta
    from app.core.opensearch import opensearch_client
    
    index_pattern = f"{project_uuid.replace('-', '_')}_*"
    end_time = datetime.utcnow()
    start_time = end_time - timedelta(hours=time_hours)
    
    try:
        results = opensearch_client.search(index=index_pattern, body={
            "size": 0,
            "query": {"bool": {"must": [
                {"range": {"timestamp": {"gte": start_time.isoformat()+"Z", "lte": end_time.isoformat()+"Z"}}},
                {"exists": {"field": "log_details.request_uri"}},
                {"range": {"log_details.response_status": {"gte": 400}}}]}},
            "aggs": {"by_api": {"terms": {"field": "log_details.request_uri", "size": 20},
                "aggs": {
                    "status_4xx": {"filter": {"range": {"log_details.response_status": {"gte": 400, "lt": 500}}}},
                    "status_5xx": {"filter": {"range": {"log_details.response_status": {"gte": 500, "lt": 600}}}}
                }}}})
        
        buckets = results.get("aggregations", {}).get("by_api", {}).get("buckets", [])
        if not buckets: return f"ìµœê·¼ {time_hours}ì‹œê°„ HTTP ì—ëŸ¬ ì—†ìŒ"
        
        lines = [f"## ğŸŒ HTTP ì—ëŸ¬ ë§¤íŠ¸ë¦­ìŠ¤ (ìµœê·¼ {time_hours//24}ì¼)", ""]
        lines.extend(["| API | 4xx | 5xx | í•©ê³„ |", "|-----|-----|-----|------|"])
        for b in buckets[:15]:
            api = b.get("key", "")[:40]
            c4xx = b.get("status_4xx", {}).get("doc_count", 0)
            c5xx = b.get("status_5xx", {}).get("doc_count", 0)
            total = c4xx + c5xx
            emoji = "ğŸ”´" if c5xx > c4xx else "ğŸŸ¡"
            lines.append(f"| {api} | {c4xx} | {c5xx} | {emoji} {total} |")
        return "\n".join(lines)
    except Exception as e:
        return f"HTTP ì—ëŸ¬ ë§¤íŠ¸ë¦­ìŠ¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}"

