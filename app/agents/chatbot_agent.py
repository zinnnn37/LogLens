"""
ReAct Agent for Log Analysis

LLMÏù¥ ÏûêÏú®Ï†ÅÏúºÎ°ú ÎèÑÍµ¨Î•º ÏÑ†ÌÉùÌïòÏó¨ Î°úÍ∑∏ Î∂ÑÏÑù ÏàòÌñâ
"""

from typing import List

from langchain.agents import create_react_agent, AgentExecutor
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.tools import Tool

from app.tools.search_tools import search_logs_by_keyword, search_logs_by_similarity
from app.tools.analysis_tools import get_log_statistics, get_recent_errors
from app.tools.detail_tools import get_log_detail, get_logs_by_trace_id
from app.tools.performance_tools import get_slowest_apis, get_traffic_by_time
from app.tools.monitoring_tools import (
    get_error_rate_trend,
    get_service_health_status,
    get_error_frequency_ranking,
    get_api_error_rates,
    get_affected_users_count
)
from app.tools.comparison_tools import compare_time_periods, detect_cascading_failures
from app.tools.alert_tools import evaluate_alert_conditions, detect_resource_issues
from app.tools.deployment_tools import analyze_deployment_impact
from app.core.config import settings


# ReAct Agent System Prompt (ÌïúÍµ≠Ïñ¥) - LangChain ÌëúÏ§Ä ÌòïÏãù
AGENT_PROMPT_TEMPLATE = """Answer the following questions as best you can. You have access to the following tools:

{tools}

CRITICAL RULES FOR "NO DATA FOUND" RESPONSES:
- If a tool returns "Î°úÍ∑∏Í∞Ä ÏóÜÏäµÎãàÎã§" or "ERROR Î†àÎ≤® Î°úÍ∑∏Í∞Ä ÏóÜÏäµÎãàÎã§" or "Í≤ÄÏÉâ Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§", this is a VALID FINAL RESULT
- DO NOT retry with different parameters
- DO NOT try other tools
- IMMEDIATELY write: "Thought: I now know the final answer" followed by "Final Answer: [explain no logs found]"
- Example response format when no data found:
  Thought: I now know the final answer
  Final Answer: ÏµúÍ∑º 24ÏãúÍ∞Ñ ÎèôÏïà ERROR Î°úÍ∑∏Í∞Ä Î∞úÏÉùÌïòÏßÄ ÏïäÏïòÏäµÎãàÎã§. ÏãúÏä§ÌÖúÏù¥ Ï†ïÏÉÅ ÏûëÎèô Ï§ëÏûÖÎãàÎã§.

SEVERITY ASSESSMENT GUIDELINES (for "Í∞ÄÏû• Ïã¨Í∞ÅÌïú", "most serious" questions):
- CRITICAL (Ï¶âÏãú Ï°∞Ïπò): Database/Connection errors, OutOfMemory, StackOverflow, Deadlock, 5xx errors (affects all users)
- HIGH (Í∏¥Í∏â Ï°∞Ïπò): Authentication/Security errors, InvalidToken, AuthFailure, UnauthorizedAccess (security risk)
- MEDIUM (Ïö∞ÏÑ† Ï°∞Ïπò): NullPointerException, IllegalStateException, RuntimeException (specific feature broken)
- LOW (Î™®ÎãàÌÑ∞ÎßÅ): 4xx errors, validation errors, slow queries (client-side or performance issues only)
- When asked "Í∞ÄÏû• Ïã¨Í∞ÅÌïú ÏóêÎü¨", "most critical error": Call get_recent_errors ONCE, analyze results, provide Final Answer
- DO NOT call get_recent_errors multiple times with different service_name filters unless specifically requested
- The tool returns errors sorted by severity automatically - trust the order

EFFICIENCY RULES (ÌíàÏßàÍ≥º ÏÜçÎèÑÏùò Í∑†Ìòï):
- For "most X" questions (Í∞ÄÏû• Ïã¨Í∞ÅÌïú, Í∞ÄÏû• ÎßéÏùÄ, most frequent), use ONE broad query first without filters
- Analyze the results - if insufficient data, you MAY call tools 1-2 more times with refined parameters
- Quality over speed: If initial results lack detail, fetch additional context (e.g., log details, related traces)
- AVOID excessive iteration (max 3-4 tool calls total for comprehensive analysis)
- Example workflow: "Í∞ÄÏû• Ïã¨Í∞ÅÌïú ÏóêÎü¨Í∞Ä Î≠êÏïº?" ‚Üí get_recent_errors(limit=10) ‚Üí [optional: get_log_detail if stack trace needed] ‚Üí Final Answer (2-3 tool calls acceptable)

AI ANALYSIS FIELD USAGE (IMPORTANT):
- Tools now return ai_analysis fields: summary, error_cause, solution, tags, analysis_type
- **IF ai_analysis.summary EXISTS**: Include it prominently in your Final Answer (it's already analyzed by AI)
- **IF ai_analysis.error_cause EXISTS**: Use it to explain the root cause
- **IF ai_analysis.solution EXISTS**: Include it as recommended action
- **IF ai_analysis.tags EXIST**: Use them to categorize or identify error types
- **IMPORTANT**: ai_analysis fields may be empty for some logs - handle gracefully
- Prioritize AI analysis results over manual analysis when available
- Example: If tool returns "ü§ñ AI Î∂ÑÏÑù: ...", integrate it into your answer

TIME PARSING GUIDELINES:
- "ÏµúÍ∑º NÏùº" or "NÏùº ÎèôÏïà" ‚Üí time_hours = N * 24
- "Ïñ¥Ï†ú" ‚Üí time_hours = 24
- "Ïù¥Î≤à Ï£º" ‚Üí time_hours = 168 (7 days)
- "ÏµúÍ∑º 1ÏãúÍ∞Ñ" or "1ÏãúÍ∞Ñ ÎèôÏïà" ‚Üí time_hours = 1
- "Ïò§Îäò" ‚Üí time_hours = 24
- Always extract time values accurately from user questions

PERFORMANCE ANALYSIS GUIDELINES (IMPORTANT):
- For "ÏùëÎãµ ÏãúÍ∞ÑÏù¥ Í∞ÄÏû• ÎäêÎ¶∞ API", "slowest API" questions: Use get_slowest_apis tool
- For "Ìä∏ÎûòÌîΩÏù¥ Í∞ÄÏû• ÎßéÏùÄ ÏãúÍ∞ÑÎåÄ", "peak traffic time" questions: Use get_traffic_by_time tool
- For "ÌèâÍ∑† ÏùëÎãµ ÏãúÍ∞Ñ", "average response time" questions: Use get_slowest_apis with appropriate limit
- get_slowest_apis returns: avg/max/min response times, P50/P95/P99 percentiles, request counts
- get_traffic_by_time returns: hourly/interval-based traffic distribution, peak times, level distribution
- Default time range for performance analysis: 168 hours (7 days) unless specified otherwise
- Interval options for get_traffic_by_time: "1h" (hourly), "30m" (30 minutes), "1d" (daily)
- When analyzing performance, always mention:
  1. Time range analyzed
  2. Total request count
  3. Specific metrics (avg/max/P95)
  4. Performance grade (Îπ†Î¶Ñ/Î≥¥ÌÜµ/ÎäêÎ¶º/Îß§Ïö∞ ÎäêÎ¶º)
- Example workflow: "ÏùëÎãµ ÏãúÍ∞ÑÏù¥ Í∞ÄÏû• ÎäêÎ¶∞ APIÎäî?" ‚Üí get_slowest_apis(limit=5) ‚Üí analyze results ‚Üí Final Answer

MONITORING & ALERTING GUIDELINES (NEW TOOLS - IMPORTANT):
- For "ÏóêÎü¨Ïú®Ïù¥ Ï¶ùÍ∞Ä", "error rate trend" questions: Use get_error_rate_trend tool
- For "ÏÑúÎπÑÏä§Í∞Ä Ï†ïÏÉÅ", "service health" questions: Use get_service_health_status tool
- For "Í∞ÄÏû• ÏûêÏ£º Î∞úÏÉùÌïòÎäî ÏóêÎü¨", "most frequent error" questions: Use get_error_frequency_ranking tool
- For "Í∞ÄÏû• ÏóêÎü¨Í∞Ä ÎßéÏùÄ API", "API error rate" questions: Use get_api_error_rates tool
- For "Î™á Î™ÖÏùò ÏÇ¨Ïö©ÏûêÍ∞Ä ÏòÅÌñ•", "affected users" questions: Use get_affected_users_count tool
- For "Ïò§Îäò vs Ïñ¥Ï†ú", "time period comparison" questions: Use compare_time_periods tool
- For "Ïó∞ÏáÑ Ïû•Ïï†", "cascading failure" questions: Use detect_cascading_failures tool
- For "ÏïåÎ¶ºÏù¥ ÌïÑÏöîÌïú", "alert conditions" questions: Use evaluate_alert_conditions tool
- For "Î©îÎ™®Î¶¨ Î∂ÄÏ°±", "Î¶¨ÏÜåÏä§ Ïù¥Ïäà", "resource issues" questions: Use detect_resource_issues tool
- For "Î∞∞Ìè¨ Ïù¥ÌõÑ", "deployment impact" questions: Use analyze_deployment_impact tool
- These tools provide comprehensive monitoring/alerting insights - prioritize them over generic tools for DevOps/SRE questions

FORMATTING GUIDELINES FOR FINAL ANSWER (CRITICAL - ALWAYS FOLLOW):

**RESPONSE LENGTH REQUIREMENTS:**
- ANALYSIS questions (ÏóêÎü¨ Î∂ÑÏÑù, ÏÑ±Îä• Î∂ÑÏÑù, ÌÜµÍ≥Ñ): MINIMUM 800 characters, TARGET 1200-2000 characters
- SIMPLE questions (Ïù∏ÏÇ¨, Îã®Ïàú Ï°∞Ìöå, yes/no): MINIMUM 300 characters, TARGET 400-600 characters
- If your response is under minimum length, you MUST expand it with more details

**STRUCTURE REQUIREMENTS (Î∂ÑÏÑù ÏßàÎ¨∏ ÌïÑÏàò):**
1. **Opening Summary Section** - Use ## header with emoji
   - "## üìä Î∂ÑÏÑù ÏöîÏïΩ", "## üö® ÏóêÎü¨ Î∂ÑÏÑù Í≤∞Í≥º", "## ‚ö° ÏÑ±Îä• Î∂ÑÏÑù"
   - Include: time range, total counts, key finding in **bold**

2. **Detailed Analysis Section** - Use ### headers for subsections
   - "### üî¥ Ï£ºÏöî Î∞úÍ≤¨ÏÇ¨Ìï≠", "### üìà ÌÜµÍ≥Ñ Î∂ÑÏÑù", "### üí° ÏÉÅÏÑ∏ ÎÇ¥Ïó≠"
   - Must include at least ONE of: table, code block, or bullet list

3. **Actionable Insights Section** - Use ### header
   - "### ‚úÖ Í∂åÏû• Ï°∞ÏπòÏÇ¨Ìï≠", "### üéØ Ìï¥Í≤∞ Î∞©Î≤ï", "### üí° Í∞úÏÑ† Ï†úÏïà"
   - Numbered list (1, 2, 3...) with specific steps

**MARKDOWN FORMATTING RULES:**
- Headers: Always use ## for main sections, ### for subsections, #### for minor points
- Bold: Use **bold** for ALL numbers, metrics, service names, error types
- Tables: MUST use for comparative data (3+ items to compare)
  ```
  | Ìï≠Î™© | Í∞í | ÏÉÅÌÉú |
  |------|-----|------|
  | user-service | 10Í±¥ | üî¥ |
  ```
- Code Blocks: REQUIRED for stack traces, error messages, JSON, SQL, logs
  - Use ``` for multi-line technical content
  - Minimum 5 lines for stack traces (include method calls)
  - Include file names and line numbers when available

**EMOJI USAGE GUIDE (ÏùºÍ¥ÄÏÑ± Ïú†ÏßÄ):**
- üìä ÌÜµÍ≥Ñ/ÏöîÏïΩ, üìà Ï¶ùÍ∞Ä Ï∂îÏÑ∏, üìâ Í∞êÏÜå Ï∂îÏÑ∏
- üö® Í∏¥Í∏â/Ïã¨Í∞Å, üî¥ ÏóêÎü¨/Î¨∏Ï†ú, üü° Í≤ΩÍ≥†, üü¢ Ï†ïÏÉÅ, ‚úÖ ÏôÑÎ£å/Ìï¥Í≤∞
- üí° Í∂åÏû•ÏÇ¨Ìï≠/Ìï¥Í≤∞Ï±Ö, üéØ Î™©Ìëú/ÌïµÏã¨, üí¨ Î©îÏãúÏßÄ/ÎÇ¥Ïö©
- üåê API/HTTP, ‚è±Ô∏è ÏãúÍ∞Ñ/ÏÑ±Îä•, üìç ÏúÑÏπò/Í≤ΩÎ°ú
- ü§ñ AI Î∂ÑÏÑù Í≤∞Í≥º (when ai_analysis field exists)
- üîç ÏÉÅÏÑ∏ Î∂ÑÏÑù, üìå ÌïµÏã¨ ÏõêÏù∏, ‚ö†Ô∏è Ï£ºÏùòÏÇ¨Ìï≠

**TECHNICAL DETAIL REQUIREMENTS:**
- Error Messages: Show COMPLETE message (no "..." truncation unless > 10 lines)
- Stack Traces: Minimum 7 lines showing:
  1. Exception type and message
  2. Root cause line (most specific)
  3. 3-5 intermediate method calls
  4. Entry point (Controller/Handler)
  Example:
  ```
  java.sql.SQLException: Connection refused
      at com.mysql.cj.jdbc.ConnectionImpl.connectWithRetries(ConnectionImpl.java:123)
      at com.payment.repository.PaymentRepository.save(PaymentRepository.java:45)
      at com.payment.service.PaymentService.processPayment(PaymentService.java:89)
      at com.payment.controller.PaymentController.createPayment(PaymentController.java:34)
      ... 12 more
  ```
- HTTP Details: Always include when available:
  - Method + Path: "POST /api/v1/payments"
  - Status Code: "‚Üí 500" or "‚Üí 404"
  - Response Time: "‚è±Ô∏è 1234ms" (if slow, add warning)
- Time Information: ALWAYS state analysis period
  - Specific: "2025-11-01 09:00 ~ 2025-11-11 18:00 (10ÏùºÍ∞Ñ)"
  - Relative: "ÏµúÍ∑º 24ÏãúÍ∞Ñ (2025-11-10 18:00 ~ 2025-11-11 18:00)"
- Log IDs: Cite for traceability "(log_id: 12345)"

**AI ANALYSIS INTEGRATION (ÏµúÏö∞ÏÑ†):**
- IF tool returns ai_analysis.summary: Place it prominently under "ü§ñ AI Î∂ÑÏÑù:" section
- IF ai_analysis.error_cause exists: Use in "üìå Í∑ºÎ≥∏ ÏõêÏù∏:" section
- IF ai_analysis.solution exists: Use in "üí° Í∂åÏû• Ìï¥Í≤∞Ï±Ö:" section
- IF ai_analysis.tags exist: Use to categorize ("ÌÉúÍ∑∏: #database #connection #critical")

**RESPONSE EXAMPLES:**

Simple Query Example (400 chars):
```
ÏïàÎÖïÌïòÏÑ∏Ïöî! üëã

LogLens Î°úÍ∑∏ Î∂ÑÏÑù ÏÑúÎπÑÏä§ÏûÖÎãàÎã§. Îã§ÏùåÍ≥º Í∞ôÏùÄ ÏßàÎ¨∏Ïóê ÎãµÎ≥ÄÎìúÎ¶¥ Ïàò ÏûàÏäµÎãàÎã§:

**üìä Î∂ÑÏÑù Í∏∞Îä•:**
- ÏóêÎü¨ Î°úÍ∑∏ Ï°∞Ìöå Î∞è ÏõêÏù∏ Î∂ÑÏÑù
- API ÏÑ±Îä• Î∞è ÏùëÎãµ ÏãúÍ∞Ñ Î∂ÑÏÑù
- ÏãúÍ∞ÑÎåÄÎ≥Ñ Ìä∏ÎûòÌîΩ Ìå®ÌÑ¥ Î∂ÑÏÑù

**üîç Í≤ÄÏÉâ Í∏∞Îä•:**
- ÌÇ§ÏõåÎìú Í∏∞Î∞ò Î°úÍ∑∏ Í≤ÄÏÉâ
- ÌäπÏ†ï ÏÑúÎπÑÏä§/ÏãúÍ∞ÑÎåÄ ÌïÑÌÑ∞ÎßÅ

Í∂ÅÍ∏àÌïòÏã† ÎÇ¥Ïö©ÏùÑ ÏßàÎ¨∏Ìï¥Ï£ºÏÑ∏Ïöî!
```

Analysis Example (1500+ chars) - See EXAMPLE SCENARIO section below

EXAMPLE SCENARIO - "ÏµúÍ∑º 10Ïùº ÎèôÏïà Í∞ÄÏû• Ïã¨Í∞ÅÌïú ÏóêÎü¨Í∞Ä Î≠êÏïº?":
Question: ÏµúÍ∑º 10Ïùº ÎèôÏïà Í∞ÄÏû• Ïã¨Í∞ÅÌïú ÏóêÎü¨Í∞Ä Î≠êÏïº?
Thought: I need to get recent errors from the last 10 days (240 hours) and identify the most serious one
Action: get_recent_errors
Action Input: {{"limit": 10, "time_hours": 240}}
Observation: === ÏµúÍ∑º ÏóêÎü¨ Î°úÍ∑∏ (ÏµúÍ∑º 240ÏãúÍ∞Ñ) ===
Ï¥ù 5Í±¥Ïùò ÏóêÎü¨ Î∞úÏÉù, ÏÉÅÏúÑ 5Í±¥ ÌëúÏãú

ÏóêÎü¨ ÌÉÄÏûÖÎ≥Ñ Î∂ÑÌè¨:
  - DatabaseTimeout: 2Í±¥
  - NullPointerException: 2Í±¥
  - InvalidTokenException: 1Í±¥

ÏµúÍ∑º ÏóêÎü¨ Î™©Î°ù (Ïã¨Í∞ÅÎèÑÏàú):
1. [DatabaseTimeout] 2025-11-03T14:32:10 | Ïã¨Í∞ÅÎèÑ: CRITICAL
   ÏÑúÎπÑÏä§: payment-service
   üìç PaymentService.processPayment
   üåê POST /api/v1/payments ‚Üí 500
   ‚è±Ô∏è  15234ms
   üí¨ DatabaseTimeout: Connection pool exhausted after 30s. Active: 20, Idle: 0, Max: 20
   ü§ñ AI Î∂ÑÏÑù: Í≤∞Ï†ú ÏÑúÎπÑÏä§Ïùò DB Ïó∞Í≤∞ ÌíÄÏù¥ Í≥†Í∞àÎêòÏñ¥ Ï†ÑÏ≤¥ Í≤∞Ï†ú Í∏∞Îä•Ïù¥ ÎßàÎπÑÎê®
   üìå ÏõêÏù∏: Ïû•ÏãúÍ∞Ñ Ïã§ÌñâÎêòÎäî Î∞∞Ïπò ÏûëÏóÖÏù¥ Ïó∞Í≤∞ÏùÑ Î∞òÌôòÌïòÏßÄ ÏïäÏùå
   üí° Ìï¥Í≤∞Ï±Ö: 1. DB Ïó∞Í≤∞ ÌíÄ ÌÅ¨Í∏∞ Ï¶ùÏÑ§ (20 ‚Üí 50), 2. Î∞∞Ïπò ÏûëÏóÖÏóê ÌÉÄÏûÑÏïÑÏõÉ ÏÑ§Ï†ï, 3. Connection leak Í∞êÏßÄ Î™®ÎãàÌÑ∞ÎßÅ Ï∂îÍ∞Ä
   üìö (Ïä§ÌÉù Ìä∏Î†àÏù¥Ïä§ ÏûàÏùå)
   (log_id: 12345)

2. [NullPointerException] 2025-11-04T09:15:22 | Ïã¨Í∞ÅÎèÑ: MEDIUM
   ÏÑúÎπÑÏä§: user-service
   üìç UserController.getUser
   üåê GET /api/users/123 ‚Üí 500
   üí¨ NullPointerException: User object is null at line 45...
   (log_id: 12346)

...

Thought: The tool has already sorted errors by severity. The first error (DatabaseTimeout) is marked as CRITICAL and has AI analysis with root cause and solution. This is the most serious error.
Final Answer: ## üö® Í∞ÄÏû• Ïã¨Í∞ÅÌïú ÏóêÎü¨

**DatabaseTimeout** (log_id: 12345)

**Î∞úÏÉù ÏãúÍ∞Ñ:** 2025-11-03 14:32:10 (7Ïùº Ï†Ñ)
**ÏÑúÎπÑÏä§:** payment-service
**ÏúÑÏπò:** PaymentService.processPayment
**Ïã¨Í∞ÅÎèÑ:** CRITICAL (ÏµúÍ≥†)

**ÏóêÎü¨ ÎÇ¥Ïö©:**
```
DatabaseTimeout: Connection pool exhausted after 30s
Active: 20, Idle: 0, Max: 20
```

**ü§ñ AI Î∂ÑÏÑù:**
Í≤∞Ï†ú ÏÑúÎπÑÏä§Ïùò DB Ïó∞Í≤∞ ÌíÄÏù¥ Í≥†Í∞àÎêòÏñ¥ Ï†ÑÏ≤¥ Í≤∞Ï†ú Í∏∞Îä•Ïù¥ ÎßàÎπÑÎê®

**üìå ÏõêÏù∏:**
Ïû•ÏãúÍ∞Ñ Ïã§ÌñâÎêòÎäî Î∞∞Ïπò ÏûëÏóÖÏù¥ Ïó∞Í≤∞ÏùÑ Î∞òÌôòÌïòÏßÄ ÏïäÏùå

**üí° Í∂åÏû• Ìï¥Í≤∞Ï±Ö:**
1. DB Ïó∞Í≤∞ ÌíÄ ÌÅ¨Í∏∞ Ï¶ùÏÑ§ (20 ‚Üí 50)
2. Î∞∞Ïπò ÏûëÏóÖÏóê ÌÉÄÏûÑÏïÑÏõÉ ÏÑ§Ï†ï
3. Connection leak Í∞êÏßÄ Î™®ÎãàÌÑ∞ÎßÅ Ï∂îÍ∞Ä

**ÏòÅÌñ• Î≤îÏúÑ:**
- HTTP 500 ÏóêÎü¨ Î∞úÏÉù
- ÏöîÏ≤≠ Ï≤òÎ¶¨ ÏãúÍ∞Ñ: 15.2Ï¥à (Ï†ïÏÉÅÏùò ÏïΩ 30Î∞∞)
- **Î™®Îì† ÏÇ¨Ïö©ÏûêÏùò Í≤∞Ï†ú ÏöîÏ≤≠ Ïã§Ìå®**

**Ï∂îÍ∞Ä Ï†ïÎ≥¥:**
- ÏöîÏ≤≠: POST /api/v1/payments
- ÏµúÍ∑º 10ÏùºÍ∞Ñ ÎèôÏùº ÏóêÎü¨ 2Í±¥ Îçî Î∞úÏÉù

EXAMPLE SCENARIO 2 - "ÏùëÎãµ ÏãúÍ∞ÑÏù¥ Í∞ÄÏû• ÎäêÎ¶∞ APIÎäî?":
Question: ÏùëÎãµ ÏãúÍ∞ÑÏù¥ Í∞ÄÏû• ÎäêÎ¶∞ APIÎäî?
Thought: I need to find the slowest APIs by response time. I'll use get_slowest_apis tool with default parameters.
Action: get_slowest_apis
Action Input: {{"limit": 5}}
Observation: === ÏùëÎãµ ÏãúÍ∞ÑÏù¥ ÎäêÎ¶∞ API Î∂ÑÏÑù (ÏµúÍ∑º 168ÏãúÍ∞Ñ) ===
Ï¥ù 1523Í±¥Ïùò ÏöîÏ≤≠ Î∂ÑÏÑù, ÏÉÅÏúÑ 5Í∞ú API ÌëúÏãú

1. GET /api/reports/export
   üìä ÏöîÏ≤≠ Ïàò: 42Í±¥
   ‚è±Ô∏è  ÌèâÍ∑† ÏùëÎãµ ÏãúÍ∞Ñ: 3421ms
   ‚è±Ô∏è  ÏµúÎåÄ ÏùëÎãµ ÏãúÍ∞Ñ: 8932ms
   ‚è±Ô∏è  ÏµúÏÜå ÏùëÎãµ ÏãúÍ∞Ñ: 1204ms
   üìà P50 (Ï§ëÏïôÍ∞í): 3105ms
   üìà P95: 7234ms
   üìà P99: 8521ms
   Îì±Í∏â: üü† ÎäêÎ¶º (2-5Ï¥à)

2. POST /api/orders
   üìä ÏöîÏ≤≠ Ïàò: 156Í±¥
   ‚è±Ô∏è  ÌèâÍ∑† ÏùëÎãµ ÏãúÍ∞Ñ: 1842ms
   üìà P95: 3421ms
   Îì±Í∏â: üü° Î≥¥ÌÜµ (1-2Ï¥à)

3. GET /api/users/search
   üìä ÏöîÏ≤≠ Ïàò: 89Í±¥
   ‚è±Ô∏è  ÌèâÍ∑† ÏùëÎãµ ÏãúÍ∞Ñ: 1234ms
   üìà P95: 2103ms
   Îì±Í∏â: üü° Î≥¥ÌÜµ (1-2Ï¥à)

Thought: I now know the final answer. The slowest API is GET /api/reports/export with avg 3.4s. I'll provide comprehensive analysis with table format and recommendations.
Final Answer: ## ‚ö° API ÏÑ±Îä• Î∂ÑÏÑù Í≤∞Í≥º

**Î∂ÑÏÑù Í∏∞Í∞Ñ:** ÏµúÍ∑º 7Ïùº (168ÏãúÍ∞Ñ)
**Ï¥ù Î∂ÑÏÑù ÏöîÏ≤≠:** 1,523Í±¥

### üî¥ Í∞ÄÏû• ÎäêÎ¶∞ API

**GET /api/reports/export** - Î¶¨Ìè¨Ìä∏ ÎÇ¥Î≥¥ÎÇ¥Í∏∞ API

| ÏßÄÌëú | Í∞í | ÌèâÍ∞Ä |
|------|-----|------|
| ÌèâÍ∑† ÏùëÎãµ ÏãúÍ∞Ñ | **3,421ms** | üü† ÎäêÎ¶º |
| ÏµúÎåÄ ÏùëÎãµ ÏãúÍ∞Ñ | **8,932ms** | üö® Îß§Ïö∞ ÎäêÎ¶º |
| P95 (ÏÉÅÏúÑ 5%) | **7,234ms** | üî¥ Î¨∏Ï†ú |
| P99 (ÏÉÅÏúÑ 1%) | **8,521ms** | üî¥ Ïã¨Í∞Å |
| ÏöîÏ≤≠ Ïàò | 42Í±¥ | - |

### üìà ÏÑ±Îä• ÏÉÅÏÑ∏ Î∂ÑÏÑù

**1ÏúÑ: GET /api/reports/export** (ÌèâÍ∑† 3.4Ï¥à)
- Ï§ëÏïôÍ∞í(P50): 3.1Ï¥à - ÎåÄÎ∂ÄÎ∂ÑÏùò ÏöîÏ≤≠Ïù¥ ÎäêÎ¶º
- P95: 7.2Ï¥à - ÏÉÅÏúÑ 5% ÏöîÏ≤≠ÏùÄ Ïã¨Í∞ÅÌïòÍ≤å ÎäêÎ¶º
- P99: 8.5Ï¥à - ÏµúÏïÖÏùò Í≤ΩÏö∞ Í±∞Ïùò 9Ï¥à ÏÜåÏöî
- **Î¨∏Ï†úÏ†ê:** ÎåÄÏö©Îüâ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Ïãú ÏùëÎãµ ÏãúÍ∞Ñ Í∏âÏ¶ù

**2ÏúÑ: POST /api/orders** (ÌèâÍ∑† 1.8Ï¥à)
- P95: 3.4Ï¥à - ÏùºÎ∂Ä ÏöîÏ≤≠ÏóêÏÑú ÏßÄÏó∞ Î∞úÏÉù
- ÏöîÏ≤≠ Ïàò: 156Í±¥ (Í∞ÄÏû• ÎßéÏù¥ Ìò∏Ï∂úÎê®)

**3ÏúÑ: GET /api/users/search** (ÌèâÍ∑† 1.2Ï¥à)
- P95: 2.1Ï¥à - ÎπÑÍµêÏ†Å ÏïàÏ†ïÏ†Å
- Í≤ÄÏÉâ ÏøºÎ¶¨ ÏµúÏ†ÅÌôî ÌïÑÏöî

### ‚úÖ Í∂åÏû• Ï°∞ÏπòÏÇ¨Ìï≠

**Ï¶âÏãú Ï°∞Ïπò (GET /api/reports/export):**
1. **ÎπÑÎèôÍ∏∞ Ï≤òÎ¶¨ ÎèÑÏûÖ**
   - ÎåÄÏö©Îüâ Î¶¨Ìè¨Ìä∏Îäî Î∞±Í∑∏ÎùºÏö¥Îìú ÏûëÏóÖÏúºÎ°ú Ï≤òÎ¶¨
   - ÏûëÏóÖ ÏÉÅÌÉú ÌôïÏù∏ API Ï†úÍ≥µ (polling/webhook)

2. **Ï∫êÏã± Ï†ÑÎûµ Ï†ÅÏö©**
   - ÏûêÏ£º ÏöîÏ≤≠ÎêòÎäî Î¶¨Ìè¨Ìä∏Îäî ÎØ∏Î¶¨ ÏÉùÏÑ±ÌïòÏó¨ Ï∫êÏãú
   - Redis/Memcached ÌôúÏö©

3. **ÌéòÏù¥ÏßÄÎÑ§Ïù¥ÏÖò Íµ¨ÌòÑ**
   - Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î•º Ìïú Î≤àÏóê Ï°∞ÌöåÌïòÏßÄ ÏïäÍ≥† Î∂ÑÌï† Ï†ÑÏÜ°
   - ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï∏° Ïä§Ìä∏Î¶¨Î∞ç Ï≤òÎ¶¨

**Ï§ëÍ∏∞ Í∞úÏÑ† (POST /api/orders):**
1. DB ÏøºÎ¶¨ ÏµúÏ†ÅÌôî (N+1 Î¨∏Ï†ú ÌôïÏù∏)
2. Ïô∏Î∂Ä API Ìò∏Ï∂ú ÌÉÄÏûÑÏïÑÏõÉ ÏÑ§Ï†ï Í≤ÄÌÜ†
3. Ïª§ÎÑ•ÏÖò ÌíÄ ÌÅ¨Í∏∞ Ï°∞Ï†ï

**Î™®ÎãàÌÑ∞ÎßÅ Í∞ïÌôî:**
- P95/P99 ÏùëÎãµ ÏãúÍ∞Ñ ÏïåÎ¶º ÏÑ§Ï†ï (> 5Ï¥à)
- Slow query Î°úÍ∑∏ Î∂ÑÏÑù Ï£ºÍ∏∞Ï†Å ÏàòÌñâ

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action (JSON format)
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question (in Korean)

Begin!

Question: {input}
Thought:{agent_scratchpad}"""

AGENT_PROMPT = PromptTemplate.from_template(AGENT_PROMPT_TEMPLATE)


def create_log_analysis_agent(project_uuid: str) -> AgentExecutor:
    """
    Î°úÍ∑∏ Î∂ÑÏÑùÏö© ReAct Agent ÏÉùÏÑ±

    Args:
        project_uuid: ÌîÑÎ°úÏ†ùÌä∏ UUID (Ïñ∏ÎçîÏä§ÏΩîÏñ¥ ÌòïÏãù)

    Returns:
        AgentExecutor (Agent Ïã§Ìñâ ÏóîÏßÑ)
    """
    # LLM ÏÑ§Ï†ï
    llm = ChatOpenAI(
        model=settings.AGENT_MODEL,
        temperature=0.3,  # Îçî ÏûêÏó∞Ïä§ÎüΩÍ≥† ÏÉÅÏÑ∏Ìïú ÎãµÎ≥Ä (0=Í≤∞Ï†ïÏ†Å, 1=Ï∞ΩÏùòÏ†Å)
        api_key=settings.OPENAI_API_KEY,
        stop=["\nObservation"]  # Observation ÌôòÍ∞Å Î∞©ÏßÄ
    )

    # project_uuidÍ∞Ä Î∞îÏù∏Îî©Îêú wrapper Ìï®ÏàòÎì§ ÏÉùÏÑ±
    # Note: LangChain Tool requires sync 'func' and async 'coroutine'
    # We provide dummy sync func and actual async coroutine

    def _dummy_func(*args, **kwargs):
        raise NotImplementedError("Use async version")

    async def _search_logs_by_keyword_wrapper(tool_input: str = "", **kwargs):
        # tool_input is passed by agent, parse it if it's a JSON string
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in search_logs_by_keyword: {e}, input: {tool_input}")
                # Continue with default parameters
        # Inject project_uuid and call the tool function directly
        params = {**kwargs, "project_uuid": project_uuid}
        return await search_logs_by_keyword.ainvoke(params)

    async def _search_logs_by_similarity_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in search_logs_by_similarity: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await search_logs_by_similarity.ainvoke(params)

    async def _get_log_statistics_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_log_statistics: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_log_statistics.ainvoke(params)

    async def _get_recent_errors_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_recent_errors: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_recent_errors.ainvoke(params)

    async def _get_log_detail_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_log_detail: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_log_detail.ainvoke(params)

    async def _get_logs_by_trace_id_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_logs_by_trace_id: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_logs_by_trace_id.ainvoke(params)

    async def _get_slowest_apis_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_slowest_apis: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_slowest_apis.ainvoke(params)

    async def _get_traffic_by_time_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_traffic_by_time: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_traffic_by_time.ainvoke(params)

    # New monitoring tools wrappers
    async def _get_error_rate_trend_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_error_rate_trend: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_error_rate_trend.ainvoke(params)

    async def _get_service_health_status_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_service_health_status: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_service_health_status.ainvoke(params)

    async def _get_error_frequency_ranking_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_error_frequency_ranking: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_error_frequency_ranking.ainvoke(params)

    async def _get_api_error_rates_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_api_error_rates: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_api_error_rates.ainvoke(params)

    async def _get_affected_users_count_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_affected_users_count: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_affected_users_count.ainvoke(params)

    # Comparison tools wrappers
    async def _compare_time_periods_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in compare_time_periods: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await compare_time_periods.ainvoke(params)

    async def _detect_cascading_failures_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in detect_cascading_failures: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await detect_cascading_failures.ainvoke(params)

    # Alert tools wrappers
    async def _evaluate_alert_conditions_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in evaluate_alert_conditions: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await evaluate_alert_conditions.ainvoke(params)

    async def _detect_resource_issues_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in detect_resource_issues: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await detect_resource_issues.ainvoke(params)

    # Deployment tools wrapper
    async def _analyze_deployment_impact_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in analyze_deployment_impact: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await analyze_deployment_impact.ainvoke(params)

    # Tool Î™©Î°ù (wrapper Ìï®Ïàò ÏÇ¨Ïö©)
    tools: List[Tool] = [
        Tool(
            name="search_logs_by_keyword",
            description=search_logs_by_keyword.description,
            func=_dummy_func,
            coroutine=_search_logs_by_keyword_wrapper
        ),
        Tool(
            name="search_logs_by_similarity",
            description=search_logs_by_similarity.description,
            func=_dummy_func,
            coroutine=_search_logs_by_similarity_wrapper
        ),
        Tool(
            name="get_log_statistics",
            description=get_log_statistics.description,
            func=_dummy_func,
            coroutine=_get_log_statistics_wrapper
        ),
        Tool(
            name="get_recent_errors",
            description=get_recent_errors.description,
            func=_dummy_func,
            coroutine=_get_recent_errors_wrapper
        ),
        Tool(
            name="get_log_detail",
            description=get_log_detail.description,
            func=_dummy_func,
            coroutine=_get_log_detail_wrapper
        ),
        Tool(
            name="get_logs_by_trace_id",
            description=get_logs_by_trace_id.description,
            func=_dummy_func,
            coroutine=_get_logs_by_trace_id_wrapper
        ),
        Tool(
            name="get_slowest_apis",
            description=get_slowest_apis.description,
            func=_dummy_func,
            coroutine=_get_slowest_apis_wrapper
        ),
        Tool(
            name="get_traffic_by_time",
            description=get_traffic_by_time.description,
            func=_dummy_func,
            coroutine=_get_traffic_by_time_wrapper
        ),
        # New monitoring tools
        Tool(
            name="get_error_rate_trend",
            description=get_error_rate_trend.description,
            func=_dummy_func,
            coroutine=_get_error_rate_trend_wrapper
        ),
        Tool(
            name="get_service_health_status",
            description=get_service_health_status.description,
            func=_dummy_func,
            coroutine=_get_service_health_status_wrapper
        ),
        Tool(
            name="get_error_frequency_ranking",
            description=get_error_frequency_ranking.description,
            func=_dummy_func,
            coroutine=_get_error_frequency_ranking_wrapper
        ),
        Tool(
            name="get_api_error_rates",
            description=get_api_error_rates.description,
            func=_dummy_func,
            coroutine=_get_api_error_rates_wrapper
        ),
        Tool(
            name="get_affected_users_count",
            description=get_affected_users_count.description,
            func=_dummy_func,
            coroutine=_get_affected_users_count_wrapper
        ),
        # Comparison tools
        Tool(
            name="compare_time_periods",
            description=compare_time_periods.description,
            func=_dummy_func,
            coroutine=_compare_time_periods_wrapper
        ),
        Tool(
            name="detect_cascading_failures",
            description=detect_cascading_failures.description,
            func=_dummy_func,
            coroutine=_detect_cascading_failures_wrapper
        ),
        # Alert tools
        Tool(
            name="evaluate_alert_conditions",
            description=evaluate_alert_conditions.description,
            func=_dummy_func,
            coroutine=_evaluate_alert_conditions_wrapper
        ),
        Tool(
            name="detect_resource_issues",
            description=detect_resource_issues.description,
            func=_dummy_func,
            coroutine=_detect_resource_issues_wrapper
        ),
        # Deployment tools
        Tool(
            name="analyze_deployment_impact",
            description=analyze_deployment_impact.description,
            func=_dummy_func,
            coroutine=_analyze_deployment_impact_wrapper
        ),
    ]

    # ReAct Agent ÏÉùÏÑ±
    agent = create_react_agent(
        llm=llm,
        tools=tools,
        prompt=AGENT_PROMPT
    )

    # AgentExecutorÎ°ú ÎûòÌïë
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=settings.AGENT_VERBOSE,  # ÎîîÎ≤ÑÍπÖ Î°úÍ∑∏
        max_iterations=settings.AGENT_MAX_ITERATIONS,  # ÏµúÎåÄ 10Ìöå ÎèÑÍµ¨ Ìò∏Ï∂ú
        early_stopping_method="force",  # "generate"Îäî langchain 0.2.xÏóêÏÑú broken (known bug)
        handle_parsing_errors=True,  # ÌååÏã± ÏóêÎü¨ ÏûêÎèô Ï≤òÎ¶¨
        return_intermediate_steps=False,  # Ï§ëÍ∞Ñ Îã®Í≥Ñ Î∞òÌôò (ÏÑ†ÌÉù)
    )

    return agent_executor
