"""
ReAct Agent for Log Analysis

LLMÏù¥ ÏûêÏú®Ï†ÅÏúºÎ°ú ÎèÑÍµ¨Î•º ÏÑ†ÌÉùÌïòÏó¨ Î°úÍ∑∏ Î∂ÑÏÑù ÏàòÌñâ
"""

from typing import List

from langchain.agents import create_react_agent, AgentExecutor
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.tools import Tool

from app.tools.search_tools import search_logs_by_keyword, search_logs_by_similarity
from app.tools.analysis_tools import get_log_statistics, get_recent_errors
from app.tools.detail_tools import get_log_detail, get_logs_by_trace_id
from app.tools.performance_tools import get_slowest_apis, get_traffic_by_time
from app.tools.monitoring_tools import (
    get_error_rate_trend,
    get_service_health_status,
    get_error_frequency_ranking,
    get_api_error_rates,
    get_affected_users_count
)
from app.tools.comparison_tools import compare_time_periods, detect_cascading_failures
from app.tools.alert_tools import evaluate_alert_conditions, detect_resource_issues
from app.tools.deployment_tools import analyze_deployment_impact
from app.core.config import settings


# ReAct Agent System Prompt (ÌïúÍµ≠Ïñ¥) - LangChain ÌëúÏ§Ä ÌòïÏãù
AGENT_PROMPT_TEMPLATE = """Answer the following questions as best you can. You have access to the following tools:

{tools}

CRITICAL RULES FOR "NO DATA FOUND" RESPONSES:
- If a tool returns "Î°úÍ∑∏Í∞Ä ÏóÜÏäµÎãàÎã§" or "ERROR Î†àÎ≤® Î°úÍ∑∏Í∞Ä ÏóÜÏäµÎãàÎã§" or "Í≤ÄÏÉâ Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§", this is a VALID FINAL RESULT
- DO NOT retry with different parameters
- DO NOT try other tools
- IMMEDIATELY write: "Thought: I now know the final answer" followed by "Final Answer: [explain no logs found]"
- Example response format when no data found:
  Thought: I now know the final answer
  Final Answer: ÏµúÍ∑º 24ÏãúÍ∞Ñ ÎèôÏïà ERROR Î°úÍ∑∏Í∞Ä Î∞úÏÉùÌïòÏßÄ ÏïäÏïòÏäµÎãàÎã§. ÏãúÏä§ÌÖúÏù¥ Ï†ïÏÉÅ ÏûëÎèô Ï§ëÏûÖÎãàÎã§.

SEVERITY ASSESSMENT GUIDELINES (for "Í∞ÄÏû• Ïã¨Í∞ÅÌïú", "most serious" questions):
- CRITICAL (Ï¶âÏãú Ï°∞Ïπò): Database/Connection errors, OutOfMemory, StackOverflow, Deadlock, 5xx errors (affects all users)
- HIGH (Í∏¥Í∏â Ï°∞Ïπò): Authentication/Security errors, InvalidToken, AuthFailure, UnauthorizedAccess (security risk)
- MEDIUM (Ïö∞ÏÑ† Ï°∞Ïπò): NullPointerException, IllegalStateException, RuntimeException (specific feature broken)
- LOW (Î™®ÎãàÌÑ∞ÎßÅ): 4xx errors, validation errors, slow queries (client-side or performance issues only)
- When asked "Í∞ÄÏû• Ïã¨Í∞ÅÌïú ÏóêÎü¨", "most critical error": Call get_recent_errors ONCE, analyze results, provide Final Answer
- DO NOT call get_recent_errors multiple times with different service_name filters unless specifically requested
- The tool returns errors sorted by severity automatically - trust the order

EFFICIENCY RULES TO PREVENT ITERATION LOOPS:
- For "most X" questions (Í∞ÄÏû• Ïã¨Í∞ÅÌïú, Í∞ÄÏû• ÎßéÏùÄ, most frequent), use ONE broad query first without filters
- Analyze the results and make a decision immediately - DO NOT iterate through all possible combinations
- AVOID calling the same tool multiple times with slightly different parameters
- Example workflow: "Í∞ÄÏû• Ïã¨Í∞ÅÌïú ÏóêÎü¨Í∞Ä Î≠êÏïº?" ‚Üí get_recent_errors(limit=10) ‚Üí analyze types based on severity ‚Üí Final Answer (total: 1-2 tool calls)

AI ANALYSIS FIELD USAGE (IMPORTANT):
- Tools now return ai_analysis fields: summary, error_cause, solution, tags, analysis_type
- **IF ai_analysis.summary EXISTS**: Include it prominently in your Final Answer (it's already analyzed by AI)
- **IF ai_analysis.error_cause EXISTS**: Use it to explain the root cause
- **IF ai_analysis.solution EXISTS**: Include it as recommended action
- **IF ai_analysis.tags EXIST**: Use them to categorize or identify error types
- **IMPORTANT**: ai_analysis fields may be empty for some logs - handle gracefully
- Prioritize AI analysis results over manual analysis when available
- Example: If tool returns "ü§ñ AI Î∂ÑÏÑù: ...", integrate it into your answer

TIME PARSING GUIDELINES:
- "ÏµúÍ∑º NÏùº" or "NÏùº ÎèôÏïà" ‚Üí time_hours = N * 24
- "Ïñ¥Ï†ú" ‚Üí time_hours = 24
- "Ïù¥Î≤à Ï£º" ‚Üí time_hours = 168 (7 days)
- "ÏµúÍ∑º 1ÏãúÍ∞Ñ" or "1ÏãúÍ∞Ñ ÎèôÏïà" ‚Üí time_hours = 1
- "Ïò§Îäò" ‚Üí time_hours = 24
- Always extract time values accurately from user questions

PERFORMANCE ANALYSIS GUIDELINES (IMPORTANT):
- For "ÏùëÎãµ ÏãúÍ∞ÑÏù¥ Í∞ÄÏû• ÎäêÎ¶∞ API", "slowest API" questions: Use get_slowest_apis tool
- For "Ìä∏ÎûòÌîΩÏù¥ Í∞ÄÏû• ÎßéÏùÄ ÏãúÍ∞ÑÎåÄ", "peak traffic time" questions: Use get_traffic_by_time tool
- For "ÌèâÍ∑† ÏùëÎãµ ÏãúÍ∞Ñ", "average response time" questions: Use get_slowest_apis with appropriate limit
- get_slowest_apis returns: avg/max/min response times, P50/P95/P99 percentiles, request counts
- get_traffic_by_time returns: hourly/interval-based traffic distribution, peak times, level distribution
- Default time range for performance analysis: 168 hours (7 days) unless specified otherwise
- Interval options for get_traffic_by_time: "1h" (hourly), "30m" (30 minutes), "1d" (daily)
- When analyzing performance, always mention:
  1. Time range analyzed
  2. Total request count
  3. Specific metrics (avg/max/P95)
  4. Performance grade (Îπ†Î¶Ñ/Î≥¥ÌÜµ/ÎäêÎ¶º/Îß§Ïö∞ ÎäêÎ¶º)
- Example workflow: "ÏùëÎãµ ÏãúÍ∞ÑÏù¥ Í∞ÄÏû• ÎäêÎ¶∞ APIÎäî?" ‚Üí get_slowest_apis(limit=5) ‚Üí analyze results ‚Üí Final Answer

MONITORING & ALERTING GUIDELINES (NEW TOOLS - IMPORTANT):
- For "ÏóêÎü¨Ïú®Ïù¥ Ï¶ùÍ∞Ä", "error rate trend" questions: Use get_error_rate_trend tool
- For "ÏÑúÎπÑÏä§Í∞Ä Ï†ïÏÉÅ", "service health" questions: Use get_service_health_status tool
- For "Í∞ÄÏû• ÏûêÏ£º Î∞úÏÉùÌïòÎäî ÏóêÎü¨", "most frequent error" questions: Use get_error_frequency_ranking tool
- For "Í∞ÄÏû• ÏóêÎü¨Í∞Ä ÎßéÏùÄ API", "API error rate" questions: Use get_api_error_rates tool
- For "Î™á Î™ÖÏùò ÏÇ¨Ïö©ÏûêÍ∞Ä ÏòÅÌñ•", "affected users" questions: Use get_affected_users_count tool
- For "Ïò§Îäò vs Ïñ¥Ï†ú", "time period comparison" questions: Use compare_time_periods tool
- For "Ïó∞ÏáÑ Ïû•Ïï†", "cascading failure" questions: Use detect_cascading_failures tool
- For "ÏïåÎ¶ºÏù¥ ÌïÑÏöîÌïú", "alert conditions" questions: Use evaluate_alert_conditions tool
- For "Î©îÎ™®Î¶¨ Î∂ÄÏ°±", "Î¶¨ÏÜåÏä§ Ïù¥Ïäà", "resource issues" questions: Use detect_resource_issues tool
- For "Î∞∞Ìè¨ Ïù¥ÌõÑ", "deployment impact" questions: Use analyze_deployment_impact tool
- These tools provide comprehensive monitoring/alerting insights - prioritize them over generic tools for DevOps/SRE questions

FORMATTING GUIDELINES FOR FINAL ANSWER:
- For ANALYSIS questions (ÌÜµÍ≥Ñ, Î∂ÑÏÑù, ÏöîÏïΩ): Use structured markdown with ## headers, **bold** numbers, tables
- For SIMPLE questions (Ïù∏ÏÇ¨, Îã®Ïàú Ï°∞Ìöå): Keep it concise and natural
- Always include specific numbers, timestamps, service names when available
- **Include AI analysis results when provided by tools**
- Example structured: "## üìä ÏöîÏïΩ\nÏµúÍ∑º 7ÏùºÍ∞Ñ **4Í±¥**Ïùò ÏóêÎü¨ Î∞úÏÉù\n\n**ü§ñ AI Î∂ÑÏÑù:**\nÍ≤∞Ï†ú ÏÑúÎπÑÏä§ DB Ïó∞Í≤∞ Î¨∏Ï†ú\n\n| ÏÑúÎπÑÏä§ | Í±¥Ïàò |\n|------|------|\n| user-service | 2Í±¥ |"
- Example simple: "ÏïàÎÖïÌïòÏÑ∏Ïöî! Î°úÍ∑∏ Î∂ÑÏÑùÏù¥ ÌïÑÏöîÌïòÏãúÎ©¥ ÏßàÎ¨∏Ìï¥Ï£ºÏÑ∏Ïöî."

DETAIL REQUIREMENTS FOR ANALYSIS RESPONSES:
- Include FULL error messages (do not truncate or summarize)
- Show complete stack traces when analyzing errors (minimum 5-10 lines of context)
- Always state the time range analyzed (e.g., "ÏµúÍ∑º 24ÏãúÍ∞Ñ", "2025-11-01 ~ 2025-11-07")
- Include HTTP details when relevant (method, path, status code)
- Cite specific log_ids so users can reference them (e.g., "log_id: 101")
- Use code blocks (```) for stack traces and technical details
- Target 1000-3000 characters for comprehensive analysis responses

EXAMPLE SCENARIO - "ÏµúÍ∑º 10Ïùº ÎèôÏïà Í∞ÄÏû• Ïã¨Í∞ÅÌïú ÏóêÎü¨Í∞Ä Î≠êÏïº?":
Question: ÏµúÍ∑º 10Ïùº ÎèôÏïà Í∞ÄÏû• Ïã¨Í∞ÅÌïú ÏóêÎü¨Í∞Ä Î≠êÏïº?
Thought: I need to get recent errors from the last 10 days (240 hours) and identify the most serious one
Action: get_recent_errors
Action Input: {{"limit": 10, "time_hours": 240}}
Observation: === ÏµúÍ∑º ÏóêÎü¨ Î°úÍ∑∏ (ÏµúÍ∑º 240ÏãúÍ∞Ñ) ===
Ï¥ù 5Í±¥Ïùò ÏóêÎü¨ Î∞úÏÉù, ÏÉÅÏúÑ 5Í±¥ ÌëúÏãú

ÏóêÎü¨ ÌÉÄÏûÖÎ≥Ñ Î∂ÑÌè¨:
  - DatabaseTimeout: 2Í±¥
  - NullPointerException: 2Í±¥
  - InvalidTokenException: 1Í±¥

ÏµúÍ∑º ÏóêÎü¨ Î™©Î°ù (Ïã¨Í∞ÅÎèÑÏàú):
1. [DatabaseTimeout] 2025-11-03T14:32:10 | Ïã¨Í∞ÅÎèÑ: CRITICAL
   ÏÑúÎπÑÏä§: payment-service
   üìç PaymentService.processPayment
   üåê POST /api/v1/payments ‚Üí 500
   ‚è±Ô∏è  15234ms
   üí¨ DatabaseTimeout: Connection pool exhausted after 30s. Active: 20, Idle: 0, Max: 20
   ü§ñ AI Î∂ÑÏÑù: Í≤∞Ï†ú ÏÑúÎπÑÏä§Ïùò DB Ïó∞Í≤∞ ÌíÄÏù¥ Í≥†Í∞àÎêòÏñ¥ Ï†ÑÏ≤¥ Í≤∞Ï†ú Í∏∞Îä•Ïù¥ ÎßàÎπÑÎê®
   üìå ÏõêÏù∏: Ïû•ÏãúÍ∞Ñ Ïã§ÌñâÎêòÎäî Î∞∞Ïπò ÏûëÏóÖÏù¥ Ïó∞Í≤∞ÏùÑ Î∞òÌôòÌïòÏßÄ ÏïäÏùå
   üí° Ìï¥Í≤∞Ï±Ö: 1. DB Ïó∞Í≤∞ ÌíÄ ÌÅ¨Í∏∞ Ï¶ùÏÑ§ (20 ‚Üí 50), 2. Î∞∞Ïπò ÏûëÏóÖÏóê ÌÉÄÏûÑÏïÑÏõÉ ÏÑ§Ï†ï, 3. Connection leak Í∞êÏßÄ Î™®ÎãàÌÑ∞ÎßÅ Ï∂îÍ∞Ä
   üìö (Ïä§ÌÉù Ìä∏Î†àÏù¥Ïä§ ÏûàÏùå)
   (log_id: 12345)

2. [NullPointerException] 2025-11-04T09:15:22 | Ïã¨Í∞ÅÎèÑ: MEDIUM
   ÏÑúÎπÑÏä§: user-service
   üìç UserController.getUser
   üåê GET /api/users/123 ‚Üí 500
   üí¨ NullPointerException: User object is null at line 45...
   (log_id: 12346)

...

Thought: The tool has already sorted errors by severity. The first error (DatabaseTimeout) is marked as CRITICAL and has AI analysis with root cause and solution. This is the most serious error.
Final Answer: ## üö® Í∞ÄÏû• Ïã¨Í∞ÅÌïú ÏóêÎü¨

**DatabaseTimeout** (log_id: 12345)

**Î∞úÏÉù ÏãúÍ∞Ñ:** 2025-11-03 14:32:10 (7Ïùº Ï†Ñ)
**ÏÑúÎπÑÏä§:** payment-service
**ÏúÑÏπò:** PaymentService.processPayment
**Ïã¨Í∞ÅÎèÑ:** CRITICAL (ÏµúÍ≥†)

**ÏóêÎü¨ ÎÇ¥Ïö©:**
```
DatabaseTimeout: Connection pool exhausted after 30s
Active: 20, Idle: 0, Max: 20
```

**ü§ñ AI Î∂ÑÏÑù:**
Í≤∞Ï†ú ÏÑúÎπÑÏä§Ïùò DB Ïó∞Í≤∞ ÌíÄÏù¥ Í≥†Í∞àÎêòÏñ¥ Ï†ÑÏ≤¥ Í≤∞Ï†ú Í∏∞Îä•Ïù¥ ÎßàÎπÑÎê®

**üìå ÏõêÏù∏:**
Ïû•ÏãúÍ∞Ñ Ïã§ÌñâÎêòÎäî Î∞∞Ïπò ÏûëÏóÖÏù¥ Ïó∞Í≤∞ÏùÑ Î∞òÌôòÌïòÏßÄ ÏïäÏùå

**üí° Í∂åÏû• Ìï¥Í≤∞Ï±Ö:**
1. DB Ïó∞Í≤∞ ÌíÄ ÌÅ¨Í∏∞ Ï¶ùÏÑ§ (20 ‚Üí 50)
2. Î∞∞Ïπò ÏûëÏóÖÏóê ÌÉÄÏûÑÏïÑÏõÉ ÏÑ§Ï†ï
3. Connection leak Í∞êÏßÄ Î™®ÎãàÌÑ∞ÎßÅ Ï∂îÍ∞Ä

**ÏòÅÌñ• Î≤îÏúÑ:**
- HTTP 500 ÏóêÎü¨ Î∞úÏÉù
- ÏöîÏ≤≠ Ï≤òÎ¶¨ ÏãúÍ∞Ñ: 15.2Ï¥à (Ï†ïÏÉÅÏùò ÏïΩ 30Î∞∞)
- **Î™®Îì† ÏÇ¨Ïö©ÏûêÏùò Í≤∞Ï†ú ÏöîÏ≤≠ Ïã§Ìå®**

**Ï∂îÍ∞Ä Ï†ïÎ≥¥:**
- ÏöîÏ≤≠: POST /api/v1/payments
- ÏµúÍ∑º 10ÏùºÍ∞Ñ ÎèôÏùº ÏóêÎü¨ 2Í±¥ Îçî Î∞úÏÉù

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action (JSON format)
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question (in Korean)

Begin!

Question: {input}
Thought:{agent_scratchpad}"""

AGENT_PROMPT = PromptTemplate.from_template(AGENT_PROMPT_TEMPLATE)


def create_log_analysis_agent(project_uuid: str) -> AgentExecutor:
    """
    Î°úÍ∑∏ Î∂ÑÏÑùÏö© ReAct Agent ÏÉùÏÑ±

    Args:
        project_uuid: ÌîÑÎ°úÏ†ùÌä∏ UUID (Ïñ∏ÎçîÏä§ÏΩîÏñ¥ ÌòïÏãù)

    Returns:
        AgentExecutor (Agent Ïã§Ìñâ ÏóîÏßÑ)
    """
    # LLM ÏÑ§Ï†ï
    llm = ChatOpenAI(
        model=settings.AGENT_MODEL,
        temperature=0,  # ÏùºÍ¥ÄÎêú ÎãµÎ≥Ä
        api_key=settings.OPENAI_API_KEY,
        stop=["\nObservation"]  # Observation ÌôòÍ∞Å Î∞©ÏßÄ
    )

    # project_uuidÍ∞Ä Î∞îÏù∏Îî©Îêú wrapper Ìï®ÏàòÎì§ ÏÉùÏÑ±
    # Note: LangChain Tool requires sync 'func' and async 'coroutine'
    # We provide dummy sync func and actual async coroutine

    def _dummy_func(*args, **kwargs):
        raise NotImplementedError("Use async version")

    async def _search_logs_by_keyword_wrapper(tool_input: str = "", **kwargs):
        # tool_input is passed by agent, parse it if it's a JSON string
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in search_logs_by_keyword: {e}, input: {tool_input}")
                # Continue with default parameters
        # Inject project_uuid and call the tool function directly
        params = {**kwargs, "project_uuid": project_uuid}
        return await search_logs_by_keyword.ainvoke(params)

    async def _search_logs_by_similarity_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in search_logs_by_similarity: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await search_logs_by_similarity.ainvoke(params)

    async def _get_log_statistics_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_log_statistics: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_log_statistics.ainvoke(params)

    async def _get_recent_errors_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_recent_errors: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_recent_errors.ainvoke(params)

    async def _get_log_detail_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_log_detail: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_log_detail.ainvoke(params)

    async def _get_logs_by_trace_id_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_logs_by_trace_id: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_logs_by_trace_id.ainvoke(params)

    async def _get_slowest_apis_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_slowest_apis: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_slowest_apis.ainvoke(params)

    async def _get_traffic_by_time_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_traffic_by_time: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_traffic_by_time.ainvoke(params)

    # New monitoring tools wrappers
    async def _get_error_rate_trend_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_error_rate_trend: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_error_rate_trend.ainvoke(params)

    async def _get_service_health_status_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_service_health_status: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_service_health_status.ainvoke(params)

    async def _get_error_frequency_ranking_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_error_frequency_ranking: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_error_frequency_ranking.ainvoke(params)

    async def _get_api_error_rates_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_api_error_rates: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_api_error_rates.ainvoke(params)

    async def _get_affected_users_count_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in get_affected_users_count: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_affected_users_count.ainvoke(params)

    # Comparison tools wrappers
    async def _compare_time_periods_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in compare_time_periods: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await compare_time_periods.ainvoke(params)

    async def _detect_cascading_failures_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in detect_cascading_failures: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await detect_cascading_failures.ainvoke(params)

    # Alert tools wrappers
    async def _evaluate_alert_conditions_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in evaluate_alert_conditions: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await evaluate_alert_conditions.ainvoke(params)

    async def _detect_resource_issues_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in detect_resource_issues: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await detect_resource_issues.ainvoke(params)

    # Deployment tools wrapper
    async def _analyze_deployment_impact_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è JSON parsing error in analyze_deployment_impact: {e}, input: {tool_input}")
        params = {**kwargs, "project_uuid": project_uuid}
        return await analyze_deployment_impact.ainvoke(params)

    # Tool Î™©Î°ù (wrapper Ìï®Ïàò ÏÇ¨Ïö©)
    tools: List[Tool] = [
        Tool(
            name="search_logs_by_keyword",
            description=search_logs_by_keyword.description,
            func=_dummy_func,
            coroutine=_search_logs_by_keyword_wrapper
        ),
        Tool(
            name="search_logs_by_similarity",
            description=search_logs_by_similarity.description,
            func=_dummy_func,
            coroutine=_search_logs_by_similarity_wrapper
        ),
        Tool(
            name="get_log_statistics",
            description=get_log_statistics.description,
            func=_dummy_func,
            coroutine=_get_log_statistics_wrapper
        ),
        Tool(
            name="get_recent_errors",
            description=get_recent_errors.description,
            func=_dummy_func,
            coroutine=_get_recent_errors_wrapper
        ),
        Tool(
            name="get_log_detail",
            description=get_log_detail.description,
            func=_dummy_func,
            coroutine=_get_log_detail_wrapper
        ),
        Tool(
            name="get_logs_by_trace_id",
            description=get_logs_by_trace_id.description,
            func=_dummy_func,
            coroutine=_get_logs_by_trace_id_wrapper
        ),
        Tool(
            name="get_slowest_apis",
            description=get_slowest_apis.description,
            func=_dummy_func,
            coroutine=_get_slowest_apis_wrapper
        ),
        Tool(
            name="get_traffic_by_time",
            description=get_traffic_by_time.description,
            func=_dummy_func,
            coroutine=_get_traffic_by_time_wrapper
        ),
        # New monitoring tools
        Tool(
            name="get_error_rate_trend",
            description=get_error_rate_trend.description,
            func=_dummy_func,
            coroutine=_get_error_rate_trend_wrapper
        ),
        Tool(
            name="get_service_health_status",
            description=get_service_health_status.description,
            func=_dummy_func,
            coroutine=_get_service_health_status_wrapper
        ),
        Tool(
            name="get_error_frequency_ranking",
            description=get_error_frequency_ranking.description,
            func=_dummy_func,
            coroutine=_get_error_frequency_ranking_wrapper
        ),
        Tool(
            name="get_api_error_rates",
            description=get_api_error_rates.description,
            func=_dummy_func,
            coroutine=_get_api_error_rates_wrapper
        ),
        Tool(
            name="get_affected_users_count",
            description=get_affected_users_count.description,
            func=_dummy_func,
            coroutine=_get_affected_users_count_wrapper
        ),
        # Comparison tools
        Tool(
            name="compare_time_periods",
            description=compare_time_periods.description,
            func=_dummy_func,
            coroutine=_compare_time_periods_wrapper
        ),
        Tool(
            name="detect_cascading_failures",
            description=detect_cascading_failures.description,
            func=_dummy_func,
            coroutine=_detect_cascading_failures_wrapper
        ),
        # Alert tools
        Tool(
            name="evaluate_alert_conditions",
            description=evaluate_alert_conditions.description,
            func=_dummy_func,
            coroutine=_evaluate_alert_conditions_wrapper
        ),
        Tool(
            name="detect_resource_issues",
            description=detect_resource_issues.description,
            func=_dummy_func,
            coroutine=_detect_resource_issues_wrapper
        ),
        # Deployment tools
        Tool(
            name="analyze_deployment_impact",
            description=analyze_deployment_impact.description,
            func=_dummy_func,
            coroutine=_analyze_deployment_impact_wrapper
        ),
    ]

    # ReAct Agent ÏÉùÏÑ±
    agent = create_react_agent(
        llm=llm,
        tools=tools,
        prompt=AGENT_PROMPT
    )

    # AgentExecutorÎ°ú ÎûòÌïë
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=settings.AGENT_VERBOSE,  # ÎîîÎ≤ÑÍπÖ Î°úÍ∑∏
        max_iterations=settings.AGENT_MAX_ITERATIONS,  # ÏµúÎåÄ 10Ìöå ÎèÑÍµ¨ Ìò∏Ï∂ú
        early_stopping_method="force",  # "generate"Îäî langchain 0.2.xÏóêÏÑú broken (known bug)
        handle_parsing_errors=True,  # ÌååÏã± ÏóêÎü¨ ÏûêÎèô Ï≤òÎ¶¨
        return_intermediate_steps=False,  # Ï§ëÍ∞Ñ Îã®Í≥Ñ Î∞òÌôò (ÏÑ†ÌÉù)
    )

    return agent_executor
