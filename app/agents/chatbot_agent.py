"""
ReAct Agent for Log Analysis

LLMì´ ììœ¨ì ìœ¼ë¡œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ë¡œê·¸ ë¶„ì„ ìˆ˜í–‰
"""

from typing import List

from langchain.agents import create_react_agent, AgentExecutor
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.tools import Tool

from app.tools.search_tools import search_logs_by_keyword, search_logs_by_similarity
from app.tools.analysis_tools import get_log_statistics, get_recent_errors
from app.tools.detail_tools import get_log_detail, get_logs_by_trace_id
from app.core.config import settings


# ReAct Agent System Prompt (í•œêµ­ì–´) - LangChain í‘œì¤€ í˜•ì‹
AGENT_PROMPT_TEMPLATE = """Answer the following questions as best you can. You have access to the following tools:

{tools}

CRITICAL RULES FOR "NO DATA FOUND" RESPONSES:
- If a tool returns "ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤" or "ERROR ë ˆë²¨ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤" or "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤", this is a VALID FINAL RESULT
- DO NOT retry with different parameters
- DO NOT try other tools
- IMMEDIATELY write: "Thought: I now know the final answer" followed by "Final Answer: [explain no logs found]"
- Example response format when no data found:
  Thought: I now know the final answer
  Final Answer: ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ ERROR ë¡œê·¸ê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.

SEVERITY ASSESSMENT GUIDELINES (for "ê°€ì¥ ì‹¬ê°í•œ", "most serious" questions):
- Database/Connection errors (DatabaseTimeout, ConnectionPoolExhausted, ConnectionRefused) = MOST SERIOUS (affects all users)
- Authentication/Security errors (InvalidToken, AuthFailure, UnauthorizedAccess) = HIGH severity (security risk)
- NullPointerException, IllegalStateException, RuntimeException = MEDIUM severity (specific feature broken)
- Slow queries, cache misses, warnings = LOW severity (performance degradation only)
- When asked "ê°€ì¥ ì‹¬ê°í•œ ì—ëŸ¬", "most critical error": Call get_recent_errors ONCE, analyze error types using above criteria, provide Final Answer
- DO NOT call get_recent_errors multiple times with different service_name filters unless specifically requested

EFFICIENCY RULES TO PREVENT ITERATION LOOPS:
- For "most X" questions (ê°€ì¥ ì‹¬ê°í•œ, ê°€ì¥ ë§ì€, most frequent), use ONE broad query first without filters
- Analyze the results and make a decision immediately - DO NOT iterate through all possible combinations
- AVOID calling the same tool multiple times with slightly different parameters
- Example workflow: "ê°€ì¥ ì‹¬ê°í•œ ì—ëŸ¬ê°€ ë­ì•¼?" â†’ get_recent_errors(limit=10) â†’ analyze types based on severity â†’ Final Answer (total: 1-2 tool calls)

FORMATTING GUIDELINES FOR FINAL ANSWER:
- For ANALYSIS questions (í†µê³„, ë¶„ì„, ìš”ì•½): Use structured markdown with ## headers, **bold** numbers, tables
- For SIMPLE questions (ì¸ì‚¬, ë‹¨ìˆœ ì¡°íšŒ): Keep it concise and natural
- Always include specific numbers, timestamps, service names when available
- Example structured: "## ğŸ“Š ìš”ì•½\nìµœê·¼ 7ì¼ê°„ **4ê±´**ì˜ ì—ëŸ¬ ë°œìƒ\n\n| ì„œë¹„ìŠ¤ | ê±´ìˆ˜ |\n|------|------|\n| user-service | 2ê±´ |"
- Example simple: "ì•ˆë…•í•˜ì„¸ìš”! ë¡œê·¸ ë¶„ì„ì´ í•„ìš”í•˜ì‹œë©´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."

DETAIL REQUIREMENTS FOR ANALYSIS RESPONSES:
- Include FULL error messages (do not truncate or summarize)
- Show complete stack traces when analyzing errors (minimum 5-10 lines of context)
- Always state the time range analyzed (e.g., "ìµœê·¼ 24ì‹œê°„", "2025-11-01 ~ 2025-11-07")
- Include HTTP details when relevant (method, path, status code)
- Cite specific log_ids so users can reference them (e.g., "log_id: 101")
- Use code blocks (```) for stack traces and technical details
- Target 1000-3000 characters for comprehensive analysis responses

EXAMPLE SCENARIO - "ê°€ì¥ ì‹¬ê°í•œ ì—ëŸ¬ê°€ ë­ì•¼?":
Question: ê°€ì¥ ì‹¬ê°í•œ ì—ëŸ¬ê°€ ë­ì•¼?
Thought: I need to get recent errors first and determine which is most serious based on severity guidelines
Action: get_recent_errors
Action Input: {{"limit": 10, "time_hours": 24}}
Observation: === ìµœê·¼ ì—ëŸ¬ ë¡œê·¸ (ìµœê·¼ 24ì‹œê°„) ===
ì´ 3ê±´ì˜ ì—ëŸ¬ ë°œìƒ, ìƒìœ„ 3ê±´ í‘œì‹œ

ì—ëŸ¬ íƒ€ì…ë³„ ë¶„í¬:
  - Unknown: 3ê±´

ìµœê·¼ ì—ëŸ¬ ëª©ë¡:
1. [Unknown] 2025-11-10T09:19
   ì„œë¹„ìŠ¤: user-service
   ë©”ì‹œì§€: NullPointerException: User object is null at line 45...
   (log_id: 101)

2. [Unknown] 2025-11-10T06:19
   ì„œë¹„ìŠ¤: payment-service
   ë©”ì‹œì§€: DatabaseTimeout: Connection pool exhausted after 30s...
   (log_id: 102)

3. [Unknown] 2025-11-09T21:19
   ì„œë¹„ìŠ¤: auth-service
   ë©”ì‹œì§€: InvalidTokenException: JWT signature verification failed...
   (log_id: 103)

Thought: According to severity guidelines, DatabaseTimeout (affects all users) is MOST SERIOUS, more critical than NullPointerException or InvalidToken
Final Answer: ## ğŸš¨ ê°€ì¥ ì‹¬ê°í•œ ì—ëŸ¬

**DatabaseTimeout** (log_id: 102)

**ë°œìƒ ì‹œê°„:** 3ì‹œê°„ ì „ (2025-11-10 06:19)
**ì„œë¹„ìŠ¤:** payment-service
**ì‹¬ê°ë„:** ìµœê³  (CRITICAL)

**ì—ëŸ¬ ë‚´ìš©:**
```
DatabaseTimeout: Connection pool exhausted after 30s
```

**ì˜í–¥ ë²”ìœ„:**
ê²°ì œ ì„œë¹„ìŠ¤ì˜ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ì´ ê³ ê°ˆë˜ì–´ **ëª¨ë“  ì‚¬ìš©ìì˜ ê²°ì œ ìš”ì²­ì´ ì‹¤íŒ¨**í–ˆìŠµë‹ˆë‹¤.

**ê¶Œì¥ ì¡°ì¹˜:**
1. ì¦‰ì‹œ DB ì—°ê²° í’€ í¬ê¸° í™•ì¸ ë° ì¦ì„¤
2. ì¥ì‹œê°„ ì‹¤í–‰ ì¤‘ì¸ ì¿¼ë¦¬ í™•ì¸
3. Connection leak ì—¬ë¶€ ì ê²€

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action (JSON format)
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question (in Korean)

Begin!

Question: {input}
Thought:{agent_scratchpad}"""

AGENT_PROMPT = PromptTemplate.from_template(AGENT_PROMPT_TEMPLATE)


def create_log_analysis_agent(project_uuid: str) -> AgentExecutor:
    """
    ë¡œê·¸ ë¶„ì„ìš© ReAct Agent ìƒì„±

    Args:
        project_uuid: í”„ë¡œì íŠ¸ UUID (ì–¸ë”ìŠ¤ì½”ì–´ í˜•ì‹)

    Returns:
        AgentExecutor (Agent ì‹¤í–‰ ì—”ì§„)
    """
    # LLM ì„¤ì •
    llm = ChatOpenAI(
        model=settings.AGENT_MODEL,
        temperature=0,  # ì¼ê´€ëœ ë‹µë³€
        api_key=settings.OPENAI_API_KEY,
        stop=["\nObservation"]  # Observation í™˜ê° ë°©ì§€
    )

    # project_uuidê°€ ë°”ì¸ë”©ëœ wrapper í•¨ìˆ˜ë“¤ ìƒì„±
    # Note: LangChain Tool requires sync 'func' and async 'coroutine'
    # We provide dummy sync func and actual async coroutine

    def _dummy_func(*args, **kwargs):
        raise NotImplementedError("Use async version")

    async def _search_logs_by_keyword_wrapper(tool_input: str = "", **kwargs):
        # tool_input is passed by agent, parse it if it's a JSON string
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON parsing error in search_logs_by_keyword: {e}, input: {tool_input}")
                # Continue with default parameters
        # Inject project_uuid and call the tool function directly
        params = {**kwargs, "project_uuid": project_uuid}
        return await search_logs_by_keyword.ainvoke(params)

    async def _search_logs_by_similarity_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON parsing error in search_logs_by_similarity: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await search_logs_by_similarity.ainvoke(params)

    async def _get_log_statistics_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON parsing error in get_log_statistics: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_log_statistics.ainvoke(params)

    async def _get_recent_errors_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON parsing error in get_recent_errors: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_recent_errors.ainvoke(params)

    async def _get_log_detail_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON parsing error in get_log_detail: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_log_detail.ainvoke(params)

    async def _get_logs_by_trace_id_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON parsing error in get_logs_by_trace_id: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_logs_by_trace_id.ainvoke(params)

    # Tool ëª©ë¡ (wrapper í•¨ìˆ˜ ì‚¬ìš©)
    tools: List[Tool] = [
        Tool(
            name="search_logs_by_keyword",
            description=search_logs_by_keyword.description,
            func=_dummy_func,
            coroutine=_search_logs_by_keyword_wrapper
        ),
        Tool(
            name="search_logs_by_similarity",
            description=search_logs_by_similarity.description,
            func=_dummy_func,
            coroutine=_search_logs_by_similarity_wrapper
        ),
        Tool(
            name="get_log_statistics",
            description=get_log_statistics.description,
            func=_dummy_func,
            coroutine=_get_log_statistics_wrapper
        ),
        Tool(
            name="get_recent_errors",
            description=get_recent_errors.description,
            func=_dummy_func,
            coroutine=_get_recent_errors_wrapper
        ),
        Tool(
            name="get_log_detail",
            description=get_log_detail.description,
            func=_dummy_func,
            coroutine=_get_log_detail_wrapper
        ),
        Tool(
            name="get_logs_by_trace_id",
            description=get_logs_by_trace_id.description,
            func=_dummy_func,
            coroutine=_get_logs_by_trace_id_wrapper
        ),
    ]

    # ReAct Agent ìƒì„±
    agent = create_react_agent(
        llm=llm,
        tools=tools,
        prompt=AGENT_PROMPT
    )

    # AgentExecutorë¡œ ë˜í•‘
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=settings.AGENT_VERBOSE,  # ë””ë²„ê¹… ë¡œê·¸
        max_iterations=settings.AGENT_MAX_ITERATIONS,  # ìµœëŒ€ 10íšŒ ë„êµ¬ í˜¸ì¶œ
        early_stopping_method="force",  # "generate"ëŠ” langchain 0.2.xì—ì„œ broken (known bug)
        handle_parsing_errors=True,  # íŒŒì‹± ì—ëŸ¬ ìë™ ì²˜ë¦¬
        return_intermediate_steps=False,  # ì¤‘ê°„ ë‹¨ê³„ ë°˜í™˜ (ì„ íƒ)
    )

    return agent_executor
