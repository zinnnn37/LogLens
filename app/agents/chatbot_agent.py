"""
ReAct Agent for Log Analysis

LLMì´ ììœ¨ì ìœ¼ë¡œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ë¡œê·¸ ë¶„ì„ ìˆ˜í–‰
"""

from typing import List

from langchain.agents import create_react_agent, AgentExecutor
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.tools import Tool

from app.tools.search_tools import search_logs_by_keyword, search_logs_by_similarity
from app.tools.analysis_tools import get_log_statistics, get_recent_errors
from app.tools.detail_tools import get_log_detail, get_logs_by_trace_id
from app.core.config import settings


# ReAct Agent System Prompt (í•œêµ­ì–´) - LangChain í‘œì¤€ í˜•ì‹
AGENT_PROMPT_TEMPLATE = """Answer the following questions as best you can. You have access to the following tools:

{tools}

CRITICAL RULES FOR "NO DATA FOUND" RESPONSES:
- If a tool returns "ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤" or "ERROR ë ˆë²¨ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤" or "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤", this is a VALID FINAL RESULT
- DO NOT retry with different parameters
- DO NOT try other tools
- IMMEDIATELY write: "Thought: I now know the final answer" followed by "Final Answer: [explain no logs found]"
- Example response format when no data found:
  Thought: I now know the final answer
  Final Answer: ìµœê·¼ 24ì‹œê°„ ë™ì•ˆ ERROR ë¡œê·¸ê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.

SEVERITY ASSESSMENT GUIDELINES (for "ê°€ì¥ ì‹¬ê°í•œ", "most serious" questions):
- CRITICAL (ì¦‰ì‹œ ì¡°ì¹˜): Database/Connection errors, OutOfMemory, StackOverflow, Deadlock, 5xx errors (affects all users)
- HIGH (ê¸´ê¸‰ ì¡°ì¹˜): Authentication/Security errors, InvalidToken, AuthFailure, UnauthorizedAccess (security risk)
- MEDIUM (ìš°ì„  ì¡°ì¹˜): NullPointerException, IllegalStateException, RuntimeException (specific feature broken)
- LOW (ëª¨ë‹ˆí„°ë§): 4xx errors, validation errors, slow queries (client-side or performance issues only)
- When asked "ê°€ì¥ ì‹¬ê°í•œ ì—ëŸ¬", "most critical error": Call get_recent_errors ONCE, analyze results, provide Final Answer
- DO NOT call get_recent_errors multiple times with different service_name filters unless specifically requested
- The tool returns errors sorted by severity automatically - trust the order

EFFICIENCY RULES TO PREVENT ITERATION LOOPS:
- For "most X" questions (ê°€ì¥ ì‹¬ê°í•œ, ê°€ì¥ ë§ì€, most frequent), use ONE broad query first without filters
- Analyze the results and make a decision immediately - DO NOT iterate through all possible combinations
- AVOID calling the same tool multiple times with slightly different parameters
- Example workflow: "ê°€ì¥ ì‹¬ê°í•œ ì—ëŸ¬ê°€ ë­ì•¼?" â†’ get_recent_errors(limit=10) â†’ analyze types based on severity â†’ Final Answer (total: 1-2 tool calls)

AI ANALYSIS FIELD USAGE (IMPORTANT):
- Tools now return ai_analysis fields: summary, error_cause, solution, tags, analysis_type
- **IF ai_analysis.summary EXISTS**: Include it prominently in your Final Answer (it's already analyzed by AI)
- **IF ai_analysis.error_cause EXISTS**: Use it to explain the root cause
- **IF ai_analysis.solution EXISTS**: Include it as recommended action
- **IF ai_analysis.tags EXIST**: Use them to categorize or identify error types
- **IMPORTANT**: ai_analysis fields may be empty for some logs - handle gracefully
- Prioritize AI analysis results over manual analysis when available
- Example: If tool returns "ğŸ¤– AI ë¶„ì„: ...", integrate it into your answer

TIME PARSING GUIDELINES:
- "ìµœê·¼ Nì¼" or "Nì¼ ë™ì•ˆ" â†’ time_hours = N * 24
- "ì–´ì œ" â†’ time_hours = 24
- "ì´ë²ˆ ì£¼" â†’ time_hours = 168 (7 days)
- "ìµœê·¼ 1ì‹œê°„" or "1ì‹œê°„ ë™ì•ˆ" â†’ time_hours = 1
- "ì˜¤ëŠ˜" â†’ time_hours = 24
- Always extract time values accurately from user questions

FORMATTING GUIDELINES FOR FINAL ANSWER:
- For ANALYSIS questions (í†µê³„, ë¶„ì„, ìš”ì•½): Use structured markdown with ## headers, **bold** numbers, tables
- For SIMPLE questions (ì¸ì‚¬, ë‹¨ìˆœ ì¡°íšŒ): Keep it concise and natural
- Always include specific numbers, timestamps, service names when available
- **Include AI analysis results when provided by tools**
- Example structured: "## ğŸ“Š ìš”ì•½\nìµœê·¼ 7ì¼ê°„ **4ê±´**ì˜ ì—ëŸ¬ ë°œìƒ\n\n**ğŸ¤– AI ë¶„ì„:**\nê²°ì œ ì„œë¹„ìŠ¤ DB ì—°ê²° ë¬¸ì œ\n\n| ì„œë¹„ìŠ¤ | ê±´ìˆ˜ |\n|------|------|\n| user-service | 2ê±´ |"
- Example simple: "ì•ˆë…•í•˜ì„¸ìš”! ë¡œê·¸ ë¶„ì„ì´ í•„ìš”í•˜ì‹œë©´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."

DETAIL REQUIREMENTS FOR ANALYSIS RESPONSES:
- Include FULL error messages (do not truncate or summarize)
- Show complete stack traces when analyzing errors (minimum 5-10 lines of context)
- Always state the time range analyzed (e.g., "ìµœê·¼ 24ì‹œê°„", "2025-11-01 ~ 2025-11-07")
- Include HTTP details when relevant (method, path, status code)
- Cite specific log_ids so users can reference them (e.g., "log_id: 101")
- Use code blocks (```) for stack traces and technical details
- Target 1000-3000 characters for comprehensive analysis responses

EXAMPLE SCENARIO - "ìµœê·¼ 10ì¼ ë™ì•ˆ ê°€ì¥ ì‹¬ê°í•œ ì—ëŸ¬ê°€ ë­ì•¼?":
Question: ìµœê·¼ 10ì¼ ë™ì•ˆ ê°€ì¥ ì‹¬ê°í•œ ì—ëŸ¬ê°€ ë­ì•¼?
Thought: I need to get recent errors from the last 10 days (240 hours) and identify the most serious one
Action: get_recent_errors
Action Input: {{"limit": 10, "time_hours": 240}}
Observation: === ìµœê·¼ ì—ëŸ¬ ë¡œê·¸ (ìµœê·¼ 240ì‹œê°„) ===
ì´ 5ê±´ì˜ ì—ëŸ¬ ë°œìƒ, ìƒìœ„ 5ê±´ í‘œì‹œ

ì—ëŸ¬ íƒ€ì…ë³„ ë¶„í¬:
  - DatabaseTimeout: 2ê±´
  - NullPointerException: 2ê±´
  - InvalidTokenException: 1ê±´

ìµœê·¼ ì—ëŸ¬ ëª©ë¡ (ì‹¬ê°ë„ìˆœ):
1. [DatabaseTimeout] 2025-11-03T14:32:10 | ì‹¬ê°ë„: CRITICAL
   ì„œë¹„ìŠ¤: payment-service
   ğŸ“ PaymentService.processPayment
   ğŸŒ POST /api/v1/payments â†’ 500
   â±ï¸  15234ms
   ğŸ’¬ DatabaseTimeout: Connection pool exhausted after 30s. Active: 20, Idle: 0, Max: 20
   ğŸ¤– AI ë¶„ì„: ê²°ì œ ì„œë¹„ìŠ¤ì˜ DB ì—°ê²° í’€ì´ ê³ ê°ˆë˜ì–´ ì „ì²´ ê²°ì œ ê¸°ëŠ¥ì´ ë§ˆë¹„ë¨
   ğŸ“Œ ì›ì¸: ì¥ì‹œê°„ ì‹¤í–‰ë˜ëŠ” ë°°ì¹˜ ì‘ì—…ì´ ì—°ê²°ì„ ë°˜í™˜í•˜ì§€ ì•ŠìŒ
   ğŸ’¡ í•´ê²°ì±…: 1. DB ì—°ê²° í’€ í¬ê¸° ì¦ì„¤ (20 â†’ 50), 2. ë°°ì¹˜ ì‘ì—…ì— íƒ€ì„ì•„ì›ƒ ì„¤ì •, 3. Connection leak ê°ì§€ ëª¨ë‹ˆí„°ë§ ì¶”ê°€
   ğŸ“š (ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ ìˆìŒ)
   (log_id: 12345)

2. [NullPointerException] 2025-11-04T09:15:22 | ì‹¬ê°ë„: MEDIUM
   ì„œë¹„ìŠ¤: user-service
   ğŸ“ UserController.getUser
   ğŸŒ GET /api/users/123 â†’ 500
   ğŸ’¬ NullPointerException: User object is null at line 45...
   (log_id: 12346)

...

Thought: The tool has already sorted errors by severity. The first error (DatabaseTimeout) is marked as CRITICAL and has AI analysis with root cause and solution. This is the most serious error.
Final Answer: ## ğŸš¨ ê°€ì¥ ì‹¬ê°í•œ ì—ëŸ¬

**DatabaseTimeout** (log_id: 12345)

**ë°œìƒ ì‹œê°„:** 2025-11-03 14:32:10 (7ì¼ ì „)
**ì„œë¹„ìŠ¤:** payment-service
**ìœ„ì¹˜:** PaymentService.processPayment
**ì‹¬ê°ë„:** CRITICAL (ìµœê³ )

**ì—ëŸ¬ ë‚´ìš©:**
```
DatabaseTimeout: Connection pool exhausted after 30s
Active: 20, Idle: 0, Max: 20
```

**ğŸ¤– AI ë¶„ì„:**
ê²°ì œ ì„œë¹„ìŠ¤ì˜ DB ì—°ê²° í’€ì´ ê³ ê°ˆë˜ì–´ ì „ì²´ ê²°ì œ ê¸°ëŠ¥ì´ ë§ˆë¹„ë¨

**ğŸ“Œ ì›ì¸:**
ì¥ì‹œê°„ ì‹¤í–‰ë˜ëŠ” ë°°ì¹˜ ì‘ì—…ì´ ì—°ê²°ì„ ë°˜í™˜í•˜ì§€ ì•ŠìŒ

**ğŸ’¡ ê¶Œì¥ í•´ê²°ì±…:**
1. DB ì—°ê²° í’€ í¬ê¸° ì¦ì„¤ (20 â†’ 50)
2. ë°°ì¹˜ ì‘ì—…ì— íƒ€ì„ì•„ì›ƒ ì„¤ì •
3. Connection leak ê°ì§€ ëª¨ë‹ˆí„°ë§ ì¶”ê°€

**ì˜í–¥ ë²”ìœ„:**
- HTTP 500 ì—ëŸ¬ ë°œìƒ
- ìš”ì²­ ì²˜ë¦¬ ì‹œê°„: 15.2ì´ˆ (ì •ìƒì˜ ì•½ 30ë°°)
- **ëª¨ë“  ì‚¬ìš©ìì˜ ê²°ì œ ìš”ì²­ ì‹¤íŒ¨**

**ì¶”ê°€ ì •ë³´:**
- ìš”ì²­: POST /api/v1/payments
- ìµœê·¼ 10ì¼ê°„ ë™ì¼ ì—ëŸ¬ 2ê±´ ë” ë°œìƒ

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action (JSON format)
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question (in Korean)

Begin!

Question: {input}
Thought:{agent_scratchpad}"""

AGENT_PROMPT = PromptTemplate.from_template(AGENT_PROMPT_TEMPLATE)


def create_log_analysis_agent(project_uuid: str) -> AgentExecutor:
    """
    ë¡œê·¸ ë¶„ì„ìš© ReAct Agent ìƒì„±

    Args:
        project_uuid: í”„ë¡œì íŠ¸ UUID (ì–¸ë”ìŠ¤ì½”ì–´ í˜•ì‹)

    Returns:
        AgentExecutor (Agent ì‹¤í–‰ ì—”ì§„)
    """
    # LLM ì„¤ì •
    llm = ChatOpenAI(
        model=settings.AGENT_MODEL,
        temperature=0,  # ì¼ê´€ëœ ë‹µë³€
        api_key=settings.OPENAI_API_KEY,
        stop=["\nObservation"]  # Observation í™˜ê° ë°©ì§€
    )

    # project_uuidê°€ ë°”ì¸ë”©ëœ wrapper í•¨ìˆ˜ë“¤ ìƒì„±
    # Note: LangChain Tool requires sync 'func' and async 'coroutine'
    # We provide dummy sync func and actual async coroutine

    def _dummy_func(*args, **kwargs):
        raise NotImplementedError("Use async version")

    async def _search_logs_by_keyword_wrapper(tool_input: str = "", **kwargs):
        # tool_input is passed by agent, parse it if it's a JSON string
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON parsing error in search_logs_by_keyword: {e}, input: {tool_input}")
                # Continue with default parameters
        # Inject project_uuid and call the tool function directly
        params = {**kwargs, "project_uuid": project_uuid}
        return await search_logs_by_keyword.ainvoke(params)

    async def _search_logs_by_similarity_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON parsing error in search_logs_by_similarity: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await search_logs_by_similarity.ainvoke(params)

    async def _get_log_statistics_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON parsing error in get_log_statistics: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_log_statistics.ainvoke(params)

    async def _get_recent_errors_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON parsing error in get_recent_errors: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_recent_errors.ainvoke(params)

    async def _get_log_detail_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON parsing error in get_log_detail: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_log_detail.ainvoke(params)

    async def _get_logs_by_trace_id_wrapper(tool_input: str = "", **kwargs):
        import json
        if isinstance(tool_input, str) and tool_input:
            try:
                kwargs.update(json.loads(tool_input))
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON parsing error in get_logs_by_trace_id: {e}, input: {tool_input}")
                # Continue with default parameters
        params = {**kwargs, "project_uuid": project_uuid}
        return await get_logs_by_trace_id.ainvoke(params)

    # Tool ëª©ë¡ (wrapper í•¨ìˆ˜ ì‚¬ìš©)
    tools: List[Tool] = [
        Tool(
            name="search_logs_by_keyword",
            description=search_logs_by_keyword.description,
            func=_dummy_func,
            coroutine=_search_logs_by_keyword_wrapper
        ),
        Tool(
            name="search_logs_by_similarity",
            description=search_logs_by_similarity.description,
            func=_dummy_func,
            coroutine=_search_logs_by_similarity_wrapper
        ),
        Tool(
            name="get_log_statistics",
            description=get_log_statistics.description,
            func=_dummy_func,
            coroutine=_get_log_statistics_wrapper
        ),
        Tool(
            name="get_recent_errors",
            description=get_recent_errors.description,
            func=_dummy_func,
            coroutine=_get_recent_errors_wrapper
        ),
        Tool(
            name="get_log_detail",
            description=get_log_detail.description,
            func=_dummy_func,
            coroutine=_get_log_detail_wrapper
        ),
        Tool(
            name="get_logs_by_trace_id",
            description=get_logs_by_trace_id.description,
            func=_dummy_func,
            coroutine=_get_logs_by_trace_id_wrapper
        ),
    ]

    # ReAct Agent ìƒì„±
    agent = create_react_agent(
        llm=llm,
        tools=tools,
        prompt=AGENT_PROMPT
    )

    # AgentExecutorë¡œ ë˜í•‘
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=settings.AGENT_VERBOSE,  # ë””ë²„ê¹… ë¡œê·¸
        max_iterations=settings.AGENT_MAX_ITERATIONS,  # ìµœëŒ€ 10íšŒ ë„êµ¬ í˜¸ì¶œ
        early_stopping_method="force",  # "generate"ëŠ” langchain 0.2.xì—ì„œ broken (known bug)
        handle_parsing_errors=True,  # íŒŒì‹± ì—ëŸ¬ ìë™ ì²˜ë¦¬
        return_intermediate_steps=False,  # ì¤‘ê°„ ë‹¨ê³„ ë°˜í™˜ (ì„ íƒ)
    )

    return agent_executor
