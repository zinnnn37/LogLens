"""
Chatbot endpoints
"""

from fastapi import APIRouter, HTTPException, BackgroundTasks
from fastapi.responses import StreamingResponse
from langchain_core.messages import HumanMessage, AIMessage
import json
import logging

from app.services.chatbot_service import chatbot_service
from app.services.embedding_service import embedding_service
from app.services.similarity_service import similarity_service
from app.chains.chatbot_chain import chatbot_chain
from app.models.chat import ChatRequest, ChatResponse
from app.core.config import settings

router = APIRouter()
logger = logging.getLogger(__name__)


@router.post(
    "/chatbot/ask",
    response_model=ChatResponse,
    summary="Ï±óÎ¥á ÏßàÎ¨∏",
    description="""
    ÏûêÏó∞Ïñ¥Î°ú Î°úÍ∑∏Ïóê ÎåÄÌï¥ ÏßàÎ¨∏ÌïòÍ≥† AI Í∏∞Î∞ò ÎãµÎ≥ÄÏùÑ Î∞õÏäµÎãàÎã§. RAG(Retrieval-Augmented Generation) Î∞©ÏãùÏúºÎ°ú Í¥ÄÎ†® Î°úÍ∑∏Î•º Í≤ÄÏÉâÌïòÏó¨ Ïª®ÌÖçÏä§Ìä∏Î°ú ÌôúÏö©Ìï©ÎãàÎã§.

    ## üÜï ÏûêÎèô ÌïÑÌÑ∞ Ï∂îÏ∂ú (NEW!)

    **questionÎßå ÏûÖÎ†•ÌïòÎ©¥ AIÍ∞Ä ÏûêÎèôÏúºÎ°ú ÌïÑÌÑ∞ Ï°∞Í±¥ÏùÑ Ï∂îÏ∂úÌï©ÎãàÎã§!**

    - "ÏóêÎü¨ Î°úÍ∑∏ Î≥¥Ïó¨Ï§ò" ‚Üí `filters: {level: "ERROR"}` ÏûêÎèô Ï∂îÏ∂ú
    - "user-serviceÏùò ÏµúÍ∑º 1ÏãúÍ∞Ñ WARNING" ‚Üí `filters: {level: "WARN", service_name: "user-service"}` + `time_range: ÏµúÍ∑º 1ÏãúÍ∞Ñ` ÏûêÎèô Ï∂îÏ∂ú
    - "Ïò§Îäò ÌîÑÎ°†Ìä∏ÏóîÎìú ÏóêÎü¨" ‚Üí `filters: {level: "ERROR", source_type: "FE"}` + `time_range: Ïò§Îäò` ÏûêÎèô Ï∂îÏ∂ú
    - "IP 192.168.1.100ÏóêÏÑú Î∞úÏÉùÌïú Î°úÍ∑∏" ‚Üí `filters: {ip: "192.168.1.100"}` ÏûêÎèô Ï∂îÏ∂ú

    **ÏûêÎèô Ï∂îÏ∂úÎêòÎäî ÌïÑÌÑ∞**:
    - Î°úÍ∑∏ Î†àÎ≤® (ERROR, WARN, INFO)
    - ÏÑúÎπÑÏä§ Ïù¥Î¶Ñ (user-service, payment-api Îì±)
    - ÏÜåÏä§ ÌÉÄÏûÖ (FE, BE)
    - IP Ï£ºÏÜå
    - ÏãúÍ∞Ñ ÌëúÌòÑ (ÏµúÍ∑º NÏãúÍ∞Ñ, Ïò§Îäò, Ïñ¥Ï†ú, ÌäπÏ†ï ÎÇ†Ïßú Îì±)

    **Í∏∞Î≥∏ ÏãúÍ∞Ñ Î≤îÏúÑ**: Î™ÖÏãúÎêòÏßÄ ÏïäÏúºÎ©¥ ÏûêÎèôÏúºÎ°ú ÏµúÍ∑º 7Ïùº Ï†ÅÏö©

    **Ï∞∏Í≥†**: filters, time_rangeÎ•º Î™ÖÏãúÏ†ÅÏúºÎ°ú Ï†ÑÎã¨ÌïòÎ©¥ ÏûêÎèô Ï∂îÏ∂úÏùÑ Í±¥ÎÑàÎúÅÎãàÎã§.

    ## Ï≤òÎ¶¨ ÌùêÎ¶Ñ

    0. **ÏûêÎèô ÌïÑÌÑ∞ Ï∂îÏ∂ú**: questionÏóêÏÑú filtersÏôÄ time_range ÏûêÎèô ÌååÏã± (Î™ÖÏãúÎêòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞)
    1. **ÏßàÎ¨∏ ÏûÑÎ≤†Îî© ÏÉùÏÑ±**: ÏßàÎ¨∏ÏùÑ 1536Ï∞®Ïõê Î≤°ÌÑ∞Î°ú Î≥ÄÌôò
    2. **QA Ï∫êÏãú ÌôïÏù∏** (2Îã®Í≥Ñ Í≤ÄÏ¶ù):
       - a. ÏùòÎØ∏Ï†Å Ïú†ÏÇ¨ÎèÑ Í≤ÄÏÉâ (ÏΩîÏÇ¨Ïù∏ Ïú†ÏÇ¨ÎèÑ ‚â• 0.8)
       - b. Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Îß§Ïπ≠ (project_uuid, filters, time_range) + TTL Í≤ÄÏ¶ù
    3. **Ï∫êÏãú ÌûàÌä∏**: Ï†ÄÏû•Îêú ÎãµÎ≥Ä Î∞òÌôò (40-60% ÎπÑÏö© Ï†àÍ∞ê)
    4. **Ï∫êÏãú ÎØ∏Ïä§**:
       - Vector Í≤ÄÏÉâÏúºÎ°ú Í¥ÄÎ†® Î°úÍ∑∏ ÌÉêÏÉâ (Ï∂îÏ∂úÎêú filters + time_range Ï†ÅÏö©)
       - GPT-4o miniÎ°ú RAG ÎãµÎ≥Ä ÏÉùÏÑ± (ÎåÄÌôî ÌûàÏä§ÌÜ†Î¶¨ Ìè¨Ìï®)
       - QA ÌéòÏñ¥ Ï∫êÏã± (Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ + ÎèôÏ†Å TTL)

    ## ÎåÄÌôî ÌûàÏä§ÌÜ†Î¶¨ ÏßÄÏõê

    - Ïù¥Ï†Ñ ÎåÄÌôî Îß•ÎùΩÏùÑ Ïú†ÏßÄÌïòÏó¨ ÌõÑÏÜç ÏßàÎ¨∏Ïóê ÎãµÎ≥Ä Í∞ÄÎä•
    - ÌÜ†ÌÅ∞ Í∏∞Î∞ò ÌûàÏä§ÌÜ†Î¶¨ ÏïïÏ∂ï (ÏµúÎåÄ 1500 ÌÜ†ÌÅ∞)
    - Ïòà: "Í∑∏ ÏóêÎü¨Îäî Ïñ∏Ï†ú Î∞úÏÉùÌñàÏñ¥?" ‚Üí Ïù¥Ï†Ñ ÎåÄÌôîÏùò ÏóêÎü¨Î•º Ï∞∏Ï°∞

    ## ÌïÑÌÑ∞ÎßÅ ÏòµÏÖò (ÏÑ†ÌÉùÏÇ¨Ìï≠)

    **ÏûêÎèô Ï∂îÏ∂úÎêòÎØÄÎ°ú ÏùºÎ∞òÏ†ÅÏúºÎ°ú Ï†ÑÎã¨Ìï† ÌïÑÏöî ÏóÜÏùå**. ÌïòÏßÄÎßå Î™ÖÏãúÏ†ÅÏúºÎ°ú Ï†ÑÎã¨ÌïòÍ≥† Ïã∂Îã§Î©¥:

    - **level**: ERROR, WARN, INFO Îì±
    - **service_name**: ÌäπÏ†ï ÏÑúÎπÑÏä§Îßå Í≤ÄÏÉâ
    - **time_range**: ÏãúÍ∞Ñ Î≤îÏúÑ ÏßÄÏ†ï (ISO 8601 ÌòïÏãù: {"start": "2024-01-15T00:00:00Z", "end": "2024-01-15T23:59:59Z"})

    ## ÎãµÎ≥Ä ÌòïÏãù

    - ÌïúÍµ≠Ïñ¥Î°ú ÎãµÎ≥Ä
    - Í¥ÄÎ†® Î°úÍ∑∏ ÏµúÎåÄ 5Í∞ú Ìè¨Ìï® (Ïú†ÏÇ¨ÎèÑ Ï†êÏàòÏôÄ Ìï®Íªò)
    - Ï∫êÏãú Ïó¨Î∂Ä ÌëúÏãú
    """,
    responses={
        200: {
            "description": "ÎãµÎ≥Ä ÏÑ±Í≥µ",
            "content": {
                "application/json": {
                    "examples": {
                        "auto_filter_extraction": {
                            "summary": "ÏûêÎèô ÌïÑÌÑ∞ Ï∂îÏ∂ú (ÏÉàÎ°ú ÏÉùÏÑ±)",
                            "description": "questionÏóêÏÑú ÌïÑÌÑ∞Í∞Ä ÏûêÎèôÏúºÎ°ú Ï∂îÏ∂úÎêòÏñ¥ Í≤ÄÏÉâÎê®",
                            "value": {
                                "answer": "ÏµúÍ∑º 1ÏãúÍ∞Ñ ÎèôÏïà user-serviceÏóêÏÑú 3Í±¥Ïùò ERRORÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§. Î™®Îëê NullPointerExceptionÏúºÎ°ú, UserService.getUser() Î©îÏÑúÎìúÏóêÏÑú Î∞úÏÉùÌñàÏäµÎãàÎã§.",
                                "from_cache": False,
                                "related_logs": [
                                    {
                                        "log_id": 12345,
                                        "timestamp": "2025-11-10T09:30:00Z",
                                        "level": "ERROR",
                                        "message": "NullPointerException in UserService.getUser()",
                                        "service_name": "user-service",
                                        "similarity_score": 0.95
                                    }
                                ],
                                "answered_at": "2025-11-10T10:00:00Z"
                            }
                        },
                        "cached_answer": {
                            "summary": "Ï∫êÏãúÎêú ÎãµÎ≥Ä (Îπ†Î•∏ ÏùëÎãµ)",
                            "description": "Ïù¥Ï†ÑÏóê ÎèôÏùºÌïú ÏßàÎ¨∏Ïù¥ ÏûàÏñ¥ Ï∫êÏãúÏóêÏÑú Ï¶âÏãú Î∞òÌôò",
                            "value": {
                                "answer": "ÏµúÍ∑º 24ÏãúÍ∞Ñ ÎèôÏïà ERROR Î†àÎ≤® Î°úÍ∑∏Îäî Ï¥ù 15Í±¥ Î∞úÏÉùÌñàÏäµÎãàÎã§. Ï£ºÏöî ÏõêÏù∏ÏùÄ NullPointerException(8Í±¥)Í≥º DatabaseConnectionException(7Í±¥)ÏûÖÎãàÎã§.",
                                "from_cache": True,
                                "related_logs": [
                                    {
                                        "log_id": 12346,
                                        "timestamp": "2025-11-10T08:15:00Z",
                                        "level": "ERROR",
                                        "message": "DatabaseConnectionException: Connection timeout",
                                        "service_name": "payment-service",
                                        "similarity_score": 0.88
                                    }
                                ],
                                "answered_at": "2025-11-10T10:00:00Z"
                            }
                        },
                        "conversation_context": {
                            "summary": "ÎåÄÌôî ÌûàÏä§ÌÜ†Î¶¨ ÌôúÏö©",
                            "description": "Ïù¥Ï†Ñ ÎåÄÌôîÎ•º Ï∞∏Ï°∞ÌïòÏó¨ ÌõÑÏÜç ÏßàÎ¨∏Ïóê ÎãµÎ≥Ä",
                            "value": {
                                "answer": "Í∑∏ Ï§ë Í∞ÄÏû• Ïã¨Í∞ÅÌïú Í≤ÉÏùÄ payment-serviceÏùò DatabaseConnectionExceptionÏûÖÎãàÎã§. Í≤∞Ï†ú Ï≤òÎ¶¨Í∞Ä Ï§ëÎã®ÎêòÏñ¥ ÎπÑÏ¶àÎãàÏä§Ïóê ÏßÅÏ†ëÏ†ÅÏù∏ ÏòÅÌñ•ÏùÑ ÎØ∏ÏπòÍ≥† ÏûàÏäµÎãàÎã§.",
                                "from_cache": False,
                                "related_logs": [
                                    {
                                        "log_id": 12346,
                                        "timestamp": "2025-11-10T08:15:00Z",
                                        "level": "ERROR",
                                        "message": "DatabaseConnectionException: Connection timeout",
                                        "service_name": "payment-service",
                                        "similarity_score": 0.92
                                    }
                                ],
                                "answered_at": "2025-11-10T10:01:00Z"
                            }
                        }
                    }
                }
            }
        },
        400: {
            "description": "ÏûòÎ™ªÎêú ÏöîÏ≤≠ - questionÏù¥ ÎπÑÏñ¥ÏûàÍ±∞ÎÇò project_uuid ÌòïÏãùÏù¥ ÏûòÎ™ªÎê®",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "question field is required"
                    }
                }
            }
        },
        500: {
            "description": "Ï≤òÎ¶¨ Ïò§Î•ò - LLM Ìò∏Ï∂ú Ïã§Ìå®, OpenSearch Ïó∞Í≤∞ Î¨∏Ï†ú Îì±",
            "content": {
                "application/json": {
                    "example": {
                        "detail": "Chatbot error: OpenAI API timeout"
                    }
                }
            }
        }
    }
)
async def ask_chatbot(request: ChatRequest):
    """RAG Í∏∞Î∞ò Î°úÍ∑∏ ÏßàÎ¨∏ ÏùëÎãµ"""
    try:
        result = await chatbot_service.ask(
            question=request.question,
            project_uuid=request.project_uuid,  # Multi-tenancy support
            chat_history=request.chat_history,  # Chat history support
            filters=request.filters,
            time_range=request.time_range,
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chatbot error: {str(e)}")


@router.post(
    "/chatbot/ask/stream",
    summary="Ï±óÎ¥á Ïä§Ìä∏Î¶¨Î∞ç ÏßàÎ¨∏",
    description="""
    ÏûêÏó∞Ïñ¥Î°ú Î°úÍ∑∏Ïóê ÎåÄÌï¥ ÏßàÎ¨∏ÌïòÍ≥† Ïã§ÏãúÍ∞Ñ ÌÉÄÏù¥Ìïë Ìö®Í≥ºÎ°ú ÎãµÎ≥ÄÏùÑ Î∞õÏäµÎãàÎã§. SSE(Server-Sent Events) ÌòïÏãùÏúºÎ°ú ÏùëÎãµÏù¥ Ïä§Ìä∏Î¶¨Î∞çÎê©ÎãàÎã§.

    ## SSE ÏùëÎãµ ÌòïÏãù

    ```
    data: ÏµúÍ∑º 24ÏãúÍ∞Ñ ÎèôÏïà\n\n
    data: user-serviceÏóêÏÑú\n\n
    data: 3Í±¥Ïùò ÏóêÎü¨Í∞Ä\n\n
    data: Î∞úÏÉùÌñàÏäµÎãàÎã§.\n\n
    data: [DONE]\n\n
    ```

    ## ÏùëÎãµ ÏãúÍ∑∏ÎÑê

    - **ÌÖçÏä§Ìä∏ Ï≤≠ÌÅ¨**: `data: {content}\\n\\n`
    - **ÏôÑÎ£å**: `data: [DONE]\\n\\n`
    - **ÏóêÎü¨**: `data: [ERROR]\\n\\n` Îã§Ïùå `data: {"error": "..."}\\n\\n`

    ## Ï≤òÎ¶¨ ÌùêÎ¶Ñ

    1. ÏßàÎ¨∏ ÏûÑÎ≤†Îî© ÏÉùÏÑ±
    2. QA Ï∫êÏãú ÌôïÏù∏ (ÌûàÏä§ÌÜ†Î¶¨ ÏóÜÏùÑ ÎïåÎßå)
    3. Ï∫êÏãú ÌûàÌä∏: Ï†ÑÏ≤¥ ÎãµÎ≥Ä Ìïú Î≤àÏóê Ï†ÑÏÜ° ÌõÑ [DONE]
    4. Ï∫êÏãú ÎØ∏Ïä§:
       - Í¥ÄÎ†® Î°úÍ∑∏ Í≤ÄÏÉâ
       - LLM Ïä§Ìä∏Î¶¨Î∞ç ÏùëÎãµ (Ï≤≠ÌÅ¨ Îã®ÏúÑ Ï†ÑÏÜ°)
       - Î∞±Í∑∏ÎùºÏö¥ÎìúÏóêÏÑú QA Ï∫êÏã± (ÎπÑÏ∞®Îã®)

    ## ÎåÄÌôî ÌûàÏä§ÌÜ†Î¶¨

    - Ïù¥Ï†Ñ ÎåÄÌôîÎ•º Ï∞∏Ï°∞ÌïòÏó¨ ÎãµÎ≥Ä ÏÉùÏÑ±
    - ÌÜ†ÌÅ∞ Í∏∞Î∞ò ÏïïÏ∂ï (ÏµúÎåÄ 1500 ÌÜ†ÌÅ∞)

    ## ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÇ¨Ïö© ÏòàÏãú (JavaScript)

    ```javascript
    const eventSource = new EventSource('/api/v1/chatbot/ask/stream');
    eventSource.onmessage = (event) => {
      if (event.data === '[DONE]') {
        eventSource.close();
      } else if (event.data === '[ERROR]') {
        // Îã§Ïùå Î©îÏãúÏßÄÏóêÏÑú ÏóêÎü¨ ÎÇ¥Ïö© ÏàòÏã†
      } else {
        console.log(event.data); // ÌÖçÏä§Ìä∏ Ï≤≠ÌÅ¨ Ï∂úÎ†•
      }
    };
    ```

    ## Ï£ºÏùòÏÇ¨Ìï≠

    - Content-Type: `text/event-stream`
    - Ï∫êÏãú ÎπÑÌôúÏÑ±Ìôî (Cache-Control: no-cache)
    - Nginx Î≤ÑÌçºÎßÅ ÎπÑÌôúÏÑ±Ìôî (X-Accel-Buffering: no)
    """,
    responses={
        200: {
            "description": "Ïä§Ìä∏Î¶¨Î∞ç ÏãúÏûë - SSE ÌòïÏãùÏúºÎ°ú ÎãµÎ≥Ä Ï†ÑÏÜ°",
            "content": {
                "text/event-stream": {
                    "example": "data: ÏµúÍ∑º 24ÏãúÍ∞Ñ ÎèôÏïà\n\ndata: user-serviceÏóêÏÑú\n\ndata: 3Í±¥Ïùò ÏóêÎü¨Í∞Ä\n\ndata: Î∞úÏÉùÌñàÏäµÎãàÎã§.\n\ndata: [DONE]\n\n"
                }
            }
        },
        500: {
            "description": "Ï≤òÎ¶¨ Ïò§Î•ò - ÏóêÎü¨ ÏãúÍ∑∏ÎÑêÍ≥º Ìï®Íªò Ïä§Ìä∏Î¶ºÏúºÎ°ú Ï†ÑÏÜ°Îê®",
            "content": {
                "text/event-stream": {
                    "example": "data: [ERROR]\n\ndata: {\"error\": \"OpenSearch connection failed\"}\n\n"
                }
            }
        }
    }
)
async def ask_chatbot_stream(request: ChatRequest, background_tasks: BackgroundTasks):
    """RAG Í∏∞Î∞ò Î°úÍ∑∏ ÏßàÎ¨∏ ÏùëÎãµ (Ïã§ÏãúÍ∞Ñ Ïä§Ìä∏Î¶¨Î∞ç)"""
    async def generate():
        try:
            # 1. Generate question embedding
            question_vector = await embedding_service.embed_query(request.question)

            # 2. Check cache (skip if chat_history present - history-dependent answers)
            if not request.chat_history:
                cache_candidates = await similarity_service.find_similar_questions(
                    question_vector=question_vector,
                    k=settings.CACHE_CANDIDATE_SIZE,
                    project_uuid=request.project_uuid
                )

                # Ï∫êÏãú ÌûàÌä∏ Ïãú Ï†ÑÏ≤¥ ÎãµÎ≥Ä Ï†ÑÏÜ°
                for candidate in cache_candidates:
                    if candidate["score"] >= chatbot_service.threshold:
                        if chatbot_service._is_cache_valid(candidate):
                            if chatbot_service._metadata_matches(
                                candidate.get("metadata", {}),
                                request.filters,
                                request.time_range,
                                request.project_uuid
                            ):
                                cached_answer = candidate["answer"]
                                yield f"data: {cached_answer}\n\n"
                                yield "data: [DONE]\n\n"
                                return

            # 3. Auto-extract filters and time_range if not provided
            filters = request.filters
            time_range = request.time_range

            if filters is None or time_range is None:
                from app.services.filter_parser import parse_question
                extracted_filters, extracted_time_range = await parse_question(request.question)

                if filters is None:
                    filters = extracted_filters
                if time_range is None:
                    time_range = extracted_time_range

            # 4. Search relevant logs
            relevant_logs_data = await similarity_service.find_similar_logs(
                log_vector=question_vector,
                k=chatbot_service.max_context,
                filters=filters,
                project_uuid=request.project_uuid,
                time_range=time_range,
            )

            # 4. Prepare context
            context_logs = chatbot_service._format_context_logs(relevant_logs_data)

            # 5. Convert chat history to LangChain messages (token-based truncation)
            history_messages = []
            if request.chat_history:
                # Truncate history based on token budget (1500 tokens)
                truncated_history = chatbot_service._truncate_history(request.chat_history, max_tokens=1500)
                for msg in truncated_history:
                    if msg.role == "user":
                        history_messages.append(HumanMessage(content=msg.content))
                    elif msg.role == "assistant":
                        history_messages.append(AIMessage(content=msg.content))

            # 6. Stream LLM response
            full_answer = ""
            async for chunk in chatbot_chain.astream({
                "context_logs": context_logs,
                "question": request.question,
                "chat_history": history_messages,
            }):
                content = chunk.content
                full_answer += content

                # SSE ÌòïÏãùÏúºÎ°ú Ï†ÑÏÜ°
                yield f"data: {content}\n\n"

            # 7. Completion signal
            yield "data: [DONE]\n\n"

            # 8. Cache QA pair (Î∞±Í∑∏ÎùºÏö¥ÎìúÏóêÏÑú ÎπÑÎèôÍ∏∞)
            related_log_ids = [log["log_id"] for log in relevant_logs_data]
            ttl = chatbot_service._calculate_ttl(request.question, time_range)

            background_tasks.add_task(
                chatbot_service._cache_qa_pair,
                question=request.question,
                question_vector=question_vector,
                answer=full_answer,
                related_log_ids=related_log_ids,
                metadata={
                    "project_uuid": request.project_uuid,
                    "filters": filters,  # Use extracted filters
                    "time_range": time_range,  # Use extracted time_range
                },
                ttl=ttl
            )

        except Exception as e:
            # Log the error with context
            logger.error(
                f"Stream error for project {request.project_uuid}: {str(e)}",
                extra={
                    "project_uuid": request.project_uuid,
                    "question": request.question[:100],  # Truncate for logging
                    "error": str(e),
                },
                exc_info=True
            )

            # Send error signal and data to client
            yield "data: [ERROR]\n\n"
            error_data = json.dumps({"error": str(e)})
            yield f"data: {error_data}\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # Nginx Î≤ÑÌçºÎßÅ ÎπÑÌôúÏÑ±Ìôî
        }
    )
